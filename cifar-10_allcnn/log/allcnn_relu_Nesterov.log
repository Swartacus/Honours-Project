I1010 14:43:31.594665  5944 caffe.cpp:217] Using GPUs 0
I1010 14:43:31.597364  5944 caffe.cpp:222] GPU 0: GeForce GTX 750 Ti
I1010 14:43:31.705914  5944 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt"
test_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt"
test_iter: 100
test_interval: 250
base_lr: 0.0001
display: 50
max_iter: 2500
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 5000
snapshot: 5000
snapshot_prefix: "cifar-10_relu_Nesterov"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
type: "Nesterov"
I1010 14:43:31.706079  5944 solver.cpp:81] Creating training net from train_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt
I1010 14:43:31.706396  5944 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn1"
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn1"
  top: "bn1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "bn1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "drop1"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv5"
  top: "bn2"
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "bn2"
  top: "bn2"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "bn2"
  top: "drop4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "drop4"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "flatten"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1010 14:43:31.706545  5944 layer_factory.hpp:77] Creating layer data
I1010 14:43:31.707008  5944 net.cpp:100] Creating Layer data
I1010 14:43:31.707016  5944 net.cpp:408] data -> data
I1010 14:43:31.707032  5944 net.cpp:408] data -> label
I1010 14:43:31.707058  5944 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1010 14:43:31.707703  5949 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_train_lmdb
I1010 14:43:31.714156  5944 data_layer.cpp:41] output data size: 64,3,32,32
I1010 14:43:31.715821  5944 net.cpp:150] Setting up data
I1010 14:43:31.715840  5944 net.cpp:157] Top shape: 64 3 32 32 (196608)
I1010 14:43:31.715844  5944 net.cpp:157] Top shape: 64 (64)
I1010 14:43:31.715847  5944 net.cpp:165] Memory required for data: 786688
I1010 14:43:31.715867  5944 layer_factory.hpp:77] Creating layer label_data_1_split
I1010 14:43:31.715889  5944 net.cpp:100] Creating Layer label_data_1_split
I1010 14:43:31.715893  5944 net.cpp:434] label_data_1_split <- label
I1010 14:43:31.715903  5944 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1010 14:43:31.715909  5944 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1010 14:43:31.715955  5944 net.cpp:150] Setting up label_data_1_split
I1010 14:43:31.715960  5944 net.cpp:157] Top shape: 64 (64)
I1010 14:43:31.715962  5944 net.cpp:157] Top shape: 64 (64)
I1010 14:43:31.715965  5944 net.cpp:165] Memory required for data: 787200
I1010 14:43:31.715966  5944 layer_factory.hpp:77] Creating layer conv1
I1010 14:43:31.715977  5944 net.cpp:100] Creating Layer conv1
I1010 14:43:31.715979  5944 net.cpp:434] conv1 <- data
I1010 14:43:31.715984  5944 net.cpp:408] conv1 -> conv1
I1010 14:43:31.854856  5944 net.cpp:150] Setting up conv1
I1010 14:43:31.854879  5944 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1010 14:43:31.854882  5944 net.cpp:165] Memory required for data: 22905600
I1010 14:43:31.854898  5944 layer_factory.hpp:77] Creating layer relu1
I1010 14:43:31.854907  5944 net.cpp:100] Creating Layer relu1
I1010 14:43:31.854910  5944 net.cpp:434] relu1 <- conv1
I1010 14:43:31.854913  5944 net.cpp:395] relu1 -> conv1 (in-place)
I1010 14:43:31.855096  5944 net.cpp:150] Setting up relu1
I1010 14:43:31.855103  5944 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1010 14:43:31.855105  5944 net.cpp:165] Memory required for data: 45024000
I1010 14:43:31.855108  5944 layer_factory.hpp:77] Creating layer conv2
I1010 14:43:31.855118  5944 net.cpp:100] Creating Layer conv2
I1010 14:43:31.855119  5944 net.cpp:434] conv2 <- conv1
I1010 14:43:31.855123  5944 net.cpp:408] conv2 -> conv2
I1010 14:43:31.856524  5944 net.cpp:150] Setting up conv2
I1010 14:43:31.856534  5944 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1010 14:43:31.856536  5944 net.cpp:165] Memory required for data: 64291584
I1010 14:43:31.856544  5944 layer_factory.hpp:77] Creating layer bn1
I1010 14:43:31.856549  5944 net.cpp:100] Creating Layer bn1
I1010 14:43:31.856550  5944 net.cpp:434] bn1 <- conv2
I1010 14:43:31.856554  5944 net.cpp:408] bn1 -> bn1
I1010 14:43:31.856745  5944 net.cpp:150] Setting up bn1
I1010 14:43:31.856750  5944 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1010 14:43:31.856766  5944 net.cpp:165] Memory required for data: 83559168
I1010 14:43:31.856772  5944 layer_factory.hpp:77] Creating layer relu2
I1010 14:43:31.856776  5944 net.cpp:100] Creating Layer relu2
I1010 14:43:31.856778  5944 net.cpp:434] relu2 <- bn1
I1010 14:43:31.856781  5944 net.cpp:395] relu2 -> bn1 (in-place)
I1010 14:43:31.856973  5944 net.cpp:150] Setting up relu2
I1010 14:43:31.856979  5944 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1010 14:43:31.856992  5944 net.cpp:165] Memory required for data: 102826752
I1010 14:43:31.856993  5944 layer_factory.hpp:77] Creating layer drop1
I1010 14:43:31.856997  5944 net.cpp:100] Creating Layer drop1
I1010 14:43:31.856999  5944 net.cpp:434] drop1 <- bn1
I1010 14:43:31.857004  5944 net.cpp:408] drop1 -> drop1
I1010 14:43:31.857049  5944 net.cpp:150] Setting up drop1
I1010 14:43:31.857069  5944 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1010 14:43:31.857071  5944 net.cpp:165] Memory required for data: 122094336
I1010 14:43:31.857086  5944 layer_factory.hpp:77] Creating layer conv3
I1010 14:43:31.857092  5944 net.cpp:100] Creating Layer conv3
I1010 14:43:31.857095  5944 net.cpp:434] conv3 <- drop1
I1010 14:43:31.857112  5944 net.cpp:408] conv3 -> conv3
I1010 14:43:31.858283  5944 net.cpp:150] Setting up conv3
I1010 14:43:31.858291  5944 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1010 14:43:31.858294  5944 net.cpp:165] Memory required for data: 126247680
I1010 14:43:31.858300  5944 layer_factory.hpp:77] Creating layer relu3
I1010 14:43:31.858304  5944 net.cpp:100] Creating Layer relu3
I1010 14:43:31.858305  5944 net.cpp:434] relu3 <- conv3
I1010 14:43:31.858309  5944 net.cpp:395] relu3 -> conv3 (in-place)
I1010 14:43:31.858552  5944 net.cpp:150] Setting up relu3
I1010 14:43:31.858559  5944 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1010 14:43:31.858561  5944 net.cpp:165] Memory required for data: 130401024
I1010 14:43:31.858563  5944 layer_factory.hpp:77] Creating layer conv4
I1010 14:43:31.858569  5944 net.cpp:100] Creating Layer conv4
I1010 14:43:31.858572  5944 net.cpp:434] conv4 <- conv3
I1010 14:43:31.858574  5944 net.cpp:408] conv4 -> conv4
I1010 14:43:31.860389  5944 net.cpp:150] Setting up conv4
I1010 14:43:31.860399  5944 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1010 14:43:31.860401  5944 net.cpp:165] Memory required for data: 136348416
I1010 14:43:31.860405  5944 layer_factory.hpp:77] Creating layer relu4
I1010 14:43:31.860409  5944 net.cpp:100] Creating Layer relu4
I1010 14:43:31.860411  5944 net.cpp:434] relu4 <- conv4
I1010 14:43:31.860414  5944 net.cpp:395] relu4 -> conv4 (in-place)
I1010 14:43:31.860580  5944 net.cpp:150] Setting up relu4
I1010 14:43:31.860585  5944 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1010 14:43:31.860587  5944 net.cpp:165] Memory required for data: 142295808
I1010 14:43:31.860590  5944 layer_factory.hpp:77] Creating layer conv5
I1010 14:43:31.860595  5944 net.cpp:100] Creating Layer conv5
I1010 14:43:31.860597  5944 net.cpp:434] conv5 <- conv4
I1010 14:43:31.860600  5944 net.cpp:408] conv5 -> conv5
I1010 14:43:31.863098  5944 net.cpp:150] Setting up conv5
I1010 14:43:31.863109  5944 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1010 14:43:31.863112  5944 net.cpp:165] Memory required for data: 146277120
I1010 14:43:31.863117  5944 layer_factory.hpp:77] Creating layer bn2
I1010 14:43:31.863121  5944 net.cpp:100] Creating Layer bn2
I1010 14:43:31.863123  5944 net.cpp:434] bn2 <- conv5
I1010 14:43:31.863127  5944 net.cpp:408] bn2 -> bn2
I1010 14:43:31.863327  5944 net.cpp:150] Setting up bn2
I1010 14:43:31.863332  5944 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1010 14:43:31.863333  5944 net.cpp:165] Memory required for data: 150258432
I1010 14:43:31.863338  5944 layer_factory.hpp:77] Creating layer relu5
I1010 14:43:31.863342  5944 net.cpp:100] Creating Layer relu5
I1010 14:43:31.863343  5944 net.cpp:434] relu5 <- bn2
I1010 14:43:31.863346  5944 net.cpp:395] relu5 -> bn2 (in-place)
I1010 14:43:31.863526  5944 net.cpp:150] Setting up relu5
I1010 14:43:31.863533  5944 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1010 14:43:31.863535  5944 net.cpp:165] Memory required for data: 154239744
I1010 14:43:31.863538  5944 layer_factory.hpp:77] Creating layer drop4
I1010 14:43:31.863540  5944 net.cpp:100] Creating Layer drop4
I1010 14:43:31.863543  5944 net.cpp:434] drop4 <- bn2
I1010 14:43:31.863546  5944 net.cpp:408] drop4 -> drop4
I1010 14:43:31.863587  5944 net.cpp:150] Setting up drop4
I1010 14:43:31.863592  5944 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1010 14:43:31.863616  5944 net.cpp:165] Memory required for data: 158221056
I1010 14:43:31.863620  5944 layer_factory.hpp:77] Creating layer conv6
I1010 14:43:31.863638  5944 net.cpp:100] Creating Layer conv6
I1010 14:43:31.863641  5944 net.cpp:434] conv6 <- drop4
I1010 14:43:31.863644  5944 net.cpp:408] conv6 -> conv6
I1010 14:43:31.866227  5944 net.cpp:150] Setting up conv6
I1010 14:43:31.866240  5944 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1010 14:43:31.866242  5944 net.cpp:165] Memory required for data: 159007488
I1010 14:43:31.866267  5944 layer_factory.hpp:77] Creating layer relu6
I1010 14:43:31.866273  5944 net.cpp:100] Creating Layer relu6
I1010 14:43:31.866276  5944 net.cpp:434] relu6 <- conv6
I1010 14:43:31.866279  5944 net.cpp:395] relu6 -> conv6 (in-place)
I1010 14:43:31.866549  5944 net.cpp:150] Setting up relu6
I1010 14:43:31.866556  5944 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1010 14:43:31.866559  5944 net.cpp:165] Memory required for data: 159793920
I1010 14:43:31.866561  5944 layer_factory.hpp:77] Creating layer conv7
I1010 14:43:31.866582  5944 net.cpp:100] Creating Layer conv7
I1010 14:43:31.866585  5944 net.cpp:434] conv7 <- conv6
I1010 14:43:31.866588  5944 net.cpp:408] conv7 -> conv7
I1010 14:43:31.869597  5944 net.cpp:150] Setting up conv7
I1010 14:43:31.869613  5944 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1010 14:43:31.869616  5944 net.cpp:165] Memory required for data: 159990528
I1010 14:43:31.869621  5944 layer_factory.hpp:77] Creating layer relu7
I1010 14:43:31.869626  5944 net.cpp:100] Creating Layer relu7
I1010 14:43:31.869629  5944 net.cpp:434] relu7 <- conv7
I1010 14:43:31.869633  5944 net.cpp:395] relu7 -> conv7 (in-place)
I1010 14:43:31.869886  5944 net.cpp:150] Setting up relu7
I1010 14:43:31.869894  5944 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1010 14:43:31.869896  5944 net.cpp:165] Memory required for data: 160187136
I1010 14:43:31.869899  5944 layer_factory.hpp:77] Creating layer conv8
I1010 14:43:31.869905  5944 net.cpp:100] Creating Layer conv8
I1010 14:43:31.869907  5944 net.cpp:434] conv8 <- conv7
I1010 14:43:31.869912  5944 net.cpp:408] conv8 -> conv8
I1010 14:43:31.871166  5944 net.cpp:150] Setting up conv8
I1010 14:43:31.871176  5944 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1010 14:43:31.871177  5944 net.cpp:165] Memory required for data: 160383744
I1010 14:43:31.871182  5944 layer_factory.hpp:77] Creating layer relu8
I1010 14:43:31.871186  5944 net.cpp:100] Creating Layer relu8
I1010 14:43:31.871188  5944 net.cpp:434] relu8 <- conv8
I1010 14:43:31.871191  5944 net.cpp:395] relu8 -> conv8 (in-place)
I1010 14:43:31.871361  5944 net.cpp:150] Setting up relu8
I1010 14:43:31.871366  5944 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1010 14:43:31.871368  5944 net.cpp:165] Memory required for data: 160580352
I1010 14:43:31.871371  5944 layer_factory.hpp:77] Creating layer conv9
I1010 14:43:31.871376  5944 net.cpp:100] Creating Layer conv9
I1010 14:43:31.871378  5944 net.cpp:434] conv9 <- conv8
I1010 14:43:31.871382  5944 net.cpp:408] conv9 -> conv9
I1010 14:43:31.872195  5944 net.cpp:150] Setting up conv9
I1010 14:43:31.872205  5944 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1010 14:43:31.872206  5944 net.cpp:165] Memory required for data: 160590592
I1010 14:43:31.872210  5944 layer_factory.hpp:77] Creating layer relu9
I1010 14:43:31.872213  5944 net.cpp:100] Creating Layer relu9
I1010 14:43:31.872215  5944 net.cpp:434] relu9 <- conv9
I1010 14:43:31.872220  5944 net.cpp:395] relu9 -> conv9 (in-place)
I1010 14:43:31.872473  5944 net.cpp:150] Setting up relu9
I1010 14:43:31.872479  5944 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1010 14:43:31.872481  5944 net.cpp:165] Memory required for data: 160600832
I1010 14:43:31.872483  5944 layer_factory.hpp:77] Creating layer pool
I1010 14:43:31.872488  5944 net.cpp:100] Creating Layer pool
I1010 14:43:31.872491  5944 net.cpp:434] pool <- conv9
I1010 14:43:31.872494  5944 net.cpp:408] pool -> pool
I1010 14:43:31.872685  5944 net.cpp:150] Setting up pool
I1010 14:43:31.872691  5944 net.cpp:157] Top shape: 64 10 1 1 (640)
I1010 14:43:31.872704  5944 net.cpp:165] Memory required for data: 160603392
I1010 14:43:31.872706  5944 layer_factory.hpp:77] Creating layer flatten
I1010 14:43:31.872710  5944 net.cpp:100] Creating Layer flatten
I1010 14:43:31.872712  5944 net.cpp:434] flatten <- pool
I1010 14:43:31.872715  5944 net.cpp:408] flatten -> flatten
I1010 14:43:31.872750  5944 net.cpp:150] Setting up flatten
I1010 14:43:31.872755  5944 net.cpp:157] Top shape: 64 10 (640)
I1010 14:43:31.872756  5944 net.cpp:165] Memory required for data: 160605952
I1010 14:43:31.872758  5944 layer_factory.hpp:77] Creating layer score
I1010 14:43:31.872777  5944 net.cpp:100] Creating Layer score
I1010 14:43:31.872781  5944 net.cpp:434] score <- flatten
I1010 14:43:31.872783  5944 net.cpp:408] score -> score
I1010 14:43:31.872936  5944 net.cpp:150] Setting up score
I1010 14:43:31.872941  5944 net.cpp:157] Top shape: 64 10 (640)
I1010 14:43:31.872943  5944 net.cpp:165] Memory required for data: 160608512
I1010 14:43:31.872947  5944 layer_factory.hpp:77] Creating layer score_score_0_split
I1010 14:43:31.872951  5944 net.cpp:100] Creating Layer score_score_0_split
I1010 14:43:31.872953  5944 net.cpp:434] score_score_0_split <- score
I1010 14:43:31.872956  5944 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1010 14:43:31.872984  5944 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1010 14:43:31.873040  5944 net.cpp:150] Setting up score_score_0_split
I1010 14:43:31.873044  5944 net.cpp:157] Top shape: 64 10 (640)
I1010 14:43:31.873046  5944 net.cpp:157] Top shape: 64 10 (640)
I1010 14:43:31.873049  5944 net.cpp:165] Memory required for data: 160613632
I1010 14:43:31.873064  5944 layer_factory.hpp:77] Creating layer accuracy
I1010 14:43:31.873069  5944 net.cpp:100] Creating Layer accuracy
I1010 14:43:31.873070  5944 net.cpp:434] accuracy <- score_score_0_split_0
I1010 14:43:31.873086  5944 net.cpp:434] accuracy <- label_data_1_split_0
I1010 14:43:31.873090  5944 net.cpp:408] accuracy -> accuracy
I1010 14:43:31.873095  5944 net.cpp:150] Setting up accuracy
I1010 14:43:31.873111  5944 net.cpp:157] Top shape: (1)
I1010 14:43:31.873112  5944 net.cpp:165] Memory required for data: 160613636
I1010 14:43:31.873114  5944 layer_factory.hpp:77] Creating layer loss
I1010 14:43:31.873119  5944 net.cpp:100] Creating Layer loss
I1010 14:43:31.873121  5944 net.cpp:434] loss <- score_score_0_split_1
I1010 14:43:31.873123  5944 net.cpp:434] loss <- label_data_1_split_1
I1010 14:43:31.873126  5944 net.cpp:408] loss -> loss
I1010 14:43:31.873147  5944 layer_factory.hpp:77] Creating layer loss
I1010 14:43:31.873488  5944 net.cpp:150] Setting up loss
I1010 14:43:31.873495  5944 net.cpp:157] Top shape: (1)
I1010 14:43:31.873497  5944 net.cpp:160]     with loss weight 1
I1010 14:43:31.873510  5944 net.cpp:165] Memory required for data: 160613640
I1010 14:43:31.873512  5944 net.cpp:226] loss needs backward computation.
I1010 14:43:31.873517  5944 net.cpp:228] accuracy does not need backward computation.
I1010 14:43:31.873520  5944 net.cpp:226] score_score_0_split needs backward computation.
I1010 14:43:31.873522  5944 net.cpp:226] score needs backward computation.
I1010 14:43:31.873524  5944 net.cpp:226] flatten needs backward computation.
I1010 14:43:31.873527  5944 net.cpp:226] pool needs backward computation.
I1010 14:43:31.873528  5944 net.cpp:226] relu9 needs backward computation.
I1010 14:43:31.873544  5944 net.cpp:226] conv9 needs backward computation.
I1010 14:43:31.873546  5944 net.cpp:226] relu8 needs backward computation.
I1010 14:43:31.873548  5944 net.cpp:226] conv8 needs backward computation.
I1010 14:43:31.873549  5944 net.cpp:226] relu7 needs backward computation.
I1010 14:43:31.873551  5944 net.cpp:226] conv7 needs backward computation.
I1010 14:43:31.873553  5944 net.cpp:226] relu6 needs backward computation.
I1010 14:43:31.873555  5944 net.cpp:226] conv6 needs backward computation.
I1010 14:43:31.873558  5944 net.cpp:226] drop4 needs backward computation.
I1010 14:43:31.873574  5944 net.cpp:226] relu5 needs backward computation.
I1010 14:43:31.873575  5944 net.cpp:226] bn2 needs backward computation.
I1010 14:43:31.873600  5944 net.cpp:226] conv5 needs backward computation.
I1010 14:43:31.873605  5944 net.cpp:226] relu4 needs backward computation.
I1010 14:43:31.873620  5944 net.cpp:226] conv4 needs backward computation.
I1010 14:43:31.873621  5944 net.cpp:226] relu3 needs backward computation.
I1010 14:43:31.873623  5944 net.cpp:226] conv3 needs backward computation.
I1010 14:43:31.873625  5944 net.cpp:226] drop1 needs backward computation.
I1010 14:43:31.873643  5944 net.cpp:226] relu2 needs backward computation.
I1010 14:43:31.873646  5944 net.cpp:226] bn1 needs backward computation.
I1010 14:43:31.873648  5944 net.cpp:226] conv2 needs backward computation.
I1010 14:43:31.873651  5944 net.cpp:226] relu1 needs backward computation.
I1010 14:43:31.873652  5944 net.cpp:226] conv1 needs backward computation.
I1010 14:43:31.873656  5944 net.cpp:228] label_data_1_split does not need backward computation.
I1010 14:43:31.873670  5944 net.cpp:228] data does not need backward computation.
I1010 14:43:31.873672  5944 net.cpp:270] This network produces output accuracy
I1010 14:43:31.873675  5944 net.cpp:270] This network produces output loss
I1010 14:43:31.873704  5944 net.cpp:283] Network initialization done.
I1010 14:43:31.873940  5944 solver.cpp:181] Creating test net (#0) specified by test_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt
I1010 14:43:31.874084  5944 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn1"
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn1"
  top: "bn1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "bn1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "drop1"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv5"
  top: "bn2"
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "bn2"
  top: "bn2"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "bn2"
  top: "drop4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "drop4"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "flatten"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1010 14:43:31.874186  5944 layer_factory.hpp:77] Creating layer data
I1010 14:43:31.874297  5944 net.cpp:100] Creating Layer data
I1010 14:43:31.874303  5944 net.cpp:408] data -> data
I1010 14:43:31.874310  5944 net.cpp:408] data -> label
I1010 14:43:31.874316  5944 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1010 14:43:31.875072  5951 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_test_lmdb
I1010 14:43:31.875196  5944 data_layer.cpp:41] output data size: 100,3,32,32
I1010 14:43:31.877198  5944 net.cpp:150] Setting up data
I1010 14:43:31.877238  5944 net.cpp:157] Top shape: 100 3 32 32 (307200)
I1010 14:43:31.877241  5944 net.cpp:157] Top shape: 100 (100)
I1010 14:43:31.877243  5944 net.cpp:165] Memory required for data: 1229200
I1010 14:43:31.877248  5944 layer_factory.hpp:77] Creating layer label_data_1_split
I1010 14:43:31.877256  5944 net.cpp:100] Creating Layer label_data_1_split
I1010 14:43:31.877260  5944 net.cpp:434] label_data_1_split <- label
I1010 14:43:31.877280  5944 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1010 14:43:31.877300  5944 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1010 14:43:31.877373  5944 net.cpp:150] Setting up label_data_1_split
I1010 14:43:31.877378  5944 net.cpp:157] Top shape: 100 (100)
I1010 14:43:31.877382  5944 net.cpp:157] Top shape: 100 (100)
I1010 14:43:31.877382  5944 net.cpp:165] Memory required for data: 1230000
I1010 14:43:31.877384  5944 layer_factory.hpp:77] Creating layer conv1
I1010 14:43:31.877393  5944 net.cpp:100] Creating Layer conv1
I1010 14:43:31.877395  5944 net.cpp:434] conv1 <- data
I1010 14:43:31.877399  5944 net.cpp:408] conv1 -> conv1
I1010 14:43:31.878434  5944 net.cpp:150] Setting up conv1
I1010 14:43:31.878463  5944 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1010 14:43:31.878464  5944 net.cpp:165] Memory required for data: 35790000
I1010 14:43:31.878473  5944 layer_factory.hpp:77] Creating layer relu1
I1010 14:43:31.878476  5944 net.cpp:100] Creating Layer relu1
I1010 14:43:31.878479  5944 net.cpp:434] relu1 <- conv1
I1010 14:43:31.878499  5944 net.cpp:395] relu1 -> conv1 (in-place)
I1010 14:43:31.878764  5944 net.cpp:150] Setting up relu1
I1010 14:43:31.878785  5944 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1010 14:43:31.878787  5944 net.cpp:165] Memory required for data: 70350000
I1010 14:43:31.878789  5944 layer_factory.hpp:77] Creating layer conv2
I1010 14:43:31.878811  5944 net.cpp:100] Creating Layer conv2
I1010 14:43:31.878814  5944 net.cpp:434] conv2 <- conv1
I1010 14:43:31.878818  5944 net.cpp:408] conv2 -> conv2
I1010 14:43:31.880208  5944 net.cpp:150] Setting up conv2
I1010 14:43:31.880231  5944 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1010 14:43:31.880234  5944 net.cpp:165] Memory required for data: 100455600
I1010 14:43:31.880240  5944 layer_factory.hpp:77] Creating layer bn1
I1010 14:43:31.880246  5944 net.cpp:100] Creating Layer bn1
I1010 14:43:31.880249  5944 net.cpp:434] bn1 <- conv2
I1010 14:43:31.880264  5944 net.cpp:408] bn1 -> bn1
I1010 14:43:31.880466  5944 net.cpp:150] Setting up bn1
I1010 14:43:31.880473  5944 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1010 14:43:31.880475  5944 net.cpp:165] Memory required for data: 130561200
I1010 14:43:31.880482  5944 layer_factory.hpp:77] Creating layer relu2
I1010 14:43:31.880486  5944 net.cpp:100] Creating Layer relu2
I1010 14:43:31.880489  5944 net.cpp:434] relu2 <- bn1
I1010 14:43:31.880507  5944 net.cpp:395] relu2 -> bn1 (in-place)
I1010 14:43:31.880758  5944 net.cpp:150] Setting up relu2
I1010 14:43:31.880766  5944 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1010 14:43:31.880769  5944 net.cpp:165] Memory required for data: 160666800
I1010 14:43:31.880771  5944 layer_factory.hpp:77] Creating layer drop1
I1010 14:43:31.880776  5944 net.cpp:100] Creating Layer drop1
I1010 14:43:31.880780  5944 net.cpp:434] drop1 <- bn1
I1010 14:43:31.880784  5944 net.cpp:408] drop1 -> drop1
I1010 14:43:31.880834  5944 net.cpp:150] Setting up drop1
I1010 14:43:31.880839  5944 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1010 14:43:31.880841  5944 net.cpp:165] Memory required for data: 190772400
I1010 14:43:31.880843  5944 layer_factory.hpp:77] Creating layer conv3
I1010 14:43:31.880851  5944 net.cpp:100] Creating Layer conv3
I1010 14:43:31.880854  5944 net.cpp:434] conv3 <- drop1
I1010 14:43:31.880857  5944 net.cpp:408] conv3 -> conv3
I1010 14:43:31.881986  5944 net.cpp:150] Setting up conv3
I1010 14:43:31.881997  5944 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1010 14:43:31.881999  5944 net.cpp:165] Memory required for data: 197262000
I1010 14:43:31.882007  5944 layer_factory.hpp:77] Creating layer relu3
I1010 14:43:31.882011  5944 net.cpp:100] Creating Layer relu3
I1010 14:43:31.882014  5944 net.cpp:434] relu3 <- conv3
I1010 14:43:31.882019  5944 net.cpp:395] relu3 -> conv3 (in-place)
I1010 14:43:31.882259  5944 net.cpp:150] Setting up relu3
I1010 14:43:31.882267  5944 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1010 14:43:31.882269  5944 net.cpp:165] Memory required for data: 203751600
I1010 14:43:31.882272  5944 layer_factory.hpp:77] Creating layer conv4
I1010 14:43:31.882278  5944 net.cpp:100] Creating Layer conv4
I1010 14:43:31.882282  5944 net.cpp:434] conv4 <- conv3
I1010 14:43:31.882285  5944 net.cpp:408] conv4 -> conv4
I1010 14:43:31.885380  5944 net.cpp:150] Setting up conv4
I1010 14:43:31.885393  5944 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1010 14:43:31.885396  5944 net.cpp:165] Memory required for data: 213044400
I1010 14:43:31.885401  5944 layer_factory.hpp:77] Creating layer relu4
I1010 14:43:31.885406  5944 net.cpp:100] Creating Layer relu4
I1010 14:43:31.885409  5944 net.cpp:434] relu4 <- conv4
I1010 14:43:31.885428  5944 net.cpp:395] relu4 -> conv4 (in-place)
I1010 14:43:31.885608  5944 net.cpp:150] Setting up relu4
I1010 14:43:31.885615  5944 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1010 14:43:31.885617  5944 net.cpp:165] Memory required for data: 222337200
I1010 14:43:31.885622  5944 layer_factory.hpp:77] Creating layer conv5
I1010 14:43:31.885627  5944 net.cpp:100] Creating Layer conv5
I1010 14:43:31.885644  5944 net.cpp:434] conv5 <- conv4
I1010 14:43:31.885649  5944 net.cpp:408] conv5 -> conv5
I1010 14:43:31.888380  5944 net.cpp:150] Setting up conv5
I1010 14:43:31.888391  5944 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1010 14:43:31.888392  5944 net.cpp:165] Memory required for data: 228558000
I1010 14:43:31.888397  5944 layer_factory.hpp:77] Creating layer bn2
I1010 14:43:31.888402  5944 net.cpp:100] Creating Layer bn2
I1010 14:43:31.888404  5944 net.cpp:434] bn2 <- conv5
I1010 14:43:31.888408  5944 net.cpp:408] bn2 -> bn2
I1010 14:43:31.888617  5944 net.cpp:150] Setting up bn2
I1010 14:43:31.888622  5944 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1010 14:43:31.888624  5944 net.cpp:165] Memory required for data: 234778800
I1010 14:43:31.888628  5944 layer_factory.hpp:77] Creating layer relu5
I1010 14:43:31.888633  5944 net.cpp:100] Creating Layer relu5
I1010 14:43:31.888634  5944 net.cpp:434] relu5 <- bn2
I1010 14:43:31.888648  5944 net.cpp:395] relu5 -> bn2 (in-place)
I1010 14:43:31.888924  5944 net.cpp:150] Setting up relu5
I1010 14:43:31.888937  5944 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1010 14:43:31.888941  5944 net.cpp:165] Memory required for data: 240999600
I1010 14:43:31.888942  5944 layer_factory.hpp:77] Creating layer drop4
I1010 14:43:31.888947  5944 net.cpp:100] Creating Layer drop4
I1010 14:43:31.888962  5944 net.cpp:434] drop4 <- bn2
I1010 14:43:31.888967  5944 net.cpp:408] drop4 -> drop4
I1010 14:43:31.889044  5944 net.cpp:150] Setting up drop4
I1010 14:43:31.889050  5944 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1010 14:43:31.889063  5944 net.cpp:165] Memory required for data: 247220400
I1010 14:43:31.889065  5944 layer_factory.hpp:77] Creating layer conv6
I1010 14:43:31.889088  5944 net.cpp:100] Creating Layer conv6
I1010 14:43:31.889091  5944 net.cpp:434] conv6 <- drop4
I1010 14:43:31.889093  5944 net.cpp:408] conv6 -> conv6
I1010 14:43:31.891585  5944 net.cpp:150] Setting up conv6
I1010 14:43:31.891595  5944 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1010 14:43:31.891598  5944 net.cpp:165] Memory required for data: 248449200
I1010 14:43:31.891607  5944 layer_factory.hpp:77] Creating layer relu6
I1010 14:43:31.891610  5944 net.cpp:100] Creating Layer relu6
I1010 14:43:31.891613  5944 net.cpp:434] relu6 <- conv6
I1010 14:43:31.891616  5944 net.cpp:395] relu6 -> conv6 (in-place)
I1010 14:43:31.891875  5944 net.cpp:150] Setting up relu6
I1010 14:43:31.891882  5944 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1010 14:43:31.891885  5944 net.cpp:165] Memory required for data: 249678000
I1010 14:43:31.891886  5944 layer_factory.hpp:77] Creating layer conv7
I1010 14:43:31.891893  5944 net.cpp:100] Creating Layer conv7
I1010 14:43:31.891896  5944 net.cpp:434] conv7 <- conv6
I1010 14:43:31.891899  5944 net.cpp:408] conv7 -> conv7
I1010 14:43:31.894516  5944 net.cpp:150] Setting up conv7
I1010 14:43:31.894527  5944 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1010 14:43:31.894529  5944 net.cpp:165] Memory required for data: 249985200
I1010 14:43:31.894534  5944 layer_factory.hpp:77] Creating layer relu7
I1010 14:43:31.894538  5944 net.cpp:100] Creating Layer relu7
I1010 14:43:31.894541  5944 net.cpp:434] relu7 <- conv7
I1010 14:43:31.894544  5944 net.cpp:395] relu7 -> conv7 (in-place)
I1010 14:43:31.894712  5944 net.cpp:150] Setting up relu7
I1010 14:43:31.894718  5944 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1010 14:43:31.894721  5944 net.cpp:165] Memory required for data: 250292400
I1010 14:43:31.894722  5944 layer_factory.hpp:77] Creating layer conv8
I1010 14:43:31.894729  5944 net.cpp:100] Creating Layer conv8
I1010 14:43:31.894731  5944 net.cpp:434] conv8 <- conv7
I1010 14:43:31.894736  5944 net.cpp:408] conv8 -> conv8
I1010 14:43:31.895707  5944 net.cpp:150] Setting up conv8
I1010 14:43:31.895716  5944 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1010 14:43:31.895720  5944 net.cpp:165] Memory required for data: 250599600
I1010 14:43:31.895723  5944 layer_factory.hpp:77] Creating layer relu8
I1010 14:43:31.895726  5944 net.cpp:100] Creating Layer relu8
I1010 14:43:31.895728  5944 net.cpp:434] relu8 <- conv8
I1010 14:43:31.895732  5944 net.cpp:395] relu8 -> conv8 (in-place)
I1010 14:43:31.895988  5944 net.cpp:150] Setting up relu8
I1010 14:43:31.895997  5944 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1010 14:43:31.895998  5944 net.cpp:165] Memory required for data: 250906800
I1010 14:43:31.896000  5944 layer_factory.hpp:77] Creating layer conv9
I1010 14:43:31.896005  5944 net.cpp:100] Creating Layer conv9
I1010 14:43:31.896008  5944 net.cpp:434] conv9 <- conv8
I1010 14:43:31.896011  5944 net.cpp:408] conv9 -> conv9
I1010 14:43:31.896754  5944 net.cpp:150] Setting up conv9
I1010 14:43:31.896762  5944 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1010 14:43:31.896764  5944 net.cpp:165] Memory required for data: 250922800
I1010 14:43:31.896769  5944 layer_factory.hpp:77] Creating layer relu9
I1010 14:43:31.896772  5944 net.cpp:100] Creating Layer relu9
I1010 14:43:31.896775  5944 net.cpp:434] relu9 <- conv9
I1010 14:43:31.896786  5944 net.cpp:395] relu9 -> conv9 (in-place)
I1010 14:43:31.897088  5944 net.cpp:150] Setting up relu9
I1010 14:43:31.897095  5944 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1010 14:43:31.897097  5944 net.cpp:165] Memory required for data: 250938800
I1010 14:43:31.897099  5944 layer_factory.hpp:77] Creating layer pool
I1010 14:43:31.897104  5944 net.cpp:100] Creating Layer pool
I1010 14:43:31.897106  5944 net.cpp:434] pool <- conv9
I1010 14:43:31.897109  5944 net.cpp:408] pool -> pool
I1010 14:43:31.897294  5944 net.cpp:150] Setting up pool
I1010 14:43:31.897300  5944 net.cpp:157] Top shape: 100 10 1 1 (1000)
I1010 14:43:31.897302  5944 net.cpp:165] Memory required for data: 250942800
I1010 14:43:31.897305  5944 layer_factory.hpp:77] Creating layer flatten
I1010 14:43:31.897308  5944 net.cpp:100] Creating Layer flatten
I1010 14:43:31.897310  5944 net.cpp:434] flatten <- pool
I1010 14:43:31.897315  5944 net.cpp:408] flatten -> flatten
I1010 14:43:31.897333  5944 net.cpp:150] Setting up flatten
I1010 14:43:31.897351  5944 net.cpp:157] Top shape: 100 10 (1000)
I1010 14:43:31.897353  5944 net.cpp:165] Memory required for data: 250946800
I1010 14:43:31.897356  5944 layer_factory.hpp:77] Creating layer score
I1010 14:43:31.897373  5944 net.cpp:100] Creating Layer score
I1010 14:43:31.897375  5944 net.cpp:434] score <- flatten
I1010 14:43:31.897378  5944 net.cpp:408] score -> score
I1010 14:43:31.897547  5944 net.cpp:150] Setting up score
I1010 14:43:31.897552  5944 net.cpp:157] Top shape: 100 10 (1000)
I1010 14:43:31.897553  5944 net.cpp:165] Memory required for data: 250950800
I1010 14:43:31.897557  5944 layer_factory.hpp:77] Creating layer score_score_0_split
I1010 14:43:31.897562  5944 net.cpp:100] Creating Layer score_score_0_split
I1010 14:43:31.897563  5944 net.cpp:434] score_score_0_split <- score
I1010 14:43:31.897567  5944 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1010 14:43:31.897570  5944 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1010 14:43:31.897614  5944 net.cpp:150] Setting up score_score_0_split
I1010 14:43:31.897619  5944 net.cpp:157] Top shape: 100 10 (1000)
I1010 14:43:31.897620  5944 net.cpp:157] Top shape: 100 10 (1000)
I1010 14:43:31.897622  5944 net.cpp:165] Memory required for data: 250958800
I1010 14:43:31.897639  5944 layer_factory.hpp:77] Creating layer accuracy
I1010 14:43:31.897641  5944 net.cpp:100] Creating Layer accuracy
I1010 14:43:31.897644  5944 net.cpp:434] accuracy <- score_score_0_split_0
I1010 14:43:31.897660  5944 net.cpp:434] accuracy <- label_data_1_split_0
I1010 14:43:31.897663  5944 net.cpp:408] accuracy -> accuracy
I1010 14:43:31.897683  5944 net.cpp:150] Setting up accuracy
I1010 14:43:31.897686  5944 net.cpp:157] Top shape: (1)
I1010 14:43:31.897687  5944 net.cpp:165] Memory required for data: 250958804
I1010 14:43:31.897689  5944 layer_factory.hpp:77] Creating layer loss
I1010 14:43:31.897692  5944 net.cpp:100] Creating Layer loss
I1010 14:43:31.897694  5944 net.cpp:434] loss <- score_score_0_split_1
I1010 14:43:31.897697  5944 net.cpp:434] loss <- label_data_1_split_1
I1010 14:43:31.897701  5944 net.cpp:408] loss -> loss
I1010 14:43:31.897721  5944 layer_factory.hpp:77] Creating layer loss
I1010 14:43:31.898066  5944 net.cpp:150] Setting up loss
I1010 14:43:31.898073  5944 net.cpp:157] Top shape: (1)
I1010 14:43:31.898075  5944 net.cpp:160]     with loss weight 1
I1010 14:43:31.898082  5944 net.cpp:165] Memory required for data: 250958808
I1010 14:43:31.898084  5944 net.cpp:226] loss needs backward computation.
I1010 14:43:31.898087  5944 net.cpp:228] accuracy does not need backward computation.
I1010 14:43:31.898090  5944 net.cpp:226] score_score_0_split needs backward computation.
I1010 14:43:31.898092  5944 net.cpp:226] score needs backward computation.
I1010 14:43:31.898094  5944 net.cpp:226] flatten needs backward computation.
I1010 14:43:31.898097  5944 net.cpp:226] pool needs backward computation.
I1010 14:43:31.898098  5944 net.cpp:226] relu9 needs backward computation.
I1010 14:43:31.898100  5944 net.cpp:226] conv9 needs backward computation.
I1010 14:43:31.898123  5944 net.cpp:226] relu8 needs backward computation.
I1010 14:43:31.898125  5944 net.cpp:226] conv8 needs backward computation.
I1010 14:43:31.898126  5944 net.cpp:226] relu7 needs backward computation.
I1010 14:43:31.898129  5944 net.cpp:226] conv7 needs backward computation.
I1010 14:43:31.898131  5944 net.cpp:226] relu6 needs backward computation.
I1010 14:43:31.898133  5944 net.cpp:226] conv6 needs backward computation.
I1010 14:43:31.898136  5944 net.cpp:226] drop4 needs backward computation.
I1010 14:43:31.898138  5944 net.cpp:226] relu5 needs backward computation.
I1010 14:43:31.898140  5944 net.cpp:226] bn2 needs backward computation.
I1010 14:43:31.898156  5944 net.cpp:226] conv5 needs backward computation.
I1010 14:43:31.898159  5944 net.cpp:226] relu4 needs backward computation.
I1010 14:43:31.898160  5944 net.cpp:226] conv4 needs backward computation.
I1010 14:43:31.898164  5944 net.cpp:226] relu3 needs backward computation.
I1010 14:43:31.898165  5944 net.cpp:226] conv3 needs backward computation.
I1010 14:43:31.898180  5944 net.cpp:226] drop1 needs backward computation.
I1010 14:43:31.898182  5944 net.cpp:226] relu2 needs backward computation.
I1010 14:43:31.898185  5944 net.cpp:226] bn1 needs backward computation.
I1010 14:43:31.898187  5944 net.cpp:226] conv2 needs backward computation.
I1010 14:43:31.898190  5944 net.cpp:226] relu1 needs backward computation.
I1010 14:43:31.898191  5944 net.cpp:226] conv1 needs backward computation.
I1010 14:43:31.898193  5944 net.cpp:228] label_data_1_split does not need backward computation.
I1010 14:43:31.898197  5944 net.cpp:228] data does not need backward computation.
I1010 14:43:31.898198  5944 net.cpp:270] This network produces output accuracy
I1010 14:43:31.898201  5944 net.cpp:270] This network produces output loss
I1010 14:43:31.898216  5944 net.cpp:283] Network initialization done.
I1010 14:43:31.898295  5944 solver.cpp:60] Solver scaffolding done.
I1010 14:43:31.899132  5944 caffe.cpp:251] Starting Optimization
I1010 14:43:31.899137  5944 solver.cpp:279] Solving 
I1010 14:43:31.899153  5944 solver.cpp:280] Learning Rate Policy: step
I1010 14:43:31.900099  5944 solver.cpp:337] Iteration 0, Testing net (#0)
I1010 14:43:35.419896  5944 solver.cpp:404]     Test net output #0: accuracy = 0.0872
I1010 14:43:35.419919  5944 solver.cpp:404]     Test net output #1: loss = 79.7208 (* 1 = 79.7208 loss)
I1010 14:43:35.461318  5944 solver.cpp:228] Iteration 0, loss = 2.36047
I1010 14:43:35.461340  5944 solver.cpp:244]     Train net output #0: accuracy = 0.09375
I1010 14:43:35.461347  5944 solver.cpp:244]     Train net output #1: loss = 2.36047 (* 1 = 2.36047 loss)
I1010 14:43:35.461355  5944 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I1010 14:43:39.619709  5944 solver.cpp:228] Iteration 50, loss = 2.29217
I1010 14:43:39.619743  5944 solver.cpp:244]     Train net output #0: accuracy = 0.140625
I1010 14:43:39.619750  5944 solver.cpp:244]     Train net output #1: loss = 2.29217 (* 1 = 2.29217 loss)
I1010 14:43:39.619755  5944 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
I1010 14:43:43.774420  5944 solver.cpp:228] Iteration 100, loss = 2.30117
I1010 14:43:43.774438  5944 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1010 14:43:43.774446  5944 solver.cpp:244]     Train net output #1: loss = 2.30117 (* 1 = 2.30117 loss)
I1010 14:43:43.774448  5944 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I1010 14:43:47.934860  5944 solver.cpp:228] Iteration 150, loss = 2.28002
I1010 14:43:47.934880  5944 solver.cpp:244]     Train net output #0: accuracy = 0.125
I1010 14:43:47.934886  5944 solver.cpp:244]     Train net output #1: loss = 2.28002 (* 1 = 2.28002 loss)
I1010 14:43:47.934890  5944 sgd_solver.cpp:106] Iteration 150, lr = 0.0001
I1010 14:43:52.092533  5944 solver.cpp:228] Iteration 200, loss = 2.33279
I1010 14:43:52.092552  5944 solver.cpp:244]     Train net output #0: accuracy = 0.125
I1010 14:43:52.092572  5944 solver.cpp:244]     Train net output #1: loss = 2.33279 (* 1 = 2.33279 loss)
I1010 14:43:52.092594  5944 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I1010 14:43:56.222218  5944 solver.cpp:337] Iteration 250, Testing net (#0)
I1010 14:43:59.732029  5944 solver.cpp:404]     Test net output #0: accuracy = 0.1254
I1010 14:43:59.732051  5944 solver.cpp:404]     Test net output #1: loss = 2.28773 (* 1 = 2.28773 loss)
I1010 14:43:59.761669  5944 solver.cpp:228] Iteration 250, loss = 2.30488
I1010 14:43:59.761689  5944 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1010 14:43:59.761696  5944 solver.cpp:244]     Train net output #1: loss = 2.30488 (* 1 = 2.30488 loss)
I1010 14:43:59.761700  5944 sgd_solver.cpp:106] Iteration 250, lr = 0.0001
I1010 14:44:03.923421  5944 solver.cpp:228] Iteration 300, loss = 2.25797
I1010 14:44:03.923557  5944 solver.cpp:244]     Train net output #0: accuracy = 0.15625
I1010 14:44:03.923578  5944 solver.cpp:244]     Train net output #1: loss = 2.25797 (* 1 = 2.25797 loss)
I1010 14:44:03.923596  5944 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I1010 14:44:08.084022  5944 solver.cpp:228] Iteration 350, loss = 2.27421
I1010 14:44:08.084040  5944 solver.cpp:244]     Train net output #0: accuracy = 0.078125
I1010 14:44:08.084061  5944 solver.cpp:244]     Train net output #1: loss = 2.27421 (* 1 = 2.27421 loss)
I1010 14:44:08.084065  5944 sgd_solver.cpp:106] Iteration 350, lr = 0.0001
I1010 14:44:12.242776  5944 solver.cpp:228] Iteration 400, loss = 2.31796
I1010 14:44:12.242795  5944 solver.cpp:244]     Train net output #0: accuracy = 0.140625
I1010 14:44:12.242816  5944 solver.cpp:244]     Train net output #1: loss = 2.31796 (* 1 = 2.31796 loss)
I1010 14:44:12.242820  5944 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I1010 14:44:16.402138  5944 solver.cpp:228] Iteration 450, loss = 2.26518
I1010 14:44:16.402158  5944 solver.cpp:244]     Train net output #0: accuracy = 0.140625
I1010 14:44:16.402164  5944 solver.cpp:244]     Train net output #1: loss = 2.26518 (* 1 = 2.26518 loss)
I1010 14:44:16.402168  5944 sgd_solver.cpp:106] Iteration 450, lr = 0.0001
I1010 14:44:20.531332  5944 solver.cpp:337] Iteration 500, Testing net (#0)
I1010 14:44:24.042855  5944 solver.cpp:404]     Test net output #0: accuracy = 0.1394
I1010 14:44:24.042876  5944 solver.cpp:404]     Test net output #1: loss = 2.26321 (* 1 = 2.26321 loss)
I1010 14:44:24.072685  5944 solver.cpp:228] Iteration 500, loss = 2.27108
I1010 14:44:24.072705  5944 solver.cpp:244]     Train net output #0: accuracy = 0.125
I1010 14:44:24.072711  5944 solver.cpp:244]     Train net output #1: loss = 2.27108 (* 1 = 2.27108 loss)
I1010 14:44:24.072716  5944 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I1010 14:44:28.234073  5944 solver.cpp:228] Iteration 550, loss = 2.27514
I1010 14:44:28.234113  5944 solver.cpp:244]     Train net output #0: accuracy = 0.140625
I1010 14:44:28.234120  5944 solver.cpp:244]     Train net output #1: loss = 2.27514 (* 1 = 2.27514 loss)
I1010 14:44:28.234138  5944 sgd_solver.cpp:106] Iteration 550, lr = 0.0001
I1010 14:44:32.390960  5944 solver.cpp:228] Iteration 600, loss = 2.26601
I1010 14:44:32.390980  5944 solver.cpp:244]     Train net output #0: accuracy = 0.140625
I1010 14:44:32.390985  5944 solver.cpp:244]     Train net output #1: loss = 2.26601 (* 1 = 2.26601 loss)
I1010 14:44:32.390990  5944 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I1010 14:44:36.551400  5944 solver.cpp:228] Iteration 650, loss = 2.24704
I1010 14:44:36.551440  5944 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1010 14:44:36.551463  5944 solver.cpp:244]     Train net output #1: loss = 2.24704 (* 1 = 2.24704 loss)
I1010 14:44:36.551481  5944 sgd_solver.cpp:106] Iteration 650, lr = 0.0001
I1010 14:44:40.710549  5944 solver.cpp:228] Iteration 700, loss = 2.1927
I1010 14:44:40.710571  5944 solver.cpp:244]     Train net output #0: accuracy = 0.21875
I1010 14:44:40.710577  5944 solver.cpp:244]     Train net output #1: loss = 2.1927 (* 1 = 2.1927 loss)
I1010 14:44:40.710580  5944 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I1010 14:44:44.841696  5944 solver.cpp:337] Iteration 750, Testing net (#0)
I1010 14:44:48.353539  5944 solver.cpp:404]     Test net output #0: accuracy = 0.178
I1010 14:44:48.353575  5944 solver.cpp:404]     Test net output #1: loss = 2.22476 (* 1 = 2.22476 loss)
I1010 14:44:48.383438  5944 solver.cpp:228] Iteration 750, loss = 2.2551
I1010 14:44:48.383458  5944 solver.cpp:244]     Train net output #0: accuracy = 0.140625
I1010 14:44:48.383466  5944 solver.cpp:244]     Train net output #1: loss = 2.2551 (* 1 = 2.2551 loss)
I1010 14:44:48.383469  5944 sgd_solver.cpp:106] Iteration 750, lr = 0.0001
I1010 14:44:52.541026  5944 solver.cpp:228] Iteration 800, loss = 2.27246
I1010 14:44:52.541046  5944 solver.cpp:244]     Train net output #0: accuracy = 0.078125
I1010 14:44:52.541067  5944 solver.cpp:244]     Train net output #1: loss = 2.27246 (* 1 = 2.27246 loss)
I1010 14:44:52.541085  5944 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I1010 14:44:56.698982  5944 solver.cpp:228] Iteration 850, loss = 2.20803
I1010 14:44:56.699002  5944 solver.cpp:244]     Train net output #0: accuracy = 0.171875
I1010 14:44:56.699008  5944 solver.cpp:244]     Train net output #1: loss = 2.20803 (* 1 = 2.20803 loss)
I1010 14:44:56.699026  5944 sgd_solver.cpp:106] Iteration 850, lr = 0.0001
I1010 14:45:00.856616  5944 solver.cpp:228] Iteration 900, loss = 2.28222
I1010 14:45:00.856634  5944 solver.cpp:244]     Train net output #0: accuracy = 0.125
I1010 14:45:00.856642  5944 solver.cpp:244]     Train net output #1: loss = 2.28222 (* 1 = 2.28222 loss)
I1010 14:45:00.856645  5944 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I1010 14:45:05.016333  5944 solver.cpp:228] Iteration 950, loss = 2.23765
I1010 14:45:05.016352  5944 solver.cpp:244]     Train net output #0: accuracy = 0.15625
I1010 14:45:05.016358  5944 solver.cpp:244]     Train net output #1: loss = 2.23765 (* 1 = 2.23765 loss)
I1010 14:45:05.016361  5944 sgd_solver.cpp:106] Iteration 950, lr = 0.0001
I1010 14:45:09.145623  5944 solver.cpp:337] Iteration 1000, Testing net (#0)
I1010 14:45:12.659198  5944 solver.cpp:404]     Test net output #0: accuracy = 0.2028
I1010 14:45:12.659219  5944 solver.cpp:404]     Test net output #1: loss = 2.19046 (* 1 = 2.19046 loss)
I1010 14:45:12.689144  5944 solver.cpp:228] Iteration 1000, loss = 2.15675
I1010 14:45:12.689164  5944 solver.cpp:244]     Train net output #0: accuracy = 0.21875
I1010 14:45:12.689172  5944 solver.cpp:244]     Train net output #1: loss = 2.15675 (* 1 = 2.15675 loss)
I1010 14:45:12.689175  5944 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I1010 14:45:16.849912  5944 solver.cpp:228] Iteration 1050, loss = 2.27009
I1010 14:45:16.849933  5944 solver.cpp:244]     Train net output #0: accuracy = 0.140625
I1010 14:45:16.849941  5944 solver.cpp:244]     Train net output #1: loss = 2.27009 (* 1 = 2.27009 loss)
I1010 14:45:16.849959  5944 sgd_solver.cpp:106] Iteration 1050, lr = 0.0001
I1010 14:45:21.009883  5944 solver.cpp:228] Iteration 1100, loss = 2.23142
I1010 14:45:21.009902  5944 solver.cpp:244]     Train net output #0: accuracy = 0.171875
I1010 14:45:21.009909  5944 solver.cpp:244]     Train net output #1: loss = 2.23142 (* 1 = 2.23142 loss)
I1010 14:45:21.009913  5944 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I1010 14:45:25.167392  5944 solver.cpp:228] Iteration 1150, loss = 2.14657
I1010 14:45:25.167412  5944 solver.cpp:244]     Train net output #0: accuracy = 0.21875
I1010 14:45:25.167433  5944 solver.cpp:244]     Train net output #1: loss = 2.14657 (* 1 = 2.14657 loss)
I1010 14:45:25.167436  5944 sgd_solver.cpp:106] Iteration 1150, lr = 0.0001
I1010 14:45:29.326858  5944 solver.cpp:228] Iteration 1200, loss = 2.18039
I1010 14:45:29.326892  5944 solver.cpp:244]     Train net output #0: accuracy = 0.15625
I1010 14:45:29.326900  5944 solver.cpp:244]     Train net output #1: loss = 2.18039 (* 1 = 2.18039 loss)
I1010 14:45:29.326916  5944 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I1010 14:45:33.457022  5944 solver.cpp:337] Iteration 1250, Testing net (#0)
I1010 14:45:36.967717  5944 solver.cpp:404]     Test net output #0: accuracy = 0.1997
I1010 14:45:36.967752  5944 solver.cpp:404]     Test net output #1: loss = 2.1775 (* 1 = 2.1775 loss)
I1010 14:45:36.997544  5944 solver.cpp:228] Iteration 1250, loss = 2.16463
I1010 14:45:36.997562  5944 solver.cpp:244]     Train net output #0: accuracy = 0.234375
I1010 14:45:36.997568  5944 solver.cpp:244]     Train net output #1: loss = 2.16463 (* 1 = 2.16463 loss)
I1010 14:45:36.997572  5944 sgd_solver.cpp:106] Iteration 1250, lr = 0.0001
I1010 14:45:41.158737  5944 solver.cpp:228] Iteration 1300, loss = 2.08177
I1010 14:45:41.158823  5944 solver.cpp:244]     Train net output #0: accuracy = 0.203125
I1010 14:45:41.158845  5944 solver.cpp:244]     Train net output #1: loss = 2.08177 (* 1 = 2.08177 loss)
I1010 14:45:41.158864  5944 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I1010 14:45:45.315783  5944 solver.cpp:228] Iteration 1350, loss = 2.17138
I1010 14:45:45.315816  5944 solver.cpp:244]     Train net output #0: accuracy = 0.1875
I1010 14:45:45.315822  5944 solver.cpp:244]     Train net output #1: loss = 2.17138 (* 1 = 2.17138 loss)
I1010 14:45:45.315840  5944 sgd_solver.cpp:106] Iteration 1350, lr = 0.0001
I1010 14:45:49.476644  5944 solver.cpp:228] Iteration 1400, loss = 2.19956
I1010 14:45:49.476665  5944 solver.cpp:244]     Train net output #0: accuracy = 0.171875
I1010 14:45:49.476673  5944 solver.cpp:244]     Train net output #1: loss = 2.19956 (* 1 = 2.19956 loss)
I1010 14:45:49.476677  5944 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I1010 14:45:53.634531  5944 solver.cpp:228] Iteration 1450, loss = 2.19823
I1010 14:45:53.634552  5944 solver.cpp:244]     Train net output #0: accuracy = 0.15625
I1010 14:45:53.634558  5944 solver.cpp:244]     Train net output #1: loss = 2.19823 (* 1 = 2.19823 loss)
I1010 14:45:53.634562  5944 sgd_solver.cpp:106] Iteration 1450, lr = 0.0001
I1010 14:45:57.764169  5944 solver.cpp:337] Iteration 1500, Testing net (#0)
I1010 14:46:01.277066  5944 solver.cpp:404]     Test net output #0: accuracy = 0.2029
I1010 14:46:01.277101  5944 solver.cpp:404]     Test net output #1: loss = 2.16281 (* 1 = 2.16281 loss)
I1010 14:46:01.308323  5944 solver.cpp:228] Iteration 1500, loss = 2.22031
I1010 14:46:01.308360  5944 solver.cpp:244]     Train net output #0: accuracy = 0.125
I1010 14:46:01.308367  5944 solver.cpp:244]     Train net output #1: loss = 2.22031 (* 1 = 2.22031 loss)
I1010 14:46:01.308372  5944 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I1010 14:46:05.465737  5944 solver.cpp:228] Iteration 1550, loss = 2.08293
I1010 14:46:05.465771  5944 solver.cpp:244]     Train net output #0: accuracy = 0.296875
I1010 14:46:05.465778  5944 solver.cpp:244]     Train net output #1: loss = 2.08293 (* 1 = 2.08293 loss)
I1010 14:46:05.465782  5944 sgd_solver.cpp:106] Iteration 1550, lr = 0.0001
I1010 14:46:09.624272  5944 solver.cpp:228] Iteration 1600, loss = 2.18147
I1010 14:46:09.624292  5944 solver.cpp:244]     Train net output #0: accuracy = 0.234375
I1010 14:46:09.624300  5944 solver.cpp:244]     Train net output #1: loss = 2.18147 (* 1 = 2.18147 loss)
I1010 14:46:09.624317  5944 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I1010 14:46:13.790518  5944 solver.cpp:228] Iteration 1650, loss = 2.22557
I1010 14:46:13.790570  5944 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1010 14:46:13.790580  5944 solver.cpp:244]     Train net output #1: loss = 2.22557 (* 1 = 2.22557 loss)
I1010 14:46:13.790585  5944 sgd_solver.cpp:106] Iteration 1650, lr = 0.0001
I1010 14:46:18.000646  5944 solver.cpp:228] Iteration 1700, loss = 2.11781
I1010 14:46:18.000668  5944 solver.cpp:244]     Train net output #0: accuracy = 0.1875
I1010 14:46:18.000674  5944 solver.cpp:244]     Train net output #1: loss = 2.11781 (* 1 = 2.11781 loss)
I1010 14:46:18.000694  5944 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I1010 14:46:22.163198  5944 solver.cpp:337] Iteration 1750, Testing net (#0)
I1010 14:46:25.736369  5944 solver.cpp:404]     Test net output #0: accuracy = 0.212
I1010 14:46:25.736439  5944 solver.cpp:404]     Test net output #1: loss = 2.13687 (* 1 = 2.13687 loss)
I1010 14:46:25.769695  5944 solver.cpp:228] Iteration 1750, loss = 2.04117
I1010 14:46:25.769744  5944 solver.cpp:244]     Train net output #0: accuracy = 0.203125
I1010 14:46:25.769759  5944 solver.cpp:244]     Train net output #1: loss = 2.04117 (* 1 = 2.04117 loss)
I1010 14:46:25.769771  5944 sgd_solver.cpp:106] Iteration 1750, lr = 0.0001
I1010 14:46:30.423897  5944 solver.cpp:228] Iteration 1800, loss = 1.99328
I1010 14:46:30.423921  5944 solver.cpp:244]     Train net output #0: accuracy = 0.21875
I1010 14:46:30.423928  5944 solver.cpp:244]     Train net output #1: loss = 1.99328 (* 1 = 1.99328 loss)
I1010 14:46:30.423933  5944 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I1010 14:46:34.955646  5944 solver.cpp:228] Iteration 1850, loss = 2.03184
I1010 14:46:34.955678  5944 solver.cpp:244]     Train net output #0: accuracy = 0.265625
I1010 14:46:34.955687  5944 solver.cpp:244]     Train net output #1: loss = 2.03184 (* 1 = 2.03184 loss)
I1010 14:46:34.955690  5944 sgd_solver.cpp:106] Iteration 1850, lr = 0.0001
I1010 14:46:39.158282  5944 solver.cpp:228] Iteration 1900, loss = 2.02548
I1010 14:46:39.158316  5944 solver.cpp:244]     Train net output #0: accuracy = 0.296875
I1010 14:46:39.158324  5944 solver.cpp:244]     Train net output #1: loss = 2.02548 (* 1 = 2.02548 loss)
I1010 14:46:39.158327  5944 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I1010 14:46:43.311758  5944 solver.cpp:228] Iteration 1950, loss = 2.12338
I1010 14:46:43.311784  5944 solver.cpp:244]     Train net output #0: accuracy = 0.203125
I1010 14:46:43.311789  5944 solver.cpp:244]     Train net output #1: loss = 2.12338 (* 1 = 2.12338 loss)
I1010 14:46:43.311794  5944 sgd_solver.cpp:106] Iteration 1950, lr = 0.0001
I1010 14:46:47.529315  5944 solver.cpp:337] Iteration 2000, Testing net (#0)
I1010 14:46:51.081960  5944 solver.cpp:404]     Test net output #0: accuracy = 0.2155
I1010 14:46:51.081984  5944 solver.cpp:404]     Test net output #1: loss = 2.11028 (* 1 = 2.11028 loss)
I1010 14:46:51.111346  5944 solver.cpp:228] Iteration 2000, loss = 2.08627
I1010 14:46:51.111367  5944 solver.cpp:244]     Train net output #0: accuracy = 0.265625
I1010 14:46:51.111376  5944 solver.cpp:244]     Train net output #1: loss = 2.08627 (* 1 = 2.08627 loss)
I1010 14:46:51.111379  5944 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I1010 14:46:55.305665  5944 solver.cpp:228] Iteration 2050, loss = 2.11572
I1010 14:46:55.305686  5944 solver.cpp:244]     Train net output #0: accuracy = 0.328125
I1010 14:46:55.305693  5944 solver.cpp:244]     Train net output #1: loss = 2.11572 (* 1 = 2.11572 loss)
I1010 14:46:55.305697  5944 sgd_solver.cpp:106] Iteration 2050, lr = 0.0001
I1010 14:46:59.506233  5944 solver.cpp:228] Iteration 2100, loss = 2.04533
I1010 14:46:59.506255  5944 solver.cpp:244]     Train net output #0: accuracy = 0.296875
I1010 14:46:59.506263  5944 solver.cpp:244]     Train net output #1: loss = 2.04533 (* 1 = 2.04533 loss)
I1010 14:46:59.506266  5944 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I1010 14:47:03.746120  5944 solver.cpp:228] Iteration 2150, loss = 1.92349
I1010 14:47:03.746140  5944 solver.cpp:244]     Train net output #0: accuracy = 0.25
I1010 14:47:03.746148  5944 solver.cpp:244]     Train net output #1: loss = 1.92349 (* 1 = 1.92349 loss)
I1010 14:47:03.746167  5944 sgd_solver.cpp:106] Iteration 2150, lr = 0.0001
I1010 14:47:07.898109  5944 solver.cpp:228] Iteration 2200, loss = 1.95262
I1010 14:47:07.898144  5944 solver.cpp:244]     Train net output #0: accuracy = 0.234375
I1010 14:47:07.898151  5944 solver.cpp:244]     Train net output #1: loss = 1.95262 (* 1 = 1.95262 loss)
I1010 14:47:07.898157  5944 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I1010 14:47:12.108491  5944 solver.cpp:337] Iteration 2250, Testing net (#0)
I1010 14:47:15.652714  5944 solver.cpp:404]     Test net output #0: accuracy = 0.2273
I1010 14:47:15.652736  5944 solver.cpp:404]     Test net output #1: loss = 2.08061 (* 1 = 2.08061 loss)
I1010 14:47:15.682066  5944 solver.cpp:228] Iteration 2250, loss = 2.05608
I1010 14:47:15.682086  5944 solver.cpp:244]     Train net output #0: accuracy = 0.25
I1010 14:47:15.682093  5944 solver.cpp:244]     Train net output #1: loss = 2.05608 (* 1 = 2.05608 loss)
I1010 14:47:15.682097  5944 sgd_solver.cpp:106] Iteration 2250, lr = 0.0001
I1010 14:47:19.833221  5944 solver.cpp:228] Iteration 2300, loss = 1.99995
I1010 14:47:19.833348  5944 solver.cpp:244]     Train net output #0: accuracy = 0.296875
I1010 14:47:19.833371  5944 solver.cpp:244]     Train net output #1: loss = 1.99995 (* 1 = 1.99995 loss)
I1010 14:47:19.833389  5944 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I1010 14:47:24.038411  5944 solver.cpp:228] Iteration 2350, loss = 2.07041
I1010 14:47:24.038434  5944 solver.cpp:244]     Train net output #0: accuracy = 0.203125
I1010 14:47:24.038440  5944 solver.cpp:244]     Train net output #1: loss = 2.07041 (* 1 = 2.07041 loss)
I1010 14:47:24.038444  5944 sgd_solver.cpp:106] Iteration 2350, lr = 0.0001
I1010 14:47:28.236665  5944 solver.cpp:228] Iteration 2400, loss = 2.14105
I1010 14:47:28.236685  5944 solver.cpp:244]     Train net output #0: accuracy = 0.21875
I1010 14:47:28.236691  5944 solver.cpp:244]     Train net output #1: loss = 2.14105 (* 1 = 2.14105 loss)
I1010 14:47:28.236696  5944 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I1010 14:47:32.394961  5944 solver.cpp:228] Iteration 2450, loss = 1.9764
I1010 14:47:32.394981  5944 solver.cpp:244]     Train net output #0: accuracy = 0.296875
I1010 14:47:32.394989  5944 solver.cpp:244]     Train net output #1: loss = 1.9764 (* 1 = 1.9764 loss)
I1010 14:47:32.394991  5944 sgd_solver.cpp:106] Iteration 2450, lr = 0.0001
I1010 14:47:36.635776  5944 solver.cpp:454] Snapshotting to binary proto file cifar-10_relu_Nesterov_iter_2500.caffemodel
I1010 14:47:36.651847  5944 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_relu_Nesterov_iter_2500.solverstate
I1010 14:47:36.688757  5944 solver.cpp:317] Iteration 2500, loss = 2.02149
I1010 14:47:36.688778  5944 solver.cpp:337] Iteration 2500, Testing net (#0)
I1010 14:47:40.285230  5944 solver.cpp:404]     Test net output #0: accuracy = 0.2522
I1010 14:47:40.285269  5944 solver.cpp:404]     Test net output #1: loss = 2.00619 (* 1 = 2.00619 loss)
I1010 14:47:40.285272  5944 solver.cpp:322] Optimization Done.
I1010 14:47:40.285274  5944 caffe.cpp:254] Optimization Done.
