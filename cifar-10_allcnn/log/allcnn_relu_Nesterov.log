I1009 20:08:09.941058  7800 caffe.cpp:217] Using GPUs 0
I1009 20:08:09.943763  7800 caffe.cpp:222] GPU 0: GeForce GTX 750 Ti
I1009 20:08:10.052479  7800 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt"
test_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt"
test_iter: 100
test_interval: 25
base_lr: 0.001
display: 50
max_iter: 250
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 5000
snapshot: 5000
snapshot_prefix: "cifar-10_relu_Nesterov"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
type: "Nesterov"
I1009 20:08:10.052620  7800 solver.cpp:81] Creating training net from train_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt
I1009 20:08:10.052949  7800 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1009 20:08:10.053083  7800 layer_factory.hpp:77] Creating layer data
I1009 20:08:10.053509  7800 net.cpp:100] Creating Layer data
I1009 20:08:10.053517  7800 net.cpp:408] data -> data
I1009 20:08:10.053555  7800 net.cpp:408] data -> label
I1009 20:08:10.053565  7800 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1009 20:08:10.054234  7805 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_train_lmdb
I1009 20:08:10.060506  7800 data_layer.cpp:41] output data size: 64,3,32,32
I1009 20:08:10.062011  7800 net.cpp:150] Setting up data
I1009 20:08:10.062026  7800 net.cpp:157] Top shape: 64 3 32 32 (196608)
I1009 20:08:10.062029  7800 net.cpp:157] Top shape: 64 (64)
I1009 20:08:10.062054  7800 net.cpp:165] Memory required for data: 786688
I1009 20:08:10.062062  7800 layer_factory.hpp:77] Creating layer label_data_1_split
I1009 20:08:10.062073  7800 net.cpp:100] Creating Layer label_data_1_split
I1009 20:08:10.062077  7800 net.cpp:434] label_data_1_split <- label
I1009 20:08:10.062116  7800 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1009 20:08:10.062139  7800 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1009 20:08:10.062214  7800 net.cpp:150] Setting up label_data_1_split
I1009 20:08:10.062237  7800 net.cpp:157] Top shape: 64 (64)
I1009 20:08:10.062238  7800 net.cpp:157] Top shape: 64 (64)
I1009 20:08:10.062240  7800 net.cpp:165] Memory required for data: 787200
I1009 20:08:10.062243  7800 layer_factory.hpp:77] Creating layer conv1
I1009 20:08:10.062280  7800 net.cpp:100] Creating Layer conv1
I1009 20:08:10.062284  7800 net.cpp:434] conv1 <- data
I1009 20:08:10.062301  7800 net.cpp:408] conv1 -> conv1
I1009 20:08:10.201194  7800 net.cpp:150] Setting up conv1
I1009 20:08:10.201216  7800 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1009 20:08:10.201220  7800 net.cpp:165] Memory required for data: 22905600
I1009 20:08:10.201236  7800 layer_factory.hpp:77] Creating layer relu1
I1009 20:08:10.201243  7800 net.cpp:100] Creating Layer relu1
I1009 20:08:10.201246  7800 net.cpp:434] relu1 <- conv1
I1009 20:08:10.201251  7800 net.cpp:395] relu1 -> conv1 (in-place)
I1009 20:08:10.201437  7800 net.cpp:150] Setting up relu1
I1009 20:08:10.201444  7800 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1009 20:08:10.201447  7800 net.cpp:165] Memory required for data: 45024000
I1009 20:08:10.201448  7800 layer_factory.hpp:77] Creating layer conv2
I1009 20:08:10.201457  7800 net.cpp:100] Creating Layer conv2
I1009 20:08:10.201459  7800 net.cpp:434] conv2 <- conv1
I1009 20:08:10.201463  7800 net.cpp:408] conv2 -> conv2
I1009 20:08:10.202859  7800 net.cpp:150] Setting up conv2
I1009 20:08:10.202869  7800 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1009 20:08:10.202872  7800 net.cpp:165] Memory required for data: 64291584
I1009 20:08:10.202878  7800 layer_factory.hpp:77] Creating layer relu2
I1009 20:08:10.202883  7800 net.cpp:100] Creating Layer relu2
I1009 20:08:10.202885  7800 net.cpp:434] relu2 <- conv2
I1009 20:08:10.202888  7800 net.cpp:395] relu2 -> conv2 (in-place)
I1009 20:08:10.203042  7800 net.cpp:150] Setting up relu2
I1009 20:08:10.203048  7800 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1009 20:08:10.203050  7800 net.cpp:165] Memory required for data: 83559168
I1009 20:08:10.203052  7800 layer_factory.hpp:77] Creating layer conv3
I1009 20:08:10.203058  7800 net.cpp:100] Creating Layer conv3
I1009 20:08:10.203060  7800 net.cpp:434] conv3 <- conv2
I1009 20:08:10.203064  7800 net.cpp:408] conv3 -> conv3
I1009 20:08:10.204200  7800 net.cpp:150] Setting up conv3
I1009 20:08:10.204208  7800 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1009 20:08:10.204210  7800 net.cpp:165] Memory required for data: 87712512
I1009 20:08:10.204217  7800 layer_factory.hpp:77] Creating layer relu3
I1009 20:08:10.204221  7800 net.cpp:100] Creating Layer relu3
I1009 20:08:10.204223  7800 net.cpp:434] relu3 <- conv3
I1009 20:08:10.204226  7800 net.cpp:395] relu3 -> conv3 (in-place)
I1009 20:08:10.204481  7800 net.cpp:150] Setting up relu3
I1009 20:08:10.204489  7800 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1009 20:08:10.204502  7800 net.cpp:165] Memory required for data: 91865856
I1009 20:08:10.204505  7800 layer_factory.hpp:77] Creating layer conv4
I1009 20:08:10.204511  7800 net.cpp:100] Creating Layer conv4
I1009 20:08:10.204514  7800 net.cpp:434] conv4 <- conv3
I1009 20:08:10.204519  7800 net.cpp:408] conv4 -> conv4
I1009 20:08:10.206308  7800 net.cpp:150] Setting up conv4
I1009 20:08:10.206318  7800 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1009 20:08:10.206321  7800 net.cpp:165] Memory required for data: 97813248
I1009 20:08:10.206326  7800 layer_factory.hpp:77] Creating layer relu4
I1009 20:08:10.206329  7800 net.cpp:100] Creating Layer relu4
I1009 20:08:10.206331  7800 net.cpp:434] relu4 <- conv4
I1009 20:08:10.206336  7800 net.cpp:395] relu4 -> conv4 (in-place)
I1009 20:08:10.206517  7800 net.cpp:150] Setting up relu4
I1009 20:08:10.206523  7800 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1009 20:08:10.206526  7800 net.cpp:165] Memory required for data: 103760640
I1009 20:08:10.206527  7800 layer_factory.hpp:77] Creating layer conv5
I1009 20:08:10.206533  7800 net.cpp:100] Creating Layer conv5
I1009 20:08:10.206535  7800 net.cpp:434] conv5 <- conv4
I1009 20:08:10.206538  7800 net.cpp:408] conv5 -> conv5
I1009 20:08:10.209019  7800 net.cpp:150] Setting up conv5
I1009 20:08:10.209030  7800 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1009 20:08:10.209033  7800 net.cpp:165] Memory required for data: 107741952
I1009 20:08:10.209039  7800 layer_factory.hpp:77] Creating layer relu5
I1009 20:08:10.209044  7800 net.cpp:100] Creating Layer relu5
I1009 20:08:10.209046  7800 net.cpp:434] relu5 <- conv5
I1009 20:08:10.209050  7800 net.cpp:395] relu5 -> conv5 (in-place)
I1009 20:08:10.209208  7800 net.cpp:150] Setting up relu5
I1009 20:08:10.209214  7800 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1009 20:08:10.209216  7800 net.cpp:165] Memory required for data: 111723264
I1009 20:08:10.209218  7800 layer_factory.hpp:77] Creating layer conv6
I1009 20:08:10.209224  7800 net.cpp:100] Creating Layer conv6
I1009 20:08:10.209228  7800 net.cpp:434] conv6 <- conv5
I1009 20:08:10.209230  7800 net.cpp:408] conv6 -> conv6
I1009 20:08:10.211735  7800 net.cpp:150] Setting up conv6
I1009 20:08:10.211746  7800 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1009 20:08:10.211750  7800 net.cpp:165] Memory required for data: 112509696
I1009 20:08:10.211768  7800 layer_factory.hpp:77] Creating layer relu6
I1009 20:08:10.211773  7800 net.cpp:100] Creating Layer relu6
I1009 20:08:10.211776  7800 net.cpp:434] relu6 <- conv6
I1009 20:08:10.211779  7800 net.cpp:395] relu6 -> conv6 (in-place)
I1009 20:08:10.212021  7800 net.cpp:150] Setting up relu6
I1009 20:08:10.212029  7800 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1009 20:08:10.212031  7800 net.cpp:165] Memory required for data: 113296128
I1009 20:08:10.212034  7800 layer_factory.hpp:77] Creating layer conv7
I1009 20:08:10.212054  7800 net.cpp:100] Creating Layer conv7
I1009 20:08:10.212057  7800 net.cpp:434] conv7 <- conv6
I1009 20:08:10.212061  7800 net.cpp:408] conv7 -> conv7
I1009 20:08:10.215096  7800 net.cpp:150] Setting up conv7
I1009 20:08:10.215113  7800 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:08:10.215116  7800 net.cpp:165] Memory required for data: 113492736
I1009 20:08:10.215122  7800 layer_factory.hpp:77] Creating layer relu7
I1009 20:08:10.215127  7800 net.cpp:100] Creating Layer relu7
I1009 20:08:10.215131  7800 net.cpp:434] relu7 <- conv7
I1009 20:08:10.215134  7800 net.cpp:395] relu7 -> conv7 (in-place)
I1009 20:08:10.215376  7800 net.cpp:150] Setting up relu7
I1009 20:08:10.215384  7800 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:08:10.215386  7800 net.cpp:165] Memory required for data: 113689344
I1009 20:08:10.215389  7800 layer_factory.hpp:77] Creating layer conv8
I1009 20:08:10.215399  7800 net.cpp:100] Creating Layer conv8
I1009 20:08:10.215400  7800 net.cpp:434] conv8 <- conv7
I1009 20:08:10.215404  7800 net.cpp:408] conv8 -> conv8
I1009 20:08:10.216595  7800 net.cpp:150] Setting up conv8
I1009 20:08:10.216605  7800 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:08:10.216619  7800 net.cpp:165] Memory required for data: 113885952
I1009 20:08:10.216624  7800 layer_factory.hpp:77] Creating layer relu8
I1009 20:08:10.216629  7800 net.cpp:100] Creating Layer relu8
I1009 20:08:10.216630  7800 net.cpp:434] relu8 <- conv8
I1009 20:08:10.216634  7800 net.cpp:395] relu8 -> conv8 (in-place)
I1009 20:08:10.216809  7800 net.cpp:150] Setting up relu8
I1009 20:08:10.216814  7800 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:08:10.217077  7800 net.cpp:165] Memory required for data: 114082560
I1009 20:08:10.217079  7800 layer_factory.hpp:77] Creating layer conv9
I1009 20:08:10.217085  7800 net.cpp:100] Creating Layer conv9
I1009 20:08:10.217088  7800 net.cpp:434] conv9 <- conv8
I1009 20:08:10.217092  7800 net.cpp:408] conv9 -> conv9
I1009 20:08:10.217883  7800 net.cpp:150] Setting up conv9
I1009 20:08:10.217892  7800 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1009 20:08:10.217895  7800 net.cpp:165] Memory required for data: 114092800
I1009 20:08:10.217902  7800 layer_factory.hpp:77] Creating layer relu9
I1009 20:08:10.217907  7800 net.cpp:100] Creating Layer relu9
I1009 20:08:10.217910  7800 net.cpp:434] relu9 <- conv9
I1009 20:08:10.217912  7800 net.cpp:395] relu9 -> conv9 (in-place)
I1009 20:08:10.218168  7800 net.cpp:150] Setting up relu9
I1009 20:08:10.218174  7800 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1009 20:08:10.218178  7800 net.cpp:165] Memory required for data: 114103040
I1009 20:08:10.218179  7800 layer_factory.hpp:77] Creating layer pool
I1009 20:08:10.218183  7800 net.cpp:100] Creating Layer pool
I1009 20:08:10.218186  7800 net.cpp:434] pool <- conv9
I1009 20:08:10.218189  7800 net.cpp:408] pool -> pool
I1009 20:08:10.218382  7800 net.cpp:150] Setting up pool
I1009 20:08:10.218389  7800 net.cpp:157] Top shape: 64 10 1 1 (640)
I1009 20:08:10.218391  7800 net.cpp:165] Memory required for data: 114105600
I1009 20:08:10.218394  7800 layer_factory.hpp:77] Creating layer score
I1009 20:08:10.218397  7800 net.cpp:100] Creating Layer score
I1009 20:08:10.218400  7800 net.cpp:434] score <- pool
I1009 20:08:10.218403  7800 net.cpp:408] score -> score
I1009 20:08:10.218542  7800 net.cpp:150] Setting up score
I1009 20:08:10.218546  7800 net.cpp:157] Top shape: 64 10 (640)
I1009 20:08:10.218549  7800 net.cpp:165] Memory required for data: 114108160
I1009 20:08:10.218554  7800 layer_factory.hpp:77] Creating layer score_score_0_split
I1009 20:08:10.218556  7800 net.cpp:100] Creating Layer score_score_0_split
I1009 20:08:10.218559  7800 net.cpp:434] score_score_0_split <- score
I1009 20:08:10.218562  7800 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1009 20:08:10.218566  7800 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1009 20:08:10.218611  7800 net.cpp:150] Setting up score_score_0_split
I1009 20:08:10.218616  7800 net.cpp:157] Top shape: 64 10 (640)
I1009 20:08:10.218631  7800 net.cpp:157] Top shape: 64 10 (640)
I1009 20:08:10.218632  7800 net.cpp:165] Memory required for data: 114113280
I1009 20:08:10.218634  7800 layer_factory.hpp:77] Creating layer accuracy
I1009 20:08:10.218655  7800 net.cpp:100] Creating Layer accuracy
I1009 20:08:10.218657  7800 net.cpp:434] accuracy <- score_score_0_split_0
I1009 20:08:10.218662  7800 net.cpp:434] accuracy <- label_data_1_split_0
I1009 20:08:10.218677  7800 net.cpp:408] accuracy -> accuracy
I1009 20:08:10.218683  7800 net.cpp:150] Setting up accuracy
I1009 20:08:10.218685  7800 net.cpp:157] Top shape: (1)
I1009 20:08:10.218688  7800 net.cpp:165] Memory required for data: 114113284
I1009 20:08:10.218689  7800 layer_factory.hpp:77] Creating layer loss
I1009 20:08:10.218693  7800 net.cpp:100] Creating Layer loss
I1009 20:08:10.218713  7800 net.cpp:434] loss <- score_score_0_split_1
I1009 20:08:10.218715  7800 net.cpp:434] loss <- label_data_1_split_1
I1009 20:08:10.218735  7800 net.cpp:408] loss -> loss
I1009 20:08:10.218756  7800 layer_factory.hpp:77] Creating layer loss
I1009 20:08:10.219061  7800 net.cpp:150] Setting up loss
I1009 20:08:10.219069  7800 net.cpp:157] Top shape: (1)
I1009 20:08:10.219079  7800 net.cpp:160]     with loss weight 1
I1009 20:08:10.219092  7800 net.cpp:165] Memory required for data: 114113288
I1009 20:08:10.219094  7800 net.cpp:226] loss needs backward computation.
I1009 20:08:10.219100  7800 net.cpp:228] accuracy does not need backward computation.
I1009 20:08:10.219102  7800 net.cpp:226] score_score_0_split needs backward computation.
I1009 20:08:10.219105  7800 net.cpp:226] score needs backward computation.
I1009 20:08:10.219107  7800 net.cpp:226] pool needs backward computation.
I1009 20:08:10.219125  7800 net.cpp:226] relu9 needs backward computation.
I1009 20:08:10.219126  7800 net.cpp:226] conv9 needs backward computation.
I1009 20:08:10.219128  7800 net.cpp:226] relu8 needs backward computation.
I1009 20:08:10.219130  7800 net.cpp:226] conv8 needs backward computation.
I1009 20:08:10.219132  7800 net.cpp:226] relu7 needs backward computation.
I1009 20:08:10.219135  7800 net.cpp:226] conv7 needs backward computation.
I1009 20:08:10.219136  7800 net.cpp:226] relu6 needs backward computation.
I1009 20:08:10.219138  7800 net.cpp:226] conv6 needs backward computation.
I1009 20:08:10.219141  7800 net.cpp:226] relu5 needs backward computation.
I1009 20:08:10.219157  7800 net.cpp:226] conv5 needs backward computation.
I1009 20:08:10.219161  7800 net.cpp:226] relu4 needs backward computation.
I1009 20:08:10.219162  7800 net.cpp:226] conv4 needs backward computation.
I1009 20:08:10.219164  7800 net.cpp:226] relu3 needs backward computation.
I1009 20:08:10.219179  7800 net.cpp:226] conv3 needs backward computation.
I1009 20:08:10.219182  7800 net.cpp:226] relu2 needs backward computation.
I1009 20:08:10.219184  7800 net.cpp:226] conv2 needs backward computation.
I1009 20:08:10.219187  7800 net.cpp:226] relu1 needs backward computation.
I1009 20:08:10.219202  7800 net.cpp:226] conv1 needs backward computation.
I1009 20:08:10.219205  7800 net.cpp:228] label_data_1_split does not need backward computation.
I1009 20:08:10.219208  7800 net.cpp:228] data does not need backward computation.
I1009 20:08:10.219210  7800 net.cpp:270] This network produces output accuracy
I1009 20:08:10.219213  7800 net.cpp:270] This network produces output loss
I1009 20:08:10.219224  7800 net.cpp:283] Network initialization done.
I1009 20:08:10.219411  7800 solver.cpp:181] Creating test net (#0) specified by test_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt
I1009 20:08:10.219552  7800 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1009 20:08:10.219667  7800 layer_factory.hpp:77] Creating layer data
I1009 20:08:10.219760  7800 net.cpp:100] Creating Layer data
I1009 20:08:10.219766  7800 net.cpp:408] data -> data
I1009 20:08:10.219772  7800 net.cpp:408] data -> label
I1009 20:08:10.219794  7800 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1009 20:08:10.220454  7807 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_test_lmdb
I1009 20:08:10.220587  7800 data_layer.cpp:41] output data size: 100,3,32,32
I1009 20:08:10.222615  7800 net.cpp:150] Setting up data
I1009 20:08:10.222637  7800 net.cpp:157] Top shape: 100 3 32 32 (307200)
I1009 20:08:10.222641  7800 net.cpp:157] Top shape: 100 (100)
I1009 20:08:10.222643  7800 net.cpp:165] Memory required for data: 1229200
I1009 20:08:10.222647  7800 layer_factory.hpp:77] Creating layer label_data_1_split
I1009 20:08:10.222671  7800 net.cpp:100] Creating Layer label_data_1_split
I1009 20:08:10.222674  7800 net.cpp:434] label_data_1_split <- label
I1009 20:08:10.222692  7800 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1009 20:08:10.222702  7800 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1009 20:08:10.222775  7800 net.cpp:150] Setting up label_data_1_split
I1009 20:08:10.222781  7800 net.cpp:157] Top shape: 100 (100)
I1009 20:08:10.222784  7800 net.cpp:157] Top shape: 100 (100)
I1009 20:08:10.222786  7800 net.cpp:165] Memory required for data: 1230000
I1009 20:08:10.222789  7800 layer_factory.hpp:77] Creating layer conv1
I1009 20:08:10.222796  7800 net.cpp:100] Creating Layer conv1
I1009 20:08:10.222800  7800 net.cpp:434] conv1 <- data
I1009 20:08:10.222803  7800 net.cpp:408] conv1 -> conv1
I1009 20:08:10.223867  7800 net.cpp:150] Setting up conv1
I1009 20:08:10.223891  7800 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1009 20:08:10.223892  7800 net.cpp:165] Memory required for data: 35790000
I1009 20:08:10.223917  7800 layer_factory.hpp:77] Creating layer relu1
I1009 20:08:10.223935  7800 net.cpp:100] Creating Layer relu1
I1009 20:08:10.223937  7800 net.cpp:434] relu1 <- conv1
I1009 20:08:10.223942  7800 net.cpp:395] relu1 -> conv1 (in-place)
I1009 20:08:10.224159  7800 net.cpp:150] Setting up relu1
I1009 20:08:10.224166  7800 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1009 20:08:10.224184  7800 net.cpp:165] Memory required for data: 70350000
I1009 20:08:10.224186  7800 layer_factory.hpp:77] Creating layer conv2
I1009 20:08:10.224205  7800 net.cpp:100] Creating Layer conv2
I1009 20:08:10.224220  7800 net.cpp:434] conv2 <- conv1
I1009 20:08:10.224225  7800 net.cpp:408] conv2 -> conv2
I1009 20:08:10.225616  7800 net.cpp:150] Setting up conv2
I1009 20:08:10.225628  7800 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1009 20:08:10.225631  7800 net.cpp:165] Memory required for data: 100455600
I1009 20:08:10.225637  7800 layer_factory.hpp:77] Creating layer relu2
I1009 20:08:10.225642  7800 net.cpp:100] Creating Layer relu2
I1009 20:08:10.225646  7800 net.cpp:434] relu2 <- conv2
I1009 20:08:10.225651  7800 net.cpp:395] relu2 -> conv2 (in-place)
I1009 20:08:10.225870  7800 net.cpp:150] Setting up relu2
I1009 20:08:10.225878  7800 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1009 20:08:10.225881  7800 net.cpp:165] Memory required for data: 130561200
I1009 20:08:10.225883  7800 layer_factory.hpp:77] Creating layer conv3
I1009 20:08:10.225890  7800 net.cpp:100] Creating Layer conv3
I1009 20:08:10.225893  7800 net.cpp:434] conv3 <- conv2
I1009 20:08:10.225898  7800 net.cpp:408] conv3 -> conv3
I1009 20:08:10.227000  7800 net.cpp:150] Setting up conv3
I1009 20:08:10.227011  7800 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1009 20:08:10.227015  7800 net.cpp:165] Memory required for data: 137050800
I1009 20:08:10.227022  7800 layer_factory.hpp:77] Creating layer relu3
I1009 20:08:10.227041  7800 net.cpp:100] Creating Layer relu3
I1009 20:08:10.227051  7800 net.cpp:434] relu3 <- conv3
I1009 20:08:10.227058  7800 net.cpp:395] relu3 -> conv3 (in-place)
I1009 20:08:10.227282  7800 net.cpp:150] Setting up relu3
I1009 20:08:10.227299  7800 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1009 20:08:10.227303  7800 net.cpp:165] Memory required for data: 143540400
I1009 20:08:10.227306  7800 layer_factory.hpp:77] Creating layer conv4
I1009 20:08:10.227314  7800 net.cpp:100] Creating Layer conv4
I1009 20:08:10.227316  7800 net.cpp:434] conv4 <- conv3
I1009 20:08:10.227320  7800 net.cpp:408] conv4 -> conv4
I1009 20:08:10.229389  7800 net.cpp:150] Setting up conv4
I1009 20:08:10.229416  7800 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1009 20:08:10.229419  7800 net.cpp:165] Memory required for data: 152833200
I1009 20:08:10.229424  7800 layer_factory.hpp:77] Creating layer relu4
I1009 20:08:10.229430  7800 net.cpp:100] Creating Layer relu4
I1009 20:08:10.229434  7800 net.cpp:434] relu4 <- conv4
I1009 20:08:10.229437  7800 net.cpp:395] relu4 -> conv4 (in-place)
I1009 20:08:10.229603  7800 net.cpp:150] Setting up relu4
I1009 20:08:10.229609  7800 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1009 20:08:10.229611  7800 net.cpp:165] Memory required for data: 162126000
I1009 20:08:10.229627  7800 layer_factory.hpp:77] Creating layer conv5
I1009 20:08:10.229634  7800 net.cpp:100] Creating Layer conv5
I1009 20:08:10.229665  7800 net.cpp:434] conv5 <- conv4
I1009 20:08:10.229684  7800 net.cpp:408] conv5 -> conv5
I1009 20:08:10.232475  7800 net.cpp:150] Setting up conv5
I1009 20:08:10.232489  7800 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1009 20:08:10.232492  7800 net.cpp:165] Memory required for data: 168346800
I1009 20:08:10.232499  7800 layer_factory.hpp:77] Creating layer relu5
I1009 20:08:10.232504  7800 net.cpp:100] Creating Layer relu5
I1009 20:08:10.232507  7800 net.cpp:434] relu5 <- conv5
I1009 20:08:10.232511  7800 net.cpp:395] relu5 -> conv5 (in-place)
I1009 20:08:10.232776  7800 net.cpp:150] Setting up relu5
I1009 20:08:10.232784  7800 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1009 20:08:10.232786  7800 net.cpp:165] Memory required for data: 174567600
I1009 20:08:10.232789  7800 layer_factory.hpp:77] Creating layer conv6
I1009 20:08:10.232795  7800 net.cpp:100] Creating Layer conv6
I1009 20:08:10.232797  7800 net.cpp:434] conv6 <- conv5
I1009 20:08:10.232801  7800 net.cpp:408] conv6 -> conv6
I1009 20:08:10.235302  7800 net.cpp:150] Setting up conv6
I1009 20:08:10.235312  7800 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1009 20:08:10.235316  7800 net.cpp:165] Memory required for data: 175796400
I1009 20:08:10.235319  7800 layer_factory.hpp:77] Creating layer relu6
I1009 20:08:10.235349  7800 net.cpp:100] Creating Layer relu6
I1009 20:08:10.235353  7800 net.cpp:434] relu6 <- conv6
I1009 20:08:10.235370  7800 net.cpp:395] relu6 -> conv6 (in-place)
I1009 20:08:10.235644  7800 net.cpp:150] Setting up relu6
I1009 20:08:10.235651  7800 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1009 20:08:10.235654  7800 net.cpp:165] Memory required for data: 177025200
I1009 20:08:10.235656  7800 layer_factory.hpp:77] Creating layer conv7
I1009 20:08:10.235662  7800 net.cpp:100] Creating Layer conv7
I1009 20:08:10.235664  7800 net.cpp:434] conv7 <- conv6
I1009 20:08:10.235668  7800 net.cpp:408] conv7 -> conv7
I1009 20:08:10.238173  7800 net.cpp:150] Setting up conv7
I1009 20:08:10.238183  7800 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:08:10.238186  7800 net.cpp:165] Memory required for data: 177332400
I1009 20:08:10.238191  7800 layer_factory.hpp:77] Creating layer relu7
I1009 20:08:10.238195  7800 net.cpp:100] Creating Layer relu7
I1009 20:08:10.238198  7800 net.cpp:434] relu7 <- conv7
I1009 20:08:10.238201  7800 net.cpp:395] relu7 -> conv7 (in-place)
I1009 20:08:10.238374  7800 net.cpp:150] Setting up relu7
I1009 20:08:10.238380  7800 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:08:10.238382  7800 net.cpp:165] Memory required for data: 177639600
I1009 20:08:10.238385  7800 layer_factory.hpp:77] Creating layer conv8
I1009 20:08:10.238392  7800 net.cpp:100] Creating Layer conv8
I1009 20:08:10.238395  7800 net.cpp:434] conv8 <- conv7
I1009 20:08:10.238399  7800 net.cpp:408] conv8 -> conv8
I1009 20:08:10.239375  7800 net.cpp:150] Setting up conv8
I1009 20:08:10.239385  7800 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:08:10.239387  7800 net.cpp:165] Memory required for data: 177946800
I1009 20:08:10.239392  7800 layer_factory.hpp:77] Creating layer relu8
I1009 20:08:10.239395  7800 net.cpp:100] Creating Layer relu8
I1009 20:08:10.239398  7800 net.cpp:434] relu8 <- conv8
I1009 20:08:10.239401  7800 net.cpp:395] relu8 -> conv8 (in-place)
I1009 20:08:10.239645  7800 net.cpp:150] Setting up relu8
I1009 20:08:10.239653  7800 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:08:10.239655  7800 net.cpp:165] Memory required for data: 178254000
I1009 20:08:10.239657  7800 layer_factory.hpp:77] Creating layer conv9
I1009 20:08:10.239663  7800 net.cpp:100] Creating Layer conv9
I1009 20:08:10.239665  7800 net.cpp:434] conv9 <- conv8
I1009 20:08:10.239670  7800 net.cpp:408] conv9 -> conv9
I1009 20:08:10.240363  7800 net.cpp:150] Setting up conv9
I1009 20:08:10.240371  7800 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1009 20:08:10.240375  7800 net.cpp:165] Memory required for data: 178270000
I1009 20:08:10.240381  7800 layer_factory.hpp:77] Creating layer relu9
I1009 20:08:10.240386  7800 net.cpp:100] Creating Layer relu9
I1009 20:08:10.240387  7800 net.cpp:434] relu9 <- conv9
I1009 20:08:10.240391  7800 net.cpp:395] relu9 -> conv9 (in-place)
I1009 20:08:10.240631  7800 net.cpp:150] Setting up relu9
I1009 20:08:10.240639  7800 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1009 20:08:10.240641  7800 net.cpp:165] Memory required for data: 178286000
I1009 20:08:10.240644  7800 layer_factory.hpp:77] Creating layer pool
I1009 20:08:10.240648  7800 net.cpp:100] Creating Layer pool
I1009 20:08:10.240650  7800 net.cpp:434] pool <- conv9
I1009 20:08:10.240653  7800 net.cpp:408] pool -> pool
I1009 20:08:10.240824  7800 net.cpp:150] Setting up pool
I1009 20:08:10.240830  7800 net.cpp:157] Top shape: 100 10 1 1 (1000)
I1009 20:08:10.240833  7800 net.cpp:165] Memory required for data: 178290000
I1009 20:08:10.240835  7800 layer_factory.hpp:77] Creating layer score
I1009 20:08:10.240839  7800 net.cpp:100] Creating Layer score
I1009 20:08:10.240841  7800 net.cpp:434] score <- pool
I1009 20:08:10.240844  7800 net.cpp:408] score -> score
I1009 20:08:10.240988  7800 net.cpp:150] Setting up score
I1009 20:08:10.240993  7800 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:08:10.240994  7800 net.cpp:165] Memory required for data: 178294000
I1009 20:08:10.240999  7800 layer_factory.hpp:77] Creating layer score_score_0_split
I1009 20:08:10.241011  7800 net.cpp:100] Creating Layer score_score_0_split
I1009 20:08:10.241014  7800 net.cpp:434] score_score_0_split <- score
I1009 20:08:10.241019  7800 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1009 20:08:10.241022  7800 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1009 20:08:10.241096  7800 net.cpp:150] Setting up score_score_0_split
I1009 20:08:10.241101  7800 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:08:10.241103  7800 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:08:10.241119  7800 net.cpp:165] Memory required for data: 178302000
I1009 20:08:10.241122  7800 layer_factory.hpp:77] Creating layer accuracy
I1009 20:08:10.241127  7800 net.cpp:100] Creating Layer accuracy
I1009 20:08:10.241142  7800 net.cpp:434] accuracy <- score_score_0_split_0
I1009 20:08:10.241144  7800 net.cpp:434] accuracy <- label_data_1_split_0
I1009 20:08:10.241147  7800 net.cpp:408] accuracy -> accuracy
I1009 20:08:10.241165  7800 net.cpp:150] Setting up accuracy
I1009 20:08:10.241168  7800 net.cpp:157] Top shape: (1)
I1009 20:08:10.241170  7800 net.cpp:165] Memory required for data: 178302004
I1009 20:08:10.241188  7800 layer_factory.hpp:77] Creating layer loss
I1009 20:08:10.241191  7800 net.cpp:100] Creating Layer loss
I1009 20:08:10.241194  7800 net.cpp:434] loss <- score_score_0_split_1
I1009 20:08:10.241196  7800 net.cpp:434] loss <- label_data_1_split_1
I1009 20:08:10.241200  7800 net.cpp:408] loss -> loss
I1009 20:08:10.241220  7800 layer_factory.hpp:77] Creating layer loss
I1009 20:08:10.241555  7800 net.cpp:150] Setting up loss
I1009 20:08:10.241562  7800 net.cpp:157] Top shape: (1)
I1009 20:08:10.241564  7800 net.cpp:160]     with loss weight 1
I1009 20:08:10.241572  7800 net.cpp:165] Memory required for data: 178302008
I1009 20:08:10.241575  7800 net.cpp:226] loss needs backward computation.
I1009 20:08:10.241577  7800 net.cpp:228] accuracy does not need backward computation.
I1009 20:08:10.241580  7800 net.cpp:226] score_score_0_split needs backward computation.
I1009 20:08:10.241582  7800 net.cpp:226] score needs backward computation.
I1009 20:08:10.241585  7800 net.cpp:226] pool needs backward computation.
I1009 20:08:10.241587  7800 net.cpp:226] relu9 needs backward computation.
I1009 20:08:10.241590  7800 net.cpp:226] conv9 needs backward computation.
I1009 20:08:10.241591  7800 net.cpp:226] relu8 needs backward computation.
I1009 20:08:10.241593  7800 net.cpp:226] conv8 needs backward computation.
I1009 20:08:10.241595  7800 net.cpp:226] relu7 needs backward computation.
I1009 20:08:10.241611  7800 net.cpp:226] conv7 needs backward computation.
I1009 20:08:10.241612  7800 net.cpp:226] relu6 needs backward computation.
I1009 20:08:10.241614  7800 net.cpp:226] conv6 needs backward computation.
I1009 20:08:10.241616  7800 net.cpp:226] relu5 needs backward computation.
I1009 20:08:10.241618  7800 net.cpp:226] conv5 needs backward computation.
I1009 20:08:10.241621  7800 net.cpp:226] relu4 needs backward computation.
I1009 20:08:10.241623  7800 net.cpp:226] conv4 needs backward computation.
I1009 20:08:10.241626  7800 net.cpp:226] relu3 needs backward computation.
I1009 20:08:10.241641  7800 net.cpp:226] conv3 needs backward computation.
I1009 20:08:10.241642  7800 net.cpp:226] relu2 needs backward computation.
I1009 20:08:10.241644  7800 net.cpp:226] conv2 needs backward computation.
I1009 20:08:10.241647  7800 net.cpp:226] relu1 needs backward computation.
I1009 20:08:10.241662  7800 net.cpp:226] conv1 needs backward computation.
I1009 20:08:10.241665  7800 net.cpp:228] label_data_1_split does not need backward computation.
I1009 20:08:10.241668  7800 net.cpp:228] data does not need backward computation.
I1009 20:08:10.241670  7800 net.cpp:270] This network produces output accuracy
I1009 20:08:10.241686  7800 net.cpp:270] This network produces output loss
I1009 20:08:10.241698  7800 net.cpp:283] Network initialization done.
I1009 20:08:10.241742  7800 solver.cpp:60] Solver scaffolding done.
I1009 20:08:10.242393  7800 caffe.cpp:251] Starting Optimization
I1009 20:08:10.242403  7800 solver.cpp:279] Solving 
I1009 20:08:10.242420  7800 solver.cpp:280] Learning Rate Policy: step
I1009 20:08:10.243268  7800 solver.cpp:337] Iteration 0, Testing net (#0)
I1009 20:08:13.104924  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:13.104962  7800 solver.cpp:404]     Test net output #1: loss = 9.17911 (* 1 = 9.17911 loss)
I1009 20:08:13.127280  7800 solver.cpp:228] Iteration 0, loss = 9.42184
I1009 20:08:13.127302  7800 solver.cpp:244]     Train net output #0: accuracy = 0.078125
I1009 20:08:13.127310  7800 solver.cpp:244]     Train net output #1: loss = 9.42184 (* 1 = 9.42184 loss)
I1009 20:08:13.127317  7800 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1009 20:08:14.782814  7800 solver.cpp:337] Iteration 25, Testing net (#0)
I1009 20:08:17.690028  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:17.690052  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:19.367054  7800 solver.cpp:337] Iteration 50, Testing net (#0)
I1009 20:08:22.299484  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:22.299521  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:22.319885  7800 solver.cpp:228] Iteration 50, loss = 2.30267
I1009 20:08:22.319908  7800 solver.cpp:244]     Train net output #0: accuracy = 0.125
I1009 20:08:22.319916  7800 solver.cpp:244]     Train net output #1: loss = 2.30267 (* 1 = 2.30267 loss)
I1009 20:08:22.319921  7800 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I1009 20:08:23.975666  7800 solver.cpp:337] Iteration 75, Testing net (#0)
I1009 20:08:26.882789  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:26.882812  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:28.559516  7800 solver.cpp:337] Iteration 100, Testing net (#0)
I1009 20:08:31.467114  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:31.467138  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:31.487421  7800 solver.cpp:228] Iteration 100, loss = 2.30292
I1009 20:08:31.487437  7800 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1009 20:08:31.487445  7800 solver.cpp:244]     Train net output #1: loss = 2.30292 (* 1 = 2.30292 loss)
I1009 20:08:31.487449  7800 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I1009 20:08:33.141965  7800 solver.cpp:337] Iteration 125, Testing net (#0)
I1009 20:08:36.049691  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:36.049728  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:37.725394  7800 solver.cpp:337] Iteration 150, Testing net (#0)
I1009 20:08:40.633311  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:40.633378  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:40.653769  7800 solver.cpp:228] Iteration 150, loss = 2.30224
I1009 20:08:40.653789  7800 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1009 20:08:40.653795  7800 solver.cpp:244]     Train net output #1: loss = 2.30224 (* 1 = 2.30224 loss)
I1009 20:08:40.653800  7800 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I1009 20:08:42.308769  7800 solver.cpp:337] Iteration 175, Testing net (#0)
I1009 20:08:45.215996  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:45.216033  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:46.894460  7800 solver.cpp:337] Iteration 200, Testing net (#0)
I1009 20:08:49.802415  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:49.802453  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:49.822767  7800 solver.cpp:228] Iteration 200, loss = 2.30251
I1009 20:08:49.822800  7800 solver.cpp:244]     Train net output #0: accuracy = 0.125
I1009 20:08:49.822808  7800 solver.cpp:244]     Train net output #1: loss = 2.30251 (* 1 = 2.30251 loss)
I1009 20:08:49.822813  7800 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I1009 20:08:51.481442  7800 solver.cpp:337] Iteration 225, Testing net (#0)
I1009 20:08:54.392051  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:54.392088  7800 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:08:56.068172  7800 solver.cpp:454] Snapshotting to binary proto file cifar-10_relu_Nesterov_iter_250.caffemodel
I1009 20:08:56.134219  7800 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_relu_Nesterov_iter_250.solverstate
I1009 20:08:56.161856  7800 solver.cpp:317] Iteration 250, loss = 2.30192
I1009 20:08:56.161890  7800 solver.cpp:337] Iteration 250, Testing net (#0)
I1009 20:08:59.019054  7800 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:59.019076  7800 solver.cpp:404]     Test net output #1: loss = 2.3026 (* 1 = 2.3026 loss)
I1009 20:08:59.019079  7800 solver.cpp:322] Optimization Done.
I1009 20:08:59.019083  7800 caffe.cpp:254] Optimization Done.
