I1009 20:06:31.583092  7747 caffe.cpp:217] Using GPUs 0
I1009 20:06:31.585798  7747 caffe.cpp:222] GPU 0: GeForce GTX 750 Ti
I1009 20:06:31.694896  7747 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt"
test_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt"
test_iter: 100
test_interval: 25
base_lr: 0.001
display: 50
max_iter: 250
lr_policy: "step"
gamma: 0.1
weight_decay: 0.0005
stepsize: 5000
snapshot: 5000
snapshot_prefix: "cifar-10_relu_AdaGrad"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
type: "AdaGrad"
I1009 20:06:31.695039  7747 solver.cpp:81] Creating training net from train_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt
I1009 20:06:31.695380  7747 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1009 20:06:31.695503  7747 layer_factory.hpp:77] Creating layer data
I1009 20:06:31.696089  7747 net.cpp:100] Creating Layer data
I1009 20:06:31.696097  7747 net.cpp:408] data -> data
I1009 20:06:31.696135  7747 net.cpp:408] data -> label
I1009 20:06:31.696146  7747 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1009 20:06:31.696801  7752 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_train_lmdb
I1009 20:06:31.703266  7747 data_layer.cpp:41] output data size: 64,3,32,32
I1009 20:06:31.704793  7747 net.cpp:150] Setting up data
I1009 20:06:31.704823  7747 net.cpp:157] Top shape: 64 3 32 32 (196608)
I1009 20:06:31.704828  7747 net.cpp:157] Top shape: 64 (64)
I1009 20:06:31.704829  7747 net.cpp:165] Memory required for data: 786688
I1009 20:06:31.704838  7747 layer_factory.hpp:77] Creating layer label_data_1_split
I1009 20:06:31.704864  7747 net.cpp:100] Creating Layer label_data_1_split
I1009 20:06:31.704880  7747 net.cpp:434] label_data_1_split <- label
I1009 20:06:31.704905  7747 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1009 20:06:31.704926  7747 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1009 20:06:31.704982  7747 net.cpp:150] Setting up label_data_1_split
I1009 20:06:31.704988  7747 net.cpp:157] Top shape: 64 (64)
I1009 20:06:31.704990  7747 net.cpp:157] Top shape: 64 (64)
I1009 20:06:31.704991  7747 net.cpp:165] Memory required for data: 787200
I1009 20:06:31.704994  7747 layer_factory.hpp:77] Creating layer conv1
I1009 20:06:31.705008  7747 net.cpp:100] Creating Layer conv1
I1009 20:06:31.705011  7747 net.cpp:434] conv1 <- data
I1009 20:06:31.705014  7747 net.cpp:408] conv1 -> conv1
I1009 20:06:31.845553  7747 net.cpp:150] Setting up conv1
I1009 20:06:31.845578  7747 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1009 20:06:31.845582  7747 net.cpp:165] Memory required for data: 22905600
I1009 20:06:31.845599  7747 layer_factory.hpp:77] Creating layer relu1
I1009 20:06:31.845607  7747 net.cpp:100] Creating Layer relu1
I1009 20:06:31.845609  7747 net.cpp:434] relu1 <- conv1
I1009 20:06:31.845613  7747 net.cpp:395] relu1 -> conv1 (in-place)
I1009 20:06:31.845815  7747 net.cpp:150] Setting up relu1
I1009 20:06:31.845821  7747 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1009 20:06:31.845824  7747 net.cpp:165] Memory required for data: 45024000
I1009 20:06:31.845826  7747 layer_factory.hpp:77] Creating layer conv2
I1009 20:06:31.845834  7747 net.cpp:100] Creating Layer conv2
I1009 20:06:31.845836  7747 net.cpp:434] conv2 <- conv1
I1009 20:06:31.845839  7747 net.cpp:408] conv2 -> conv2
I1009 20:06:31.847208  7747 net.cpp:150] Setting up conv2
I1009 20:06:31.847218  7747 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1009 20:06:31.847220  7747 net.cpp:165] Memory required for data: 64291584
I1009 20:06:31.847226  7747 layer_factory.hpp:77] Creating layer relu2
I1009 20:06:31.847230  7747 net.cpp:100] Creating Layer relu2
I1009 20:06:31.847232  7747 net.cpp:434] relu2 <- conv2
I1009 20:06:31.847235  7747 net.cpp:395] relu2 -> conv2 (in-place)
I1009 20:06:31.847390  7747 net.cpp:150] Setting up relu2
I1009 20:06:31.847396  7747 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1009 20:06:31.847398  7747 net.cpp:165] Memory required for data: 83559168
I1009 20:06:31.847400  7747 layer_factory.hpp:77] Creating layer conv3
I1009 20:06:31.847406  7747 net.cpp:100] Creating Layer conv3
I1009 20:06:31.847409  7747 net.cpp:434] conv3 <- conv2
I1009 20:06:31.847411  7747 net.cpp:408] conv3 -> conv3
I1009 20:06:31.848569  7747 net.cpp:150] Setting up conv3
I1009 20:06:31.848578  7747 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1009 20:06:31.848582  7747 net.cpp:165] Memory required for data: 87712512
I1009 20:06:31.848587  7747 layer_factory.hpp:77] Creating layer relu3
I1009 20:06:31.848592  7747 net.cpp:100] Creating Layer relu3
I1009 20:06:31.848593  7747 net.cpp:434] relu3 <- conv3
I1009 20:06:31.848597  7747 net.cpp:395] relu3 -> conv3 (in-place)
I1009 20:06:31.848853  7747 net.cpp:150] Setting up relu3
I1009 20:06:31.848860  7747 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1009 20:06:31.848875  7747 net.cpp:165] Memory required for data: 91865856
I1009 20:06:31.848877  7747 layer_factory.hpp:77] Creating layer conv4
I1009 20:06:31.848883  7747 net.cpp:100] Creating Layer conv4
I1009 20:06:31.848886  7747 net.cpp:434] conv4 <- conv3
I1009 20:06:31.848889  7747 net.cpp:408] conv4 -> conv4
I1009 20:06:31.850683  7747 net.cpp:150] Setting up conv4
I1009 20:06:31.850693  7747 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1009 20:06:31.850697  7747 net.cpp:165] Memory required for data: 97813248
I1009 20:06:31.850702  7747 layer_factory.hpp:77] Creating layer relu4
I1009 20:06:31.850705  7747 net.cpp:100] Creating Layer relu4
I1009 20:06:31.850708  7747 net.cpp:434] relu4 <- conv4
I1009 20:06:31.850710  7747 net.cpp:395] relu4 -> conv4 (in-place)
I1009 20:06:31.850883  7747 net.cpp:150] Setting up relu4
I1009 20:06:31.850889  7747 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1009 20:06:31.850891  7747 net.cpp:165] Memory required for data: 103760640
I1009 20:06:31.850894  7747 layer_factory.hpp:77] Creating layer conv5
I1009 20:06:31.850899  7747 net.cpp:100] Creating Layer conv5
I1009 20:06:31.850901  7747 net.cpp:434] conv5 <- conv4
I1009 20:06:31.850904  7747 net.cpp:408] conv5 -> conv5
I1009 20:06:31.853420  7747 net.cpp:150] Setting up conv5
I1009 20:06:31.853444  7747 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1009 20:06:31.853446  7747 net.cpp:165] Memory required for data: 107741952
I1009 20:06:31.853468  7747 layer_factory.hpp:77] Creating layer relu5
I1009 20:06:31.853473  7747 net.cpp:100] Creating Layer relu5
I1009 20:06:31.853476  7747 net.cpp:434] relu5 <- conv5
I1009 20:06:31.853479  7747 net.cpp:395] relu5 -> conv5 (in-place)
I1009 20:06:31.853669  7747 net.cpp:150] Setting up relu5
I1009 20:06:31.853675  7747 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1009 20:06:31.853677  7747 net.cpp:165] Memory required for data: 111723264
I1009 20:06:31.853679  7747 layer_factory.hpp:77] Creating layer conv6
I1009 20:06:31.853699  7747 net.cpp:100] Creating Layer conv6
I1009 20:06:31.853703  7747 net.cpp:434] conv6 <- conv5
I1009 20:06:31.853705  7747 net.cpp:408] conv6 -> conv6
I1009 20:06:31.856268  7747 net.cpp:150] Setting up conv6
I1009 20:06:31.856295  7747 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1009 20:06:31.856297  7747 net.cpp:165] Memory required for data: 112509696
I1009 20:06:31.856302  7747 layer_factory.hpp:77] Creating layer relu6
I1009 20:06:31.856307  7747 net.cpp:100] Creating Layer relu6
I1009 20:06:31.856309  7747 net.cpp:434] relu6 <- conv6
I1009 20:06:31.856312  7747 net.cpp:395] relu6 -> conv6 (in-place)
I1009 20:06:31.856580  7747 net.cpp:150] Setting up relu6
I1009 20:06:31.856602  7747 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1009 20:06:31.856604  7747 net.cpp:165] Memory required for data: 113296128
I1009 20:06:31.856607  7747 layer_factory.hpp:77] Creating layer conv7
I1009 20:06:31.856614  7747 net.cpp:100] Creating Layer conv7
I1009 20:06:31.856616  7747 net.cpp:434] conv7 <- conv6
I1009 20:06:31.856621  7747 net.cpp:408] conv7 -> conv7
I1009 20:06:31.859666  7747 net.cpp:150] Setting up conv7
I1009 20:06:31.859685  7747 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:06:31.859688  7747 net.cpp:165] Memory required for data: 113492736
I1009 20:06:31.859694  7747 layer_factory.hpp:77] Creating layer relu7
I1009 20:06:31.859699  7747 net.cpp:100] Creating Layer relu7
I1009 20:06:31.859702  7747 net.cpp:434] relu7 <- conv7
I1009 20:06:31.859706  7747 net.cpp:395] relu7 -> conv7 (in-place)
I1009 20:06:31.859961  7747 net.cpp:150] Setting up relu7
I1009 20:06:31.859969  7747 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:06:31.859972  7747 net.cpp:165] Memory required for data: 113689344
I1009 20:06:31.859973  7747 layer_factory.hpp:77] Creating layer conv8
I1009 20:06:31.859983  7747 net.cpp:100] Creating Layer conv8
I1009 20:06:31.859987  7747 net.cpp:434] conv8 <- conv7
I1009 20:06:31.859990  7747 net.cpp:408] conv8 -> conv8
I1009 20:06:31.861241  7747 net.cpp:150] Setting up conv8
I1009 20:06:31.861251  7747 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:06:31.861263  7747 net.cpp:165] Memory required for data: 113885952
I1009 20:06:31.861268  7747 layer_factory.hpp:77] Creating layer relu8
I1009 20:06:31.861274  7747 net.cpp:100] Creating Layer relu8
I1009 20:06:31.861276  7747 net.cpp:434] relu8 <- conv8
I1009 20:06:31.861279  7747 net.cpp:395] relu8 -> conv8 (in-place)
I1009 20:06:31.861448  7747 net.cpp:150] Setting up relu8
I1009 20:06:31.861454  7747 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:06:31.861455  7747 net.cpp:165] Memory required for data: 114082560
I1009 20:06:31.861457  7747 layer_factory.hpp:77] Creating layer conv9
I1009 20:06:31.861464  7747 net.cpp:100] Creating Layer conv9
I1009 20:06:31.861466  7747 net.cpp:434] conv9 <- conv8
I1009 20:06:31.861469  7747 net.cpp:408] conv9 -> conv9
I1009 20:06:31.862282  7747 net.cpp:150] Setting up conv9
I1009 20:06:31.862290  7747 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1009 20:06:31.862293  7747 net.cpp:165] Memory required for data: 114092800
I1009 20:06:31.862299  7747 layer_factory.hpp:77] Creating layer relu9
I1009 20:06:31.862304  7747 net.cpp:100] Creating Layer relu9
I1009 20:06:31.862306  7747 net.cpp:434] relu9 <- conv9
I1009 20:06:31.862309  7747 net.cpp:395] relu9 -> conv9 (in-place)
I1009 20:06:31.862573  7747 net.cpp:150] Setting up relu9
I1009 20:06:31.862581  7747 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1009 20:06:31.862583  7747 net.cpp:165] Memory required for data: 114103040
I1009 20:06:31.862586  7747 layer_factory.hpp:77] Creating layer pool
I1009 20:06:31.862591  7747 net.cpp:100] Creating Layer pool
I1009 20:06:31.862592  7747 net.cpp:434] pool <- conv9
I1009 20:06:31.862596  7747 net.cpp:408] pool -> pool
I1009 20:06:31.862805  7747 net.cpp:150] Setting up pool
I1009 20:06:31.862812  7747 net.cpp:157] Top shape: 64 10 1 1 (640)
I1009 20:06:31.862814  7747 net.cpp:165] Memory required for data: 114105600
I1009 20:06:31.862817  7747 layer_factory.hpp:77] Creating layer score
I1009 20:06:31.862821  7747 net.cpp:100] Creating Layer score
I1009 20:06:31.862823  7747 net.cpp:434] score <- pool
I1009 20:06:31.862828  7747 net.cpp:408] score -> score
I1009 20:06:31.862982  7747 net.cpp:150] Setting up score
I1009 20:06:31.862987  7747 net.cpp:157] Top shape: 64 10 (640)
I1009 20:06:31.862989  7747 net.cpp:165] Memory required for data: 114108160
I1009 20:06:31.862993  7747 layer_factory.hpp:77] Creating layer score_score_0_split
I1009 20:06:31.862996  7747 net.cpp:100] Creating Layer score_score_0_split
I1009 20:06:31.862998  7747 net.cpp:434] score_score_0_split <- score
I1009 20:06:31.863003  7747 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1009 20:06:31.863008  7747 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1009 20:06:31.863051  7747 net.cpp:150] Setting up score_score_0_split
I1009 20:06:31.863055  7747 net.cpp:157] Top shape: 64 10 (640)
I1009 20:06:31.863059  7747 net.cpp:157] Top shape: 64 10 (640)
I1009 20:06:31.863060  7747 net.cpp:165] Memory required for data: 114113280
I1009 20:06:31.863062  7747 layer_factory.hpp:77] Creating layer accuracy
I1009 20:06:31.863066  7747 net.cpp:100] Creating Layer accuracy
I1009 20:06:31.863070  7747 net.cpp:434] accuracy <- score_score_0_split_0
I1009 20:06:31.863072  7747 net.cpp:434] accuracy <- label_data_1_split_0
I1009 20:06:31.863075  7747 net.cpp:408] accuracy -> accuracy
I1009 20:06:31.863080  7747 net.cpp:150] Setting up accuracy
I1009 20:06:31.863083  7747 net.cpp:157] Top shape: (1)
I1009 20:06:31.863085  7747 net.cpp:165] Memory required for data: 114113284
I1009 20:06:31.863086  7747 layer_factory.hpp:77] Creating layer loss
I1009 20:06:31.863090  7747 net.cpp:100] Creating Layer loss
I1009 20:06:31.863095  7747 net.cpp:434] loss <- score_score_0_split_1
I1009 20:06:31.863111  7747 net.cpp:434] loss <- label_data_1_split_1
I1009 20:06:31.863116  7747 net.cpp:408] loss -> loss
I1009 20:06:31.863134  7747 layer_factory.hpp:77] Creating layer loss
I1009 20:06:31.863451  7747 net.cpp:150] Setting up loss
I1009 20:06:31.863459  7747 net.cpp:157] Top shape: (1)
I1009 20:06:31.863461  7747 net.cpp:160]     with loss weight 1
I1009 20:06:31.863479  7747 net.cpp:165] Memory required for data: 114113288
I1009 20:06:31.863482  7747 net.cpp:226] loss needs backward computation.
I1009 20:06:31.863488  7747 net.cpp:228] accuracy does not need backward computation.
I1009 20:06:31.863492  7747 net.cpp:226] score_score_0_split needs backward computation.
I1009 20:06:31.863493  7747 net.cpp:226] score needs backward computation.
I1009 20:06:31.863495  7747 net.cpp:226] pool needs backward computation.
I1009 20:06:31.863497  7747 net.cpp:226] relu9 needs backward computation.
I1009 20:06:31.863513  7747 net.cpp:226] conv9 needs backward computation.
I1009 20:06:31.863515  7747 net.cpp:226] relu8 needs backward computation.
I1009 20:06:31.863517  7747 net.cpp:226] conv8 needs backward computation.
I1009 20:06:31.863519  7747 net.cpp:226] relu7 needs backward computation.
I1009 20:06:31.863521  7747 net.cpp:226] conv7 needs backward computation.
I1009 20:06:31.863523  7747 net.cpp:226] relu6 needs backward computation.
I1009 20:06:31.863525  7747 net.cpp:226] conv6 needs backward computation.
I1009 20:06:31.863528  7747 net.cpp:226] relu5 needs backward computation.
I1009 20:06:31.863529  7747 net.cpp:226] conv5 needs backward computation.
I1009 20:06:31.863533  7747 net.cpp:226] relu4 needs backward computation.
I1009 20:06:31.863548  7747 net.cpp:226] conv4 needs backward computation.
I1009 20:06:31.863551  7747 net.cpp:226] relu3 needs backward computation.
I1009 20:06:31.863554  7747 net.cpp:226] conv3 needs backward computation.
I1009 20:06:31.863555  7747 net.cpp:226] relu2 needs backward computation.
I1009 20:06:31.863557  7747 net.cpp:226] conv2 needs backward computation.
I1009 20:06:31.863560  7747 net.cpp:226] relu1 needs backward computation.
I1009 20:06:31.863562  7747 net.cpp:226] conv1 needs backward computation.
I1009 20:06:31.863579  7747 net.cpp:228] label_data_1_split does not need backward computation.
I1009 20:06:31.863580  7747 net.cpp:228] data does not need backward computation.
I1009 20:06:31.863582  7747 net.cpp:270] This network produces output accuracy
I1009 20:06:31.863585  7747 net.cpp:270] This network produces output loss
I1009 20:06:31.863600  7747 net.cpp:283] Network initialization done.
I1009 20:06:31.863776  7747 solver.cpp:181] Creating test net (#0) specified by test_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt
I1009 20:06:31.863934  7747 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1009 20:06:31.864042  7747 layer_factory.hpp:77] Creating layer data
I1009 20:06:31.864179  7747 net.cpp:100] Creating Layer data
I1009 20:06:31.864186  7747 net.cpp:408] data -> data
I1009 20:06:31.864205  7747 net.cpp:408] data -> label
I1009 20:06:31.864212  7747 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1009 20:06:31.864903  7754 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_test_lmdb
I1009 20:06:31.865058  7747 data_layer.cpp:41] output data size: 100,3,32,32
I1009 20:06:31.867064  7747 net.cpp:150] Setting up data
I1009 20:06:31.867112  7747 net.cpp:157] Top shape: 100 3 32 32 (307200)
I1009 20:06:31.867116  7747 net.cpp:157] Top shape: 100 (100)
I1009 20:06:31.867118  7747 net.cpp:165] Memory required for data: 1229200
I1009 20:06:31.867123  7747 layer_factory.hpp:77] Creating layer label_data_1_split
I1009 20:06:31.867131  7747 net.cpp:100] Creating Layer label_data_1_split
I1009 20:06:31.867151  7747 net.cpp:434] label_data_1_split <- label
I1009 20:06:31.867171  7747 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1009 20:06:31.867177  7747 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1009 20:06:31.867286  7747 net.cpp:150] Setting up label_data_1_split
I1009 20:06:31.867291  7747 net.cpp:157] Top shape: 100 (100)
I1009 20:06:31.867308  7747 net.cpp:157] Top shape: 100 (100)
I1009 20:06:31.867311  7747 net.cpp:165] Memory required for data: 1230000
I1009 20:06:31.867312  7747 layer_factory.hpp:77] Creating layer conv1
I1009 20:06:31.867334  7747 net.cpp:100] Creating Layer conv1
I1009 20:06:31.867336  7747 net.cpp:434] conv1 <- data
I1009 20:06:31.867354  7747 net.cpp:408] conv1 -> conv1
I1009 20:06:31.868300  7747 net.cpp:150] Setting up conv1
I1009 20:06:31.868325  7747 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1009 20:06:31.868327  7747 net.cpp:165] Memory required for data: 35790000
I1009 20:06:31.868348  7747 layer_factory.hpp:77] Creating layer relu1
I1009 20:06:31.868353  7747 net.cpp:100] Creating Layer relu1
I1009 20:06:31.868371  7747 net.cpp:434] relu1 <- conv1
I1009 20:06:31.868374  7747 net.cpp:395] relu1 -> conv1 (in-place)
I1009 20:06:31.868682  7747 net.cpp:150] Setting up relu1
I1009 20:06:31.868690  7747 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1009 20:06:31.868692  7747 net.cpp:165] Memory required for data: 70350000
I1009 20:06:31.868695  7747 layer_factory.hpp:77] Creating layer conv2
I1009 20:06:31.868716  7747 net.cpp:100] Creating Layer conv2
I1009 20:06:31.868741  7747 net.cpp:434] conv2 <- conv1
I1009 20:06:31.868762  7747 net.cpp:408] conv2 -> conv2
I1009 20:06:31.870131  7747 net.cpp:150] Setting up conv2
I1009 20:06:31.870157  7747 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1009 20:06:31.870159  7747 net.cpp:165] Memory required for data: 100455600
I1009 20:06:31.870179  7747 layer_factory.hpp:77] Creating layer relu2
I1009 20:06:31.870184  7747 net.cpp:100] Creating Layer relu2
I1009 20:06:31.870193  7747 net.cpp:434] relu2 <- conv2
I1009 20:06:31.870196  7747 net.cpp:395] relu2 -> conv2 (in-place)
I1009 20:06:31.870435  7747 net.cpp:150] Setting up relu2
I1009 20:06:31.870445  7747 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1009 20:06:31.870462  7747 net.cpp:165] Memory required for data: 130561200
I1009 20:06:31.870468  7747 layer_factory.hpp:77] Creating layer conv3
I1009 20:06:31.870489  7747 net.cpp:100] Creating Layer conv3
I1009 20:06:31.870492  7747 net.cpp:434] conv3 <- conv2
I1009 20:06:31.870496  7747 net.cpp:408] conv3 -> conv3
I1009 20:06:31.871830  7747 net.cpp:150] Setting up conv3
I1009 20:06:31.871840  7747 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1009 20:06:31.871845  7747 net.cpp:165] Memory required for data: 137050800
I1009 20:06:31.871870  7747 layer_factory.hpp:77] Creating layer relu3
I1009 20:06:31.871886  7747 net.cpp:100] Creating Layer relu3
I1009 20:06:31.871889  7747 net.cpp:434] relu3 <- conv3
I1009 20:06:31.871893  7747 net.cpp:395] relu3 -> conv3 (in-place)
I1009 20:06:31.872135  7747 net.cpp:150] Setting up relu3
I1009 20:06:31.872144  7747 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1009 20:06:31.872146  7747 net.cpp:165] Memory required for data: 143540400
I1009 20:06:31.872149  7747 layer_factory.hpp:77] Creating layer conv4
I1009 20:06:31.872159  7747 net.cpp:100] Creating Layer conv4
I1009 20:06:31.872161  7747 net.cpp:434] conv4 <- conv3
I1009 20:06:31.872165  7747 net.cpp:408] conv4 -> conv4
I1009 20:06:31.874280  7747 net.cpp:150] Setting up conv4
I1009 20:06:31.874325  7747 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1009 20:06:31.874327  7747 net.cpp:165] Memory required for data: 152833200
I1009 20:06:31.874347  7747 layer_factory.hpp:77] Creating layer relu4
I1009 20:06:31.874366  7747 net.cpp:100] Creating Layer relu4
I1009 20:06:31.874371  7747 net.cpp:434] relu4 <- conv4
I1009 20:06:31.874387  7747 net.cpp:395] relu4 -> conv4 (in-place)
I1009 20:06:31.874558  7747 net.cpp:150] Setting up relu4
I1009 20:06:31.874565  7747 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1009 20:06:31.874567  7747 net.cpp:165] Memory required for data: 162126000
I1009 20:06:31.874569  7747 layer_factory.hpp:77] Creating layer conv5
I1009 20:06:31.874590  7747 net.cpp:100] Creating Layer conv5
I1009 20:06:31.874593  7747 net.cpp:434] conv5 <- conv4
I1009 20:06:31.874596  7747 net.cpp:408] conv5 -> conv5
I1009 20:06:31.877383  7747 net.cpp:150] Setting up conv5
I1009 20:06:31.877396  7747 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1009 20:06:31.877399  7747 net.cpp:165] Memory required for data: 168346800
I1009 20:06:31.877423  7747 layer_factory.hpp:77] Creating layer relu5
I1009 20:06:31.877427  7747 net.cpp:100] Creating Layer relu5
I1009 20:06:31.877429  7747 net.cpp:434] relu5 <- conv5
I1009 20:06:31.877434  7747 net.cpp:395] relu5 -> conv5 (in-place)
I1009 20:06:31.877710  7747 net.cpp:150] Setting up relu5
I1009 20:06:31.877718  7747 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1009 20:06:31.877722  7747 net.cpp:165] Memory required for data: 174567600
I1009 20:06:31.877723  7747 layer_factory.hpp:77] Creating layer conv6
I1009 20:06:31.877729  7747 net.cpp:100] Creating Layer conv6
I1009 20:06:31.877732  7747 net.cpp:434] conv6 <- conv5
I1009 20:06:31.877735  7747 net.cpp:408] conv6 -> conv6
I1009 20:06:31.880295  7747 net.cpp:150] Setting up conv6
I1009 20:06:31.880321  7747 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1009 20:06:31.880322  7747 net.cpp:165] Memory required for data: 175796400
I1009 20:06:31.880327  7747 layer_factory.hpp:77] Creating layer relu6
I1009 20:06:31.880342  7747 net.cpp:100] Creating Layer relu6
I1009 20:06:31.880359  7747 net.cpp:434] relu6 <- conv6
I1009 20:06:31.880365  7747 net.cpp:395] relu6 -> conv6 (in-place)
I1009 20:06:31.880615  7747 net.cpp:150] Setting up relu6
I1009 20:06:31.880623  7747 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1009 20:06:31.880625  7747 net.cpp:165] Memory required for data: 177025200
I1009 20:06:31.880627  7747 layer_factory.hpp:77] Creating layer conv7
I1009 20:06:31.880635  7747 net.cpp:100] Creating Layer conv7
I1009 20:06:31.880636  7747 net.cpp:434] conv7 <- conv6
I1009 20:06:31.880640  7747 net.cpp:408] conv7 -> conv7
I1009 20:06:31.883256  7747 net.cpp:150] Setting up conv7
I1009 20:06:31.883266  7747 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:06:31.883270  7747 net.cpp:165] Memory required for data: 177332400
I1009 20:06:31.883273  7747 layer_factory.hpp:77] Creating layer relu7
I1009 20:06:31.883277  7747 net.cpp:100] Creating Layer relu7
I1009 20:06:31.883280  7747 net.cpp:434] relu7 <- conv7
I1009 20:06:31.883283  7747 net.cpp:395] relu7 -> conv7 (in-place)
I1009 20:06:31.883457  7747 net.cpp:150] Setting up relu7
I1009 20:06:31.883465  7747 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:06:31.883466  7747 net.cpp:165] Memory required for data: 177639600
I1009 20:06:31.883468  7747 layer_factory.hpp:77] Creating layer conv8
I1009 20:06:31.883476  7747 net.cpp:100] Creating Layer conv8
I1009 20:06:31.883479  7747 net.cpp:434] conv8 <- conv7
I1009 20:06:31.883482  7747 net.cpp:408] conv8 -> conv8
I1009 20:06:31.884477  7747 net.cpp:150] Setting up conv8
I1009 20:06:31.884487  7747 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:06:31.884490  7747 net.cpp:165] Memory required for data: 177946800
I1009 20:06:31.884495  7747 layer_factory.hpp:77] Creating layer relu8
I1009 20:06:31.884498  7747 net.cpp:100] Creating Layer relu8
I1009 20:06:31.884500  7747 net.cpp:434] relu8 <- conv8
I1009 20:06:31.884503  7747 net.cpp:395] relu8 -> conv8 (in-place)
I1009 20:06:31.884765  7747 net.cpp:150] Setting up relu8
I1009 20:06:31.884773  7747 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:06:31.884775  7747 net.cpp:165] Memory required for data: 178254000
I1009 20:06:31.884778  7747 layer_factory.hpp:77] Creating layer conv9
I1009 20:06:31.884783  7747 net.cpp:100] Creating Layer conv9
I1009 20:06:31.884786  7747 net.cpp:434] conv9 <- conv8
I1009 20:06:31.884789  7747 net.cpp:408] conv9 -> conv9
I1009 20:06:31.885555  7747 net.cpp:150] Setting up conv9
I1009 20:06:31.885563  7747 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1009 20:06:31.885566  7747 net.cpp:165] Memory required for data: 178270000
I1009 20:06:31.885573  7747 layer_factory.hpp:77] Creating layer relu9
I1009 20:06:31.885577  7747 net.cpp:100] Creating Layer relu9
I1009 20:06:31.885579  7747 net.cpp:434] relu9 <- conv9
I1009 20:06:31.885583  7747 net.cpp:395] relu9 -> conv9 (in-place)
I1009 20:06:31.885857  7747 net.cpp:150] Setting up relu9
I1009 20:06:31.885865  7747 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1009 20:06:31.885867  7747 net.cpp:165] Memory required for data: 178286000
I1009 20:06:31.885869  7747 layer_factory.hpp:77] Creating layer pool
I1009 20:06:31.885874  7747 net.cpp:100] Creating Layer pool
I1009 20:06:31.885876  7747 net.cpp:434] pool <- conv9
I1009 20:06:31.885880  7747 net.cpp:408] pool -> pool
I1009 20:06:31.886070  7747 net.cpp:150] Setting up pool
I1009 20:06:31.886076  7747 net.cpp:157] Top shape: 100 10 1 1 (1000)
I1009 20:06:31.886080  7747 net.cpp:165] Memory required for data: 178290000
I1009 20:06:31.886081  7747 layer_factory.hpp:77] Creating layer score
I1009 20:06:31.886085  7747 net.cpp:100] Creating Layer score
I1009 20:06:31.886087  7747 net.cpp:434] score <- pool
I1009 20:06:31.886091  7747 net.cpp:408] score -> score
I1009 20:06:31.886226  7747 net.cpp:150] Setting up score
I1009 20:06:31.886231  7747 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:06:31.886234  7747 net.cpp:165] Memory required for data: 178294000
I1009 20:06:31.886237  7747 layer_factory.hpp:77] Creating layer score_score_0_split
I1009 20:06:31.886250  7747 net.cpp:100] Creating Layer score_score_0_split
I1009 20:06:31.886252  7747 net.cpp:434] score_score_0_split <- score
I1009 20:06:31.886255  7747 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1009 20:06:31.886261  7747 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1009 20:06:31.886337  7747 net.cpp:150] Setting up score_score_0_split
I1009 20:06:31.886355  7747 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:06:31.886358  7747 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:06:31.886359  7747 net.cpp:165] Memory required for data: 178302000
I1009 20:06:31.886361  7747 layer_factory.hpp:77] Creating layer accuracy
I1009 20:06:31.886379  7747 net.cpp:100] Creating Layer accuracy
I1009 20:06:31.886381  7747 net.cpp:434] accuracy <- score_score_0_split_0
I1009 20:06:31.886384  7747 net.cpp:434] accuracy <- label_data_1_split_0
I1009 20:06:31.886400  7747 net.cpp:408] accuracy -> accuracy
I1009 20:06:31.886406  7747 net.cpp:150] Setting up accuracy
I1009 20:06:31.886423  7747 net.cpp:157] Top shape: (1)
I1009 20:06:31.886425  7747 net.cpp:165] Memory required for data: 178302004
I1009 20:06:31.886426  7747 layer_factory.hpp:77] Creating layer loss
I1009 20:06:31.886430  7747 net.cpp:100] Creating Layer loss
I1009 20:06:31.886432  7747 net.cpp:434] loss <- score_score_0_split_1
I1009 20:06:31.886435  7747 net.cpp:434] loss <- label_data_1_split_1
I1009 20:06:31.886453  7747 net.cpp:408] loss -> loss
I1009 20:06:31.886472  7747 layer_factory.hpp:77] Creating layer loss
I1009 20:06:31.886796  7747 net.cpp:150] Setting up loss
I1009 20:06:31.886806  7747 net.cpp:157] Top shape: (1)
I1009 20:06:31.886807  7747 net.cpp:160]     with loss weight 1
I1009 20:06:31.886829  7747 net.cpp:165] Memory required for data: 178302008
I1009 20:06:31.886832  7747 net.cpp:226] loss needs backward computation.
I1009 20:06:31.886849  7747 net.cpp:228] accuracy does not need backward computation.
I1009 20:06:31.886852  7747 net.cpp:226] score_score_0_split needs backward computation.
I1009 20:06:31.886854  7747 net.cpp:226] score needs backward computation.
I1009 20:06:31.886857  7747 net.cpp:226] pool needs backward computation.
I1009 20:06:31.886859  7747 net.cpp:226] relu9 needs backward computation.
I1009 20:06:31.886862  7747 net.cpp:226] conv9 needs backward computation.
I1009 20:06:31.886863  7747 net.cpp:226] relu8 needs backward computation.
I1009 20:06:31.886865  7747 net.cpp:226] conv8 needs backward computation.
I1009 20:06:31.886868  7747 net.cpp:226] relu7 needs backward computation.
I1009 20:06:31.886869  7747 net.cpp:226] conv7 needs backward computation.
I1009 20:06:31.886871  7747 net.cpp:226] relu6 needs backward computation.
I1009 20:06:31.886873  7747 net.cpp:226] conv6 needs backward computation.
I1009 20:06:31.886875  7747 net.cpp:226] relu5 needs backward computation.
I1009 20:06:31.886878  7747 net.cpp:226] conv5 needs backward computation.
I1009 20:06:31.886880  7747 net.cpp:226] relu4 needs backward computation.
I1009 20:06:31.886883  7747 net.cpp:226] conv4 needs backward computation.
I1009 20:06:31.886884  7747 net.cpp:226] relu3 needs backward computation.
I1009 20:06:31.886886  7747 net.cpp:226] conv3 needs backward computation.
I1009 20:06:31.886888  7747 net.cpp:226] relu2 needs backward computation.
I1009 20:06:31.886890  7747 net.cpp:226] conv2 needs backward computation.
I1009 20:06:31.886893  7747 net.cpp:226] relu1 needs backward computation.
I1009 20:06:31.886894  7747 net.cpp:226] conv1 needs backward computation.
I1009 20:06:31.886898  7747 net.cpp:228] label_data_1_split does not need backward computation.
I1009 20:06:31.886899  7747 net.cpp:228] data does not need backward computation.
I1009 20:06:31.886901  7747 net.cpp:270] This network produces output accuracy
I1009 20:06:31.886904  7747 net.cpp:270] This network produces output loss
I1009 20:06:31.886917  7747 net.cpp:283] Network initialization done.
I1009 20:06:31.886983  7747 solver.cpp:60] Solver scaffolding done.
I1009 20:06:31.887640  7747 caffe.cpp:251] Starting Optimization
I1009 20:06:31.887651  7747 solver.cpp:279] Solving 
I1009 20:06:31.887666  7747 solver.cpp:280] Learning Rate Policy: step
I1009 20:06:31.888523  7747 solver.cpp:337] Iteration 0, Testing net (#0)
I1009 20:06:34.749594  7747 solver.cpp:404]     Test net output #0: accuracy = 0.0888
I1009 20:06:34.749616  7747 solver.cpp:404]     Test net output #1: loss = 10.7532 (* 1 = 10.7532 loss)
I1009 20:06:34.772117  7747 solver.cpp:228] Iteration 0, loss = 9.47867
I1009 20:06:34.772137  7747 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1009 20:06:34.772145  7747 solver.cpp:244]     Train net output #1: loss = 9.47867 (* 1 = 9.47867 loss)
I1009 20:06:34.772168  7747 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1009 20:06:36.428917  7747 solver.cpp:337] Iteration 25, Testing net (#0)
I1009 20:06:39.335940  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1455
I1009 20:06:39.335961  7747 solver.cpp:404]     Test net output #1: loss = 2.29165 (* 1 = 2.29165 loss)
I1009 20:06:41.009820  7747 solver.cpp:337] Iteration 50, Testing net (#0)
I1009 20:06:43.917395  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1388
I1009 20:06:43.917418  7747 solver.cpp:404]     Test net output #1: loss = 2.29324 (* 1 = 2.29324 loss)
I1009 20:06:43.937731  7747 solver.cpp:228] Iteration 50, loss = 2.28642
I1009 20:06:43.937750  7747 solver.cpp:244]     Train net output #0: accuracy = 0.09375
I1009 20:06:43.937757  7747 solver.cpp:244]     Train net output #1: loss = 2.28642 (* 1 = 2.28642 loss)
I1009 20:06:43.937762  7747 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I1009 20:06:45.593221  7747 solver.cpp:337] Iteration 75, Testing net (#0)
I1009 20:06:48.499665  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1683
I1009 20:06:48.499701  7747 solver.cpp:404]     Test net output #1: loss = 2.28508 (* 1 = 2.28508 loss)
I1009 20:06:50.176137  7747 solver.cpp:337] Iteration 100, Testing net (#0)
I1009 20:06:53.080704  7747 solver.cpp:404]     Test net output #0: accuracy = 0.15
I1009 20:06:53.080727  7747 solver.cpp:404]     Test net output #1: loss = 2.29498 (* 1 = 2.29498 loss)
I1009 20:06:53.101003  7747 solver.cpp:228] Iteration 100, loss = 2.28766
I1009 20:06:53.101021  7747 solver.cpp:244]     Train net output #0: accuracy = 0.15625
I1009 20:06:53.101027  7747 solver.cpp:244]     Train net output #1: loss = 2.28766 (* 1 = 2.28766 loss)
I1009 20:06:53.101032  7747 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I1009 20:06:54.757925  7747 solver.cpp:337] Iteration 125, Testing net (#0)
I1009 20:06:57.663738  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1623
I1009 20:06:57.663760  7747 solver.cpp:404]     Test net output #1: loss = 2.26728 (* 1 = 2.26728 loss)
I1009 20:06:59.340347  7747 solver.cpp:337] Iteration 150, Testing net (#0)
I1009 20:07:02.249567  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1883
I1009 20:07:02.249678  7747 solver.cpp:404]     Test net output #1: loss = 2.27053 (* 1 = 2.27053 loss)
I1009 20:07:02.269865  7747 solver.cpp:228] Iteration 150, loss = 2.25336
I1009 20:07:02.269882  7747 solver.cpp:244]     Train net output #0: accuracy = 0.203125
I1009 20:07:02.269903  7747 solver.cpp:244]     Train net output #1: loss = 2.25336 (* 1 = 2.25336 loss)
I1009 20:07:02.269907  7747 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I1009 20:07:03.928973  7747 solver.cpp:337] Iteration 175, Testing net (#0)
I1009 20:07:06.835327  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1769
I1009 20:07:06.835376  7747 solver.cpp:404]     Test net output #1: loss = 2.27855 (* 1 = 2.27855 loss)
I1009 20:07:08.511952  7747 solver.cpp:337] Iteration 200, Testing net (#0)
I1009 20:07:11.417937  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1868
I1009 20:07:11.417985  7747 solver.cpp:404]     Test net output #1: loss = 2.25487 (* 1 = 2.25487 loss)
I1009 20:07:11.438325  7747 solver.cpp:228] Iteration 200, loss = 2.25485
I1009 20:07:11.438344  7747 solver.cpp:244]     Train net output #0: accuracy = 0.21875
I1009 20:07:11.438350  7747 solver.cpp:244]     Train net output #1: loss = 2.25485 (* 1 = 2.25485 loss)
I1009 20:07:11.438354  7747 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I1009 20:07:13.095022  7747 solver.cpp:337] Iteration 225, Testing net (#0)
I1009 20:07:16.000342  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1965
I1009 20:07:16.000362  7747 solver.cpp:404]     Test net output #1: loss = 2.24766 (* 1 = 2.24766 loss)
I1009 20:07:17.678442  7747 solver.cpp:454] Snapshotting to binary proto file cifar-10_relu_AdaGrad_iter_250.caffemodel
I1009 20:07:17.744401  7747 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_relu_AdaGrad_iter_250.solverstate
I1009 20:07:17.771888  7747 solver.cpp:317] Iteration 250, loss = 2.26745
I1009 20:07:17.771924  7747 solver.cpp:337] Iteration 250, Testing net (#0)
I1009 20:07:20.627821  7747 solver.cpp:404]     Test net output #0: accuracy = 0.1869
I1009 20:07:20.627845  7747 solver.cpp:404]     Test net output #1: loss = 2.23716 (* 1 = 2.23716 loss)
I1009 20:07:20.627848  7747 solver.cpp:322] Optimization Done.
I1009 20:07:20.627851  7747 caffe.cpp:254] Optimization Done.
