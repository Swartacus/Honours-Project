I1010 14:47:40.389904  6022 caffe.cpp:217] Using GPUs 0
I1010 14:47:40.392578  6022 caffe.cpp:222] GPU 0: GeForce GTX 750 Ti
I1010 14:47:40.500581  6022 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt"
test_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt"
test_iter: 100
test_interval: 250
base_lr: 0.0001
display: 50
max_iter: 2500
lr_policy: "step"
gamma: 0.1
weight_decay: 0.0005
stepsize: 5000
snapshot: 5000
snapshot_prefix: "cifar-10_relu_RMSProp"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
type: "RMSProp"
I1010 14:47:40.500759  6022 solver.cpp:81] Creating training net from train_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt
I1010 14:47:40.501109  6022 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn1"
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn1"
  top: "bn1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "bn1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "drop1"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv5"
  top: "bn2"
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "bn2"
  top: "bn2"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "bn2"
  top: "drop4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "drop4"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "flatten"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1010 14:47:40.501271  6022 layer_factory.hpp:77] Creating layer data
I1010 14:47:40.501802  6022 net.cpp:100] Creating Layer data
I1010 14:47:40.501818  6022 net.cpp:408] data -> data
I1010 14:47:40.501865  6022 net.cpp:408] data -> label
I1010 14:47:40.501879  6022 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1010 14:47:40.504199  6027 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_train_lmdb
I1010 14:47:40.509625  6022 data_layer.cpp:41] output data size: 64,3,32,32
I1010 14:47:40.511260  6022 net.cpp:150] Setting up data
I1010 14:47:40.511297  6022 net.cpp:157] Top shape: 64 3 32 32 (196608)
I1010 14:47:40.511301  6022 net.cpp:157] Top shape: 64 (64)
I1010 14:47:40.511303  6022 net.cpp:165] Memory required for data: 786688
I1010 14:47:40.511312  6022 layer_factory.hpp:77] Creating layer label_data_1_split
I1010 14:47:40.511320  6022 net.cpp:100] Creating Layer label_data_1_split
I1010 14:47:40.511325  6022 net.cpp:434] label_data_1_split <- label
I1010 14:47:40.511334  6022 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1010 14:47:40.511343  6022 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1010 14:47:40.511395  6022 net.cpp:150] Setting up label_data_1_split
I1010 14:47:40.511400  6022 net.cpp:157] Top shape: 64 (64)
I1010 14:47:40.511404  6022 net.cpp:157] Top shape: 64 (64)
I1010 14:47:40.511404  6022 net.cpp:165] Memory required for data: 787200
I1010 14:47:40.511407  6022 layer_factory.hpp:77] Creating layer conv1
I1010 14:47:40.511420  6022 net.cpp:100] Creating Layer conv1
I1010 14:47:40.511422  6022 net.cpp:434] conv1 <- data
I1010 14:47:40.511426  6022 net.cpp:408] conv1 -> conv1
I1010 14:47:40.648190  6022 net.cpp:150] Setting up conv1
I1010 14:47:40.648210  6022 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1010 14:47:40.648212  6022 net.cpp:165] Memory required for data: 22905600
I1010 14:47:40.648229  6022 layer_factory.hpp:77] Creating layer relu1
I1010 14:47:40.648236  6022 net.cpp:100] Creating Layer relu1
I1010 14:47:40.648239  6022 net.cpp:434] relu1 <- conv1
I1010 14:47:40.648243  6022 net.cpp:395] relu1 -> conv1 (in-place)
I1010 14:47:40.648430  6022 net.cpp:150] Setting up relu1
I1010 14:47:40.648437  6022 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1010 14:47:40.648439  6022 net.cpp:165] Memory required for data: 45024000
I1010 14:47:40.648442  6022 layer_factory.hpp:77] Creating layer conv2
I1010 14:47:40.648449  6022 net.cpp:100] Creating Layer conv2
I1010 14:47:40.648452  6022 net.cpp:434] conv2 <- conv1
I1010 14:47:40.648455  6022 net.cpp:408] conv2 -> conv2
I1010 14:47:40.649863  6022 net.cpp:150] Setting up conv2
I1010 14:47:40.649873  6022 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1010 14:47:40.649875  6022 net.cpp:165] Memory required for data: 64291584
I1010 14:47:40.649883  6022 layer_factory.hpp:77] Creating layer bn1
I1010 14:47:40.649886  6022 net.cpp:100] Creating Layer bn1
I1010 14:47:40.649888  6022 net.cpp:434] bn1 <- conv2
I1010 14:47:40.649891  6022 net.cpp:408] bn1 -> bn1
I1010 14:47:40.650074  6022 net.cpp:150] Setting up bn1
I1010 14:47:40.650079  6022 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1010 14:47:40.650081  6022 net.cpp:165] Memory required for data: 83559168
I1010 14:47:40.650089  6022 layer_factory.hpp:77] Creating layer relu2
I1010 14:47:40.650091  6022 net.cpp:100] Creating Layer relu2
I1010 14:47:40.650094  6022 net.cpp:434] relu2 <- bn1
I1010 14:47:40.650096  6022 net.cpp:395] relu2 -> bn1 (in-place)
I1010 14:47:40.650261  6022 net.cpp:150] Setting up relu2
I1010 14:47:40.650267  6022 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1010 14:47:40.650269  6022 net.cpp:165] Memory required for data: 102826752
I1010 14:47:40.650281  6022 layer_factory.hpp:77] Creating layer drop1
I1010 14:47:40.650285  6022 net.cpp:100] Creating Layer drop1
I1010 14:47:40.650288  6022 net.cpp:434] drop1 <- bn1
I1010 14:47:40.650291  6022 net.cpp:408] drop1 -> drop1
I1010 14:47:40.650347  6022 net.cpp:150] Setting up drop1
I1010 14:47:40.650367  6022 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1010 14:47:40.650368  6022 net.cpp:165] Memory required for data: 122094336
I1010 14:47:40.650370  6022 layer_factory.hpp:77] Creating layer conv3
I1010 14:47:40.650389  6022 net.cpp:100] Creating Layer conv3
I1010 14:47:40.650391  6022 net.cpp:434] conv3 <- drop1
I1010 14:47:40.650408  6022 net.cpp:408] conv3 -> conv3
I1010 14:47:40.651563  6022 net.cpp:150] Setting up conv3
I1010 14:47:40.651572  6022 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1010 14:47:40.651574  6022 net.cpp:165] Memory required for data: 126247680
I1010 14:47:40.651582  6022 layer_factory.hpp:77] Creating layer relu3
I1010 14:47:40.651584  6022 net.cpp:100] Creating Layer relu3
I1010 14:47:40.651587  6022 net.cpp:434] relu3 <- conv3
I1010 14:47:40.651590  6022 net.cpp:395] relu3 -> conv3 (in-place)
I1010 14:47:40.651831  6022 net.cpp:150] Setting up relu3
I1010 14:47:40.651839  6022 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1010 14:47:40.651841  6022 net.cpp:165] Memory required for data: 130401024
I1010 14:47:40.651844  6022 layer_factory.hpp:77] Creating layer conv4
I1010 14:47:40.651849  6022 net.cpp:100] Creating Layer conv4
I1010 14:47:40.651850  6022 net.cpp:434] conv4 <- conv3
I1010 14:47:40.651854  6022 net.cpp:408] conv4 -> conv4
I1010 14:47:40.653725  6022 net.cpp:150] Setting up conv4
I1010 14:47:40.653735  6022 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1010 14:47:40.653738  6022 net.cpp:165] Memory required for data: 136348416
I1010 14:47:40.653743  6022 layer_factory.hpp:77] Creating layer relu4
I1010 14:47:40.653746  6022 net.cpp:100] Creating Layer relu4
I1010 14:47:40.653748  6022 net.cpp:434] relu4 <- conv4
I1010 14:47:40.653751  6022 net.cpp:395] relu4 -> conv4 (in-place)
I1010 14:47:40.653914  6022 net.cpp:150] Setting up relu4
I1010 14:47:40.653920  6022 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1010 14:47:40.653923  6022 net.cpp:165] Memory required for data: 142295808
I1010 14:47:40.653924  6022 layer_factory.hpp:77] Creating layer conv5
I1010 14:47:40.653929  6022 net.cpp:100] Creating Layer conv5
I1010 14:47:40.653931  6022 net.cpp:434] conv5 <- conv4
I1010 14:47:40.653934  6022 net.cpp:408] conv5 -> conv5
I1010 14:47:40.656404  6022 net.cpp:150] Setting up conv5
I1010 14:47:40.656414  6022 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1010 14:47:40.656416  6022 net.cpp:165] Memory required for data: 146277120
I1010 14:47:40.656420  6022 layer_factory.hpp:77] Creating layer bn2
I1010 14:47:40.656425  6022 net.cpp:100] Creating Layer bn2
I1010 14:47:40.656427  6022 net.cpp:434] bn2 <- conv5
I1010 14:47:40.656430  6022 net.cpp:408] bn2 -> bn2
I1010 14:47:40.656617  6022 net.cpp:150] Setting up bn2
I1010 14:47:40.656622  6022 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1010 14:47:40.656625  6022 net.cpp:165] Memory required for data: 150258432
I1010 14:47:40.656630  6022 layer_factory.hpp:77] Creating layer relu5
I1010 14:47:40.656632  6022 net.cpp:100] Creating Layer relu5
I1010 14:47:40.656635  6022 net.cpp:434] relu5 <- bn2
I1010 14:47:40.656637  6022 net.cpp:395] relu5 -> bn2 (in-place)
I1010 14:47:40.656805  6022 net.cpp:150] Setting up relu5
I1010 14:47:40.656811  6022 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1010 14:47:40.656826  6022 net.cpp:165] Memory required for data: 154239744
I1010 14:47:40.656828  6022 layer_factory.hpp:77] Creating layer drop4
I1010 14:47:40.656831  6022 net.cpp:100] Creating Layer drop4
I1010 14:47:40.656834  6022 net.cpp:434] drop4 <- bn2
I1010 14:47:40.656837  6022 net.cpp:408] drop4 -> drop4
I1010 14:47:40.656879  6022 net.cpp:150] Setting up drop4
I1010 14:47:40.656884  6022 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1010 14:47:40.656886  6022 net.cpp:165] Memory required for data: 158221056
I1010 14:47:40.656898  6022 layer_factory.hpp:77] Creating layer conv6
I1010 14:47:40.656905  6022 net.cpp:100] Creating Layer conv6
I1010 14:47:40.656909  6022 net.cpp:434] conv6 <- drop4
I1010 14:47:40.656913  6022 net.cpp:408] conv6 -> conv6
I1010 14:47:40.659422  6022 net.cpp:150] Setting up conv6
I1010 14:47:40.659448  6022 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1010 14:47:40.659451  6022 net.cpp:165] Memory required for data: 159007488
I1010 14:47:40.659459  6022 layer_factory.hpp:77] Creating layer relu6
I1010 14:47:40.659464  6022 net.cpp:100] Creating Layer relu6
I1010 14:47:40.659487  6022 net.cpp:434] relu6 <- conv6
I1010 14:47:40.659492  6022 net.cpp:395] relu6 -> conv6 (in-place)
I1010 14:47:40.659713  6022 net.cpp:150] Setting up relu6
I1010 14:47:40.659721  6022 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1010 14:47:40.659737  6022 net.cpp:165] Memory required for data: 159793920
I1010 14:47:40.659740  6022 layer_factory.hpp:77] Creating layer conv7
I1010 14:47:40.659746  6022 net.cpp:100] Creating Layer conv7
I1010 14:47:40.659749  6022 net.cpp:434] conv7 <- conv6
I1010 14:47:40.659752  6022 net.cpp:408] conv7 -> conv7
I1010 14:47:40.662448  6022 net.cpp:150] Setting up conv7
I1010 14:47:40.662477  6022 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1010 14:47:40.662479  6022 net.cpp:165] Memory required for data: 159990528
I1010 14:47:40.662485  6022 layer_factory.hpp:77] Creating layer relu7
I1010 14:47:40.662490  6022 net.cpp:100] Creating Layer relu7
I1010 14:47:40.662493  6022 net.cpp:434] relu7 <- conv7
I1010 14:47:40.662497  6022 net.cpp:395] relu7 -> conv7 (in-place)
I1010 14:47:40.662753  6022 net.cpp:150] Setting up relu7
I1010 14:47:40.662775  6022 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1010 14:47:40.662778  6022 net.cpp:165] Memory required for data: 160187136
I1010 14:47:40.662781  6022 layer_factory.hpp:77] Creating layer conv8
I1010 14:47:40.662787  6022 net.cpp:100] Creating Layer conv8
I1010 14:47:40.662789  6022 net.cpp:434] conv8 <- conv7
I1010 14:47:40.662793  6022 net.cpp:408] conv8 -> conv8
I1010 14:47:40.664055  6022 net.cpp:150] Setting up conv8
I1010 14:47:40.664064  6022 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1010 14:47:40.664067  6022 net.cpp:165] Memory required for data: 160383744
I1010 14:47:40.664072  6022 layer_factory.hpp:77] Creating layer relu8
I1010 14:47:40.664075  6022 net.cpp:100] Creating Layer relu8
I1010 14:47:40.664077  6022 net.cpp:434] relu8 <- conv8
I1010 14:47:40.664080  6022 net.cpp:395] relu8 -> conv8 (in-place)
I1010 14:47:40.664233  6022 net.cpp:150] Setting up relu8
I1010 14:47:40.664239  6022 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1010 14:47:40.664242  6022 net.cpp:165] Memory required for data: 160580352
I1010 14:47:40.664243  6022 layer_factory.hpp:77] Creating layer conv9
I1010 14:47:40.664248  6022 net.cpp:100] Creating Layer conv9
I1010 14:47:40.664250  6022 net.cpp:434] conv9 <- conv8
I1010 14:47:40.664253  6022 net.cpp:408] conv9 -> conv9
I1010 14:47:40.664988  6022 net.cpp:150] Setting up conv9
I1010 14:47:40.664995  6022 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1010 14:47:40.664999  6022 net.cpp:165] Memory required for data: 160590592
I1010 14:47:40.665002  6022 layer_factory.hpp:77] Creating layer relu9
I1010 14:47:40.665005  6022 net.cpp:100] Creating Layer relu9
I1010 14:47:40.665007  6022 net.cpp:434] relu9 <- conv9
I1010 14:47:40.665010  6022 net.cpp:395] relu9 -> conv9 (in-place)
I1010 14:47:40.665233  6022 net.cpp:150] Setting up relu9
I1010 14:47:40.665241  6022 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1010 14:47:40.665242  6022 net.cpp:165] Memory required for data: 160600832
I1010 14:47:40.665244  6022 layer_factory.hpp:77] Creating layer pool
I1010 14:47:40.665249  6022 net.cpp:100] Creating Layer pool
I1010 14:47:40.665251  6022 net.cpp:434] pool <- conv9
I1010 14:47:40.665254  6022 net.cpp:408] pool -> pool
I1010 14:47:40.665418  6022 net.cpp:150] Setting up pool
I1010 14:47:40.665424  6022 net.cpp:157] Top shape: 64 10 1 1 (640)
I1010 14:47:40.665426  6022 net.cpp:165] Memory required for data: 160603392
I1010 14:47:40.665438  6022 layer_factory.hpp:77] Creating layer flatten
I1010 14:47:40.665442  6022 net.cpp:100] Creating Layer flatten
I1010 14:47:40.665446  6022 net.cpp:434] flatten <- pool
I1010 14:47:40.665448  6022 net.cpp:408] flatten -> flatten
I1010 14:47:40.665482  6022 net.cpp:150] Setting up flatten
I1010 14:47:40.665485  6022 net.cpp:157] Top shape: 64 10 (640)
I1010 14:47:40.665488  6022 net.cpp:165] Memory required for data: 160605952
I1010 14:47:40.665489  6022 layer_factory.hpp:77] Creating layer score
I1010 14:47:40.665493  6022 net.cpp:100] Creating Layer score
I1010 14:47:40.665509  6022 net.cpp:434] score <- flatten
I1010 14:47:40.665513  6022 net.cpp:408] score -> score
I1010 14:47:40.665654  6022 net.cpp:150] Setting up score
I1010 14:47:40.665658  6022 net.cpp:157] Top shape: 64 10 (640)
I1010 14:47:40.665660  6022 net.cpp:165] Memory required for data: 160608512
I1010 14:47:40.665664  6022 layer_factory.hpp:77] Creating layer score_score_0_split
I1010 14:47:40.665668  6022 net.cpp:100] Creating Layer score_score_0_split
I1010 14:47:40.665669  6022 net.cpp:434] score_score_0_split <- score
I1010 14:47:40.665673  6022 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1010 14:47:40.665676  6022 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1010 14:47:40.665714  6022 net.cpp:150] Setting up score_score_0_split
I1010 14:47:40.665719  6022 net.cpp:157] Top shape: 64 10 (640)
I1010 14:47:40.665721  6022 net.cpp:157] Top shape: 64 10 (640)
I1010 14:47:40.665724  6022 net.cpp:165] Memory required for data: 160613632
I1010 14:47:40.665725  6022 layer_factory.hpp:77] Creating layer accuracy
I1010 14:47:40.665729  6022 net.cpp:100] Creating Layer accuracy
I1010 14:47:40.665745  6022 net.cpp:434] accuracy <- score_score_0_split_0
I1010 14:47:40.665747  6022 net.cpp:434] accuracy <- label_data_1_split_0
I1010 14:47:40.665751  6022 net.cpp:408] accuracy -> accuracy
I1010 14:47:40.665757  6022 net.cpp:150] Setting up accuracy
I1010 14:47:40.665761  6022 net.cpp:157] Top shape: (1)
I1010 14:47:40.665763  6022 net.cpp:165] Memory required for data: 160613636
I1010 14:47:40.665766  6022 layer_factory.hpp:77] Creating layer loss
I1010 14:47:40.665786  6022 net.cpp:100] Creating Layer loss
I1010 14:47:40.665787  6022 net.cpp:434] loss <- score_score_0_split_1
I1010 14:47:40.665791  6022 net.cpp:434] loss <- label_data_1_split_1
I1010 14:47:40.665793  6022 net.cpp:408] loss -> loss
I1010 14:47:40.665812  6022 layer_factory.hpp:77] Creating layer loss
I1010 14:47:40.666128  6022 net.cpp:150] Setting up loss
I1010 14:47:40.666136  6022 net.cpp:157] Top shape: (1)
I1010 14:47:40.666152  6022 net.cpp:160]     with loss weight 1
I1010 14:47:40.666164  6022 net.cpp:165] Memory required for data: 160613640
I1010 14:47:40.666167  6022 net.cpp:226] loss needs backward computation.
I1010 14:47:40.666173  6022 net.cpp:228] accuracy does not need backward computation.
I1010 14:47:40.666177  6022 net.cpp:226] score_score_0_split needs backward computation.
I1010 14:47:40.666193  6022 net.cpp:226] score needs backward computation.
I1010 14:47:40.666196  6022 net.cpp:226] flatten needs backward computation.
I1010 14:47:40.666198  6022 net.cpp:226] pool needs backward computation.
I1010 14:47:40.666200  6022 net.cpp:226] relu9 needs backward computation.
I1010 14:47:40.666215  6022 net.cpp:226] conv9 needs backward computation.
I1010 14:47:40.666218  6022 net.cpp:226] relu8 needs backward computation.
I1010 14:47:40.666219  6022 net.cpp:226] conv8 needs backward computation.
I1010 14:47:40.666221  6022 net.cpp:226] relu7 needs backward computation.
I1010 14:47:40.666224  6022 net.cpp:226] conv7 needs backward computation.
I1010 14:47:40.666225  6022 net.cpp:226] relu6 needs backward computation.
I1010 14:47:40.666227  6022 net.cpp:226] conv6 needs backward computation.
I1010 14:47:40.666229  6022 net.cpp:226] drop4 needs backward computation.
I1010 14:47:40.666231  6022 net.cpp:226] relu5 needs backward computation.
I1010 14:47:40.666234  6022 net.cpp:226] bn2 needs backward computation.
I1010 14:47:40.666244  6022 net.cpp:226] conv5 needs backward computation.
I1010 14:47:40.666245  6022 net.cpp:226] relu4 needs backward computation.
I1010 14:47:40.666247  6022 net.cpp:226] conv4 needs backward computation.
I1010 14:47:40.666250  6022 net.cpp:226] relu3 needs backward computation.
I1010 14:47:40.666252  6022 net.cpp:226] conv3 needs backward computation.
I1010 14:47:40.666254  6022 net.cpp:226] drop1 needs backward computation.
I1010 14:47:40.666256  6022 net.cpp:226] relu2 needs backward computation.
I1010 14:47:40.666259  6022 net.cpp:226] bn1 needs backward computation.
I1010 14:47:40.666260  6022 net.cpp:226] conv2 needs backward computation.
I1010 14:47:40.666262  6022 net.cpp:226] relu1 needs backward computation.
I1010 14:47:40.666265  6022 net.cpp:226] conv1 needs backward computation.
I1010 14:47:40.666267  6022 net.cpp:228] label_data_1_split does not need backward computation.
I1010 14:47:40.666270  6022 net.cpp:228] data does not need backward computation.
I1010 14:47:40.666272  6022 net.cpp:270] This network produces output accuracy
I1010 14:47:40.666288  6022 net.cpp:270] This network produces output loss
I1010 14:47:40.666301  6022 net.cpp:283] Network initialization done.
I1010 14:47:40.666522  6022 solver.cpp:181] Creating test net (#0) specified by test_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt
I1010 14:47:40.666694  6022 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn1"
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "bn1"
  top: "bn1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "bn1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "drop1"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv5"
  top: "bn2"
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "bn2"
  top: "bn2"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "bn2"
  top: "drop4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "drop4"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "flatten"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1010 14:47:40.666807  6022 layer_factory.hpp:77] Creating layer data
I1010 14:47:40.666887  6022 net.cpp:100] Creating Layer data
I1010 14:47:40.666892  6022 net.cpp:408] data -> data
I1010 14:47:40.666896  6022 net.cpp:408] data -> label
I1010 14:47:40.666903  6022 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1010 14:47:40.667608  6029 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_test_lmdb
I1010 14:47:40.667727  6022 data_layer.cpp:41] output data size: 100,3,32,32
I1010 14:47:40.669736  6022 net.cpp:150] Setting up data
I1010 14:47:40.669770  6022 net.cpp:157] Top shape: 100 3 32 32 (307200)
I1010 14:47:40.669788  6022 net.cpp:157] Top shape: 100 (100)
I1010 14:47:40.669790  6022 net.cpp:165] Memory required for data: 1229200
I1010 14:47:40.669795  6022 layer_factory.hpp:77] Creating layer label_data_1_split
I1010 14:47:40.669817  6022 net.cpp:100] Creating Layer label_data_1_split
I1010 14:47:40.669821  6022 net.cpp:434] label_data_1_split <- label
I1010 14:47:40.669824  6022 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1010 14:47:40.669832  6022 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1010 14:47:40.669903  6022 net.cpp:150] Setting up label_data_1_split
I1010 14:47:40.669922  6022 net.cpp:157] Top shape: 100 (100)
I1010 14:47:40.669929  6022 net.cpp:157] Top shape: 100 (100)
I1010 14:47:40.669944  6022 net.cpp:165] Memory required for data: 1230000
I1010 14:47:40.669948  6022 layer_factory.hpp:77] Creating layer conv1
I1010 14:47:40.669957  6022 net.cpp:100] Creating Layer conv1
I1010 14:47:40.669960  6022 net.cpp:434] conv1 <- data
I1010 14:47:40.669965  6022 net.cpp:408] conv1 -> conv1
I1010 14:47:40.671100  6022 net.cpp:150] Setting up conv1
I1010 14:47:40.671124  6022 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1010 14:47:40.671126  6022 net.cpp:165] Memory required for data: 35790000
I1010 14:47:40.671135  6022 layer_factory.hpp:77] Creating layer relu1
I1010 14:47:40.671139  6022 net.cpp:100] Creating Layer relu1
I1010 14:47:40.671144  6022 net.cpp:434] relu1 <- conv1
I1010 14:47:40.671161  6022 net.cpp:395] relu1 -> conv1 (in-place)
I1010 14:47:40.671483  6022 net.cpp:150] Setting up relu1
I1010 14:47:40.671494  6022 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1010 14:47:40.671497  6022 net.cpp:165] Memory required for data: 70350000
I1010 14:47:40.671500  6022 layer_factory.hpp:77] Creating layer conv2
I1010 14:47:40.671520  6022 net.cpp:100] Creating Layer conv2
I1010 14:47:40.671522  6022 net.cpp:434] conv2 <- conv1
I1010 14:47:40.671530  6022 net.cpp:408] conv2 -> conv2
I1010 14:47:40.672837  6022 net.cpp:150] Setting up conv2
I1010 14:47:40.672847  6022 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1010 14:47:40.672852  6022 net.cpp:165] Memory required for data: 100455600
I1010 14:47:40.672859  6022 layer_factory.hpp:77] Creating layer bn1
I1010 14:47:40.672864  6022 net.cpp:100] Creating Layer bn1
I1010 14:47:40.672866  6022 net.cpp:434] bn1 <- conv2
I1010 14:47:40.672870  6022 net.cpp:408] bn1 -> bn1
I1010 14:47:40.673056  6022 net.cpp:150] Setting up bn1
I1010 14:47:40.673063  6022 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1010 14:47:40.673064  6022 net.cpp:165] Memory required for data: 130561200
I1010 14:47:40.673071  6022 layer_factory.hpp:77] Creating layer relu2
I1010 14:47:40.673075  6022 net.cpp:100] Creating Layer relu2
I1010 14:47:40.673077  6022 net.cpp:434] relu2 <- bn1
I1010 14:47:40.673082  6022 net.cpp:395] relu2 -> bn1 (in-place)
I1010 14:47:40.673302  6022 net.cpp:150] Setting up relu2
I1010 14:47:40.673313  6022 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1010 14:47:40.673316  6022 net.cpp:165] Memory required for data: 160666800
I1010 14:47:40.673318  6022 layer_factory.hpp:77] Creating layer drop1
I1010 14:47:40.673323  6022 net.cpp:100] Creating Layer drop1
I1010 14:47:40.673327  6022 net.cpp:434] drop1 <- bn1
I1010 14:47:40.673331  6022 net.cpp:408] drop1 -> drop1
I1010 14:47:40.673365  6022 net.cpp:150] Setting up drop1
I1010 14:47:40.673370  6022 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1010 14:47:40.673372  6022 net.cpp:165] Memory required for data: 190772400
I1010 14:47:40.673375  6022 layer_factory.hpp:77] Creating layer conv3
I1010 14:47:40.673382  6022 net.cpp:100] Creating Layer conv3
I1010 14:47:40.673384  6022 net.cpp:434] conv3 <- drop1
I1010 14:47:40.673388  6022 net.cpp:408] conv3 -> conv3
I1010 14:47:40.674444  6022 net.cpp:150] Setting up conv3
I1010 14:47:40.674454  6022 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1010 14:47:40.674456  6022 net.cpp:165] Memory required for data: 197262000
I1010 14:47:40.674463  6022 layer_factory.hpp:77] Creating layer relu3
I1010 14:47:40.674469  6022 net.cpp:100] Creating Layer relu3
I1010 14:47:40.674471  6022 net.cpp:434] relu3 <- conv3
I1010 14:47:40.674474  6022 net.cpp:395] relu3 -> conv3 (in-place)
I1010 14:47:40.674685  6022 net.cpp:150] Setting up relu3
I1010 14:47:40.674695  6022 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1010 14:47:40.674697  6022 net.cpp:165] Memory required for data: 203751600
I1010 14:47:40.674700  6022 layer_factory.hpp:77] Creating layer conv4
I1010 14:47:40.674705  6022 net.cpp:100] Creating Layer conv4
I1010 14:47:40.674708  6022 net.cpp:434] conv4 <- conv3
I1010 14:47:40.674712  6022 net.cpp:408] conv4 -> conv4
I1010 14:47:40.676533  6022 net.cpp:150] Setting up conv4
I1010 14:47:40.676543  6022 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1010 14:47:40.676545  6022 net.cpp:165] Memory required for data: 213044400
I1010 14:47:40.676550  6022 layer_factory.hpp:77] Creating layer relu4
I1010 14:47:40.676554  6022 net.cpp:100] Creating Layer relu4
I1010 14:47:40.676556  6022 net.cpp:434] relu4 <- conv4
I1010 14:47:40.676559  6022 net.cpp:395] relu4 -> conv4 (in-place)
I1010 14:47:40.676692  6022 net.cpp:150] Setting up relu4
I1010 14:47:40.676699  6022 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1010 14:47:40.676702  6022 net.cpp:165] Memory required for data: 222337200
I1010 14:47:40.676703  6022 layer_factory.hpp:77] Creating layer conv5
I1010 14:47:40.676709  6022 net.cpp:100] Creating Layer conv5
I1010 14:47:40.676712  6022 net.cpp:434] conv5 <- conv4
I1010 14:47:40.676715  6022 net.cpp:408] conv5 -> conv5
I1010 14:47:40.679718  6022 net.cpp:150] Setting up conv5
I1010 14:47:40.679746  6022 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1010 14:47:40.679749  6022 net.cpp:165] Memory required for data: 228558000
I1010 14:47:40.679754  6022 layer_factory.hpp:77] Creating layer bn2
I1010 14:47:40.679760  6022 net.cpp:100] Creating Layer bn2
I1010 14:47:40.679764  6022 net.cpp:434] bn2 <- conv5
I1010 14:47:40.679767  6022 net.cpp:408] bn2 -> bn2
I1010 14:47:40.679980  6022 net.cpp:150] Setting up bn2
I1010 14:47:40.679985  6022 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1010 14:47:40.679986  6022 net.cpp:165] Memory required for data: 234778800
I1010 14:47:40.679991  6022 layer_factory.hpp:77] Creating layer relu5
I1010 14:47:40.679994  6022 net.cpp:100] Creating Layer relu5
I1010 14:47:40.679996  6022 net.cpp:434] relu5 <- bn2
I1010 14:47:40.679999  6022 net.cpp:395] relu5 -> bn2 (in-place)
I1010 14:47:40.680266  6022 net.cpp:150] Setting up relu5
I1010 14:47:40.680274  6022 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1010 14:47:40.680277  6022 net.cpp:165] Memory required for data: 240999600
I1010 14:47:40.680279  6022 layer_factory.hpp:77] Creating layer drop4
I1010 14:47:40.680284  6022 net.cpp:100] Creating Layer drop4
I1010 14:47:40.680285  6022 net.cpp:434] drop4 <- bn2
I1010 14:47:40.680289  6022 net.cpp:408] drop4 -> drop4
I1010 14:47:40.680335  6022 net.cpp:150] Setting up drop4
I1010 14:47:40.680358  6022 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1010 14:47:40.680359  6022 net.cpp:165] Memory required for data: 247220400
I1010 14:47:40.680361  6022 layer_factory.hpp:77] Creating layer conv6
I1010 14:47:40.680382  6022 net.cpp:100] Creating Layer conv6
I1010 14:47:40.680402  6022 net.cpp:434] conv6 <- drop4
I1010 14:47:40.680405  6022 net.cpp:408] conv6 -> conv6
I1010 14:47:40.682876  6022 net.cpp:150] Setting up conv6
I1010 14:47:40.682886  6022 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1010 14:47:40.682888  6022 net.cpp:165] Memory required for data: 248449200
I1010 14:47:40.682896  6022 layer_factory.hpp:77] Creating layer relu6
I1010 14:47:40.682900  6022 net.cpp:100] Creating Layer relu6
I1010 14:47:40.682903  6022 net.cpp:434] relu6 <- conv6
I1010 14:47:40.682905  6022 net.cpp:395] relu6 -> conv6 (in-place)
I1010 14:47:40.683135  6022 net.cpp:150] Setting up relu6
I1010 14:47:40.683143  6022 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1010 14:47:40.683145  6022 net.cpp:165] Memory required for data: 249678000
I1010 14:47:40.683147  6022 layer_factory.hpp:77] Creating layer conv7
I1010 14:47:40.683153  6022 net.cpp:100] Creating Layer conv7
I1010 14:47:40.683156  6022 net.cpp:434] conv7 <- conv6
I1010 14:47:40.683158  6022 net.cpp:408] conv7 -> conv7
I1010 14:47:40.685744  6022 net.cpp:150] Setting up conv7
I1010 14:47:40.685770  6022 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1010 14:47:40.685772  6022 net.cpp:165] Memory required for data: 249985200
I1010 14:47:40.685777  6022 layer_factory.hpp:77] Creating layer relu7
I1010 14:47:40.685782  6022 net.cpp:100] Creating Layer relu7
I1010 14:47:40.685784  6022 net.cpp:434] relu7 <- conv7
I1010 14:47:40.685787  6022 net.cpp:395] relu7 -> conv7 (in-place)
I1010 14:47:40.685968  6022 net.cpp:150] Setting up relu7
I1010 14:47:40.685974  6022 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1010 14:47:40.685976  6022 net.cpp:165] Memory required for data: 250292400
I1010 14:47:40.685978  6022 layer_factory.hpp:77] Creating layer conv8
I1010 14:47:40.685984  6022 net.cpp:100] Creating Layer conv8
I1010 14:47:40.685986  6022 net.cpp:434] conv8 <- conv7
I1010 14:47:40.685989  6022 net.cpp:408] conv8 -> conv8
I1010 14:47:40.687033  6022 net.cpp:150] Setting up conv8
I1010 14:47:40.687057  6022 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1010 14:47:40.687060  6022 net.cpp:165] Memory required for data: 250599600
I1010 14:47:40.687065  6022 layer_factory.hpp:77] Creating layer relu8
I1010 14:47:40.687083  6022 net.cpp:100] Creating Layer relu8
I1010 14:47:40.687084  6022 net.cpp:434] relu8 <- conv8
I1010 14:47:40.687088  6022 net.cpp:395] relu8 -> conv8 (in-place)
I1010 14:47:40.687438  6022 net.cpp:150] Setting up relu8
I1010 14:47:40.687448  6022 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1010 14:47:40.687450  6022 net.cpp:165] Memory required for data: 250906800
I1010 14:47:40.687453  6022 layer_factory.hpp:77] Creating layer conv9
I1010 14:47:40.687460  6022 net.cpp:100] Creating Layer conv9
I1010 14:47:40.687463  6022 net.cpp:434] conv9 <- conv8
I1010 14:47:40.687466  6022 net.cpp:408] conv9 -> conv9
I1010 14:47:40.688457  6022 net.cpp:150] Setting up conv9
I1010 14:47:40.688468  6022 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1010 14:47:40.688472  6022 net.cpp:165] Memory required for data: 250922800
I1010 14:47:40.688477  6022 layer_factory.hpp:77] Creating layer relu9
I1010 14:47:40.688482  6022 net.cpp:100] Creating Layer relu9
I1010 14:47:40.688483  6022 net.cpp:434] relu9 <- conv9
I1010 14:47:40.688498  6022 net.cpp:395] relu9 -> conv9 (in-place)
I1010 14:47:40.689014  6022 net.cpp:150] Setting up relu9
I1010 14:47:40.689028  6022 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1010 14:47:40.689029  6022 net.cpp:165] Memory required for data: 250938800
I1010 14:47:40.689033  6022 layer_factory.hpp:77] Creating layer pool
I1010 14:47:40.689038  6022 net.cpp:100] Creating Layer pool
I1010 14:47:40.689040  6022 net.cpp:434] pool <- conv9
I1010 14:47:40.689044  6022 net.cpp:408] pool -> pool
I1010 14:47:40.689193  6022 net.cpp:150] Setting up pool
I1010 14:47:40.689198  6022 net.cpp:157] Top shape: 100 10 1 1 (1000)
I1010 14:47:40.689201  6022 net.cpp:165] Memory required for data: 250942800
I1010 14:47:40.689203  6022 layer_factory.hpp:77] Creating layer flatten
I1010 14:47:40.689208  6022 net.cpp:100] Creating Layer flatten
I1010 14:47:40.689209  6022 net.cpp:434] flatten <- pool
I1010 14:47:40.689213  6022 net.cpp:408] flatten -> flatten
I1010 14:47:40.689234  6022 net.cpp:150] Setting up flatten
I1010 14:47:40.689239  6022 net.cpp:157] Top shape: 100 10 (1000)
I1010 14:47:40.689241  6022 net.cpp:165] Memory required for data: 250946800
I1010 14:47:40.689244  6022 layer_factory.hpp:77] Creating layer score
I1010 14:47:40.689249  6022 net.cpp:100] Creating Layer score
I1010 14:47:40.689251  6022 net.cpp:434] score <- flatten
I1010 14:47:40.689254  6022 net.cpp:408] score -> score
I1010 14:47:40.689348  6022 net.cpp:150] Setting up score
I1010 14:47:40.689353  6022 net.cpp:157] Top shape: 100 10 (1000)
I1010 14:47:40.689355  6022 net.cpp:165] Memory required for data: 250950800
I1010 14:47:40.689360  6022 layer_factory.hpp:77] Creating layer score_score_0_split
I1010 14:47:40.689363  6022 net.cpp:100] Creating Layer score_score_0_split
I1010 14:47:40.689365  6022 net.cpp:434] score_score_0_split <- score
I1010 14:47:40.689369  6022 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1010 14:47:40.689373  6022 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1010 14:47:40.689401  6022 net.cpp:150] Setting up score_score_0_split
I1010 14:47:40.689404  6022 net.cpp:157] Top shape: 100 10 (1000)
I1010 14:47:40.689407  6022 net.cpp:157] Top shape: 100 10 (1000)
I1010 14:47:40.689409  6022 net.cpp:165] Memory required for data: 250958800
I1010 14:47:40.689411  6022 layer_factory.hpp:77] Creating layer accuracy
I1010 14:47:40.689417  6022 net.cpp:100] Creating Layer accuracy
I1010 14:47:40.689419  6022 net.cpp:434] accuracy <- score_score_0_split_0
I1010 14:47:40.689422  6022 net.cpp:434] accuracy <- label_data_1_split_0
I1010 14:47:40.689426  6022 net.cpp:408] accuracy -> accuracy
I1010 14:47:40.689431  6022 net.cpp:150] Setting up accuracy
I1010 14:47:40.689435  6022 net.cpp:157] Top shape: (1)
I1010 14:47:40.689436  6022 net.cpp:165] Memory required for data: 250958804
I1010 14:47:40.689438  6022 layer_factory.hpp:77] Creating layer loss
I1010 14:47:40.689441  6022 net.cpp:100] Creating Layer loss
I1010 14:47:40.689443  6022 net.cpp:434] loss <- score_score_0_split_1
I1010 14:47:40.689445  6022 net.cpp:434] loss <- label_data_1_split_1
I1010 14:47:40.689448  6022 net.cpp:408] loss -> loss
I1010 14:47:40.689455  6022 layer_factory.hpp:77] Creating layer loss
I1010 14:47:40.690052  6022 net.cpp:150] Setting up loss
I1010 14:47:40.690063  6022 net.cpp:157] Top shape: (1)
I1010 14:47:40.690078  6022 net.cpp:160]     with loss weight 1
I1010 14:47:40.690089  6022 net.cpp:165] Memory required for data: 250958808
I1010 14:47:40.690093  6022 net.cpp:226] loss needs backward computation.
I1010 14:47:40.690095  6022 net.cpp:228] accuracy does not need backward computation.
I1010 14:47:40.690099  6022 net.cpp:226] score_score_0_split needs backward computation.
I1010 14:47:40.690101  6022 net.cpp:226] score needs backward computation.
I1010 14:47:40.690104  6022 net.cpp:226] flatten needs backward computation.
I1010 14:47:40.690105  6022 net.cpp:226] pool needs backward computation.
I1010 14:47:40.690107  6022 net.cpp:226] relu9 needs backward computation.
I1010 14:47:40.690109  6022 net.cpp:226] conv9 needs backward computation.
I1010 14:47:40.690119  6022 net.cpp:226] relu8 needs backward computation.
I1010 14:47:40.690121  6022 net.cpp:226] conv8 needs backward computation.
I1010 14:47:40.690124  6022 net.cpp:226] relu7 needs backward computation.
I1010 14:47:40.690125  6022 net.cpp:226] conv7 needs backward computation.
I1010 14:47:40.690127  6022 net.cpp:226] relu6 needs backward computation.
I1010 14:47:40.690129  6022 net.cpp:226] conv6 needs backward computation.
I1010 14:47:40.690131  6022 net.cpp:226] drop4 needs backward computation.
I1010 14:47:40.690134  6022 net.cpp:226] relu5 needs backward computation.
I1010 14:47:40.690135  6022 net.cpp:226] bn2 needs backward computation.
I1010 14:47:40.690138  6022 net.cpp:226] conv5 needs backward computation.
I1010 14:47:40.690140  6022 net.cpp:226] relu4 needs backward computation.
I1010 14:47:40.690142  6022 net.cpp:226] conv4 needs backward computation.
I1010 14:47:40.690145  6022 net.cpp:226] relu3 needs backward computation.
I1010 14:47:40.690146  6022 net.cpp:226] conv3 needs backward computation.
I1010 14:47:40.690148  6022 net.cpp:226] drop1 needs backward computation.
I1010 14:47:40.690150  6022 net.cpp:226] relu2 needs backward computation.
I1010 14:47:40.690152  6022 net.cpp:226] bn1 needs backward computation.
I1010 14:47:40.690155  6022 net.cpp:226] conv2 needs backward computation.
I1010 14:47:40.690156  6022 net.cpp:226] relu1 needs backward computation.
I1010 14:47:40.690158  6022 net.cpp:226] conv1 needs backward computation.
I1010 14:47:40.690161  6022 net.cpp:228] label_data_1_split does not need backward computation.
I1010 14:47:40.690165  6022 net.cpp:228] data does not need backward computation.
I1010 14:47:40.690166  6022 net.cpp:270] This network produces output accuracy
I1010 14:47:40.690168  6022 net.cpp:270] This network produces output loss
I1010 14:47:40.690182  6022 net.cpp:283] Network initialization done.
I1010 14:47:40.690232  6022 solver.cpp:60] Solver scaffolding done.
I1010 14:47:40.690986  6022 caffe.cpp:251] Starting Optimization
I1010 14:47:40.690990  6022 solver.cpp:279] Solving 
I1010 14:47:40.690992  6022 solver.cpp:280] Learning Rate Policy: step
I1010 14:47:40.692914  6022 solver.cpp:337] Iteration 0, Testing net (#0)
I1010 14:47:44.292616  6022 solver.cpp:404]     Test net output #0: accuracy = 0.0933
I1010 14:47:44.292656  6022 solver.cpp:404]     Test net output #1: loss = 79.188 (* 1 = 79.188 loss)
I1010 14:47:44.331084  6022 solver.cpp:228] Iteration 0, loss = 2.95507
I1010 14:47:44.331104  6022 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1010 14:47:44.331110  6022 solver.cpp:244]     Train net output #1: loss = 2.95507 (* 1 = 2.95507 loss)
I1010 14:47:44.331123  6022 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I1010 14:47:48.641652  6022 solver.cpp:228] Iteration 50, loss = 2.2802
I1010 14:47:48.641679  6022 solver.cpp:244]     Train net output #0: accuracy = 0.1875
I1010 14:47:48.641686  6022 solver.cpp:244]     Train net output #1: loss = 2.2802 (* 1 = 2.2802 loss)
I1010 14:47:48.641690  6022 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
I1010 14:47:52.930860  6022 solver.cpp:228] Iteration 100, loss = 2.0656
I1010 14:47:52.930884  6022 solver.cpp:244]     Train net output #0: accuracy = 0.21875
I1010 14:47:52.930891  6022 solver.cpp:244]     Train net output #1: loss = 2.0656 (* 1 = 2.0656 loss)
I1010 14:47:52.930896  6022 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I1010 14:47:57.126423  6022 solver.cpp:228] Iteration 150, loss = 2.04092
I1010 14:47:57.126442  6022 solver.cpp:244]     Train net output #0: accuracy = 0.28125
I1010 14:47:57.126463  6022 solver.cpp:244]     Train net output #1: loss = 2.04092 (* 1 = 2.04092 loss)
I1010 14:47:57.126467  6022 sgd_solver.cpp:106] Iteration 150, lr = 0.0001
I1010 14:48:01.298844  6022 solver.cpp:228] Iteration 200, loss = 1.89026
I1010 14:48:01.298868  6022 solver.cpp:244]     Train net output #0: accuracy = 0.296875
I1010 14:48:01.298876  6022 solver.cpp:244]     Train net output #1: loss = 1.89026 (* 1 = 1.89026 loss)
I1010 14:48:01.298893  6022 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I1010 14:48:05.541638  6022 solver.cpp:337] Iteration 250, Testing net (#0)
I1010 14:48:09.120990  6022 solver.cpp:404]     Test net output #0: accuracy = 0.3058
I1010 14:48:09.121016  6022 solver.cpp:404]     Test net output #1: loss = 1.94619 (* 1 = 1.94619 loss)
I1010 14:48:09.152576  6022 solver.cpp:228] Iteration 250, loss = 2.01466
I1010 14:48:09.152611  6022 solver.cpp:244]     Train net output #0: accuracy = 0.296875
I1010 14:48:09.152618  6022 solver.cpp:244]     Train net output #1: loss = 2.01466 (* 1 = 2.01466 loss)
I1010 14:48:09.152622  6022 sgd_solver.cpp:106] Iteration 250, lr = 0.0001
I1010 14:48:13.320520  6022 solver.cpp:228] Iteration 300, loss = 2.05215
I1010 14:48:13.320627  6022 solver.cpp:244]     Train net output #0: accuracy = 0.234375
I1010 14:48:13.320637  6022 solver.cpp:244]     Train net output #1: loss = 2.05215 (* 1 = 2.05215 loss)
I1010 14:48:13.320654  6022 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I1010 14:48:17.470579  6022 solver.cpp:228] Iteration 350, loss = 1.92414
I1010 14:48:17.470613  6022 solver.cpp:244]     Train net output #0: accuracy = 0.34375
I1010 14:48:17.470620  6022 solver.cpp:244]     Train net output #1: loss = 1.92414 (* 1 = 1.92414 loss)
I1010 14:48:17.470636  6022 sgd_solver.cpp:106] Iteration 350, lr = 0.0001
I1010 14:48:21.621716  6022 solver.cpp:228] Iteration 400, loss = 1.86781
I1010 14:48:21.621736  6022 solver.cpp:244]     Train net output #0: accuracy = 0.328125
I1010 14:48:21.621743  6022 solver.cpp:244]     Train net output #1: loss = 1.86781 (* 1 = 1.86781 loss)
I1010 14:48:21.621760  6022 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I1010 14:48:25.769613  6022 solver.cpp:228] Iteration 450, loss = 1.60874
I1010 14:48:25.769647  6022 solver.cpp:244]     Train net output #0: accuracy = 0.421875
I1010 14:48:25.769654  6022 solver.cpp:244]     Train net output #1: loss = 1.60874 (* 1 = 1.60874 loss)
I1010 14:48:25.769657  6022 sgd_solver.cpp:106] Iteration 450, lr = 0.0001
I1010 14:48:29.892658  6022 solver.cpp:337] Iteration 500, Testing net (#0)
I1010 14:48:33.394467  6022 solver.cpp:404]     Test net output #0: accuracy = 0.3579
I1010 14:48:33.394503  6022 solver.cpp:404]     Test net output #1: loss = 1.93211 (* 1 = 1.93211 loss)
I1010 14:48:33.420866  6022 solver.cpp:228] Iteration 500, loss = 1.77991
I1010 14:48:33.420881  6022 solver.cpp:244]     Train net output #0: accuracy = 0.375
I1010 14:48:33.420900  6022 solver.cpp:244]     Train net output #1: loss = 1.77991 (* 1 = 1.77991 loss)
I1010 14:48:33.420905  6022 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I1010 14:48:37.573163  6022 solver.cpp:228] Iteration 550, loss = 1.75966
I1010 14:48:37.573182  6022 solver.cpp:244]     Train net output #0: accuracy = 0.375
I1010 14:48:37.573189  6022 solver.cpp:244]     Train net output #1: loss = 1.75966 (* 1 = 1.75966 loss)
I1010 14:48:37.573194  6022 sgd_solver.cpp:106] Iteration 550, lr = 0.0001
I1010 14:48:41.721763  6022 solver.cpp:228] Iteration 600, loss = 1.8478
I1010 14:48:41.721784  6022 solver.cpp:244]     Train net output #0: accuracy = 0.375
I1010 14:48:41.721791  6022 solver.cpp:244]     Train net output #1: loss = 1.8478 (* 1 = 1.8478 loss)
I1010 14:48:41.721796  6022 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I1010 14:48:45.873795  6022 solver.cpp:228] Iteration 650, loss = 1.86366
I1010 14:48:45.873839  6022 solver.cpp:244]     Train net output #0: accuracy = 0.375
I1010 14:48:45.873847  6022 solver.cpp:244]     Train net output #1: loss = 1.86366 (* 1 = 1.86366 loss)
I1010 14:48:45.873865  6022 sgd_solver.cpp:106] Iteration 650, lr = 0.0001
I1010 14:48:50.022572  6022 solver.cpp:228] Iteration 700, loss = 1.76175
I1010 14:48:50.022593  6022 solver.cpp:244]     Train net output #0: accuracy = 0.40625
I1010 14:48:50.022600  6022 solver.cpp:244]     Train net output #1: loss = 1.76175 (* 1 = 1.76175 loss)
I1010 14:48:50.022619  6022 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I1010 14:48:54.146144  6022 solver.cpp:337] Iteration 750, Testing net (#0)
I1010 14:48:57.644807  6022 solver.cpp:404]     Test net output #0: accuracy = 0.448
I1010 14:48:57.644829  6022 solver.cpp:404]     Test net output #1: loss = 1.6321 (* 1 = 1.6321 loss)
I1010 14:48:57.671123  6022 solver.cpp:228] Iteration 750, loss = 1.71952
I1010 14:48:57.671136  6022 solver.cpp:244]     Train net output #0: accuracy = 0.375
I1010 14:48:57.671142  6022 solver.cpp:244]     Train net output #1: loss = 1.71952 (* 1 = 1.71952 loss)
I1010 14:48:57.671162  6022 sgd_solver.cpp:106] Iteration 750, lr = 0.0001
I1010 14:49:01.827042  6022 solver.cpp:228] Iteration 800, loss = 1.60162
I1010 14:49:01.827062  6022 solver.cpp:244]     Train net output #0: accuracy = 0.484375
I1010 14:49:01.827069  6022 solver.cpp:244]     Train net output #1: loss = 1.60162 (* 1 = 1.60162 loss)
I1010 14:49:01.827087  6022 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I1010 14:49:05.977700  6022 solver.cpp:228] Iteration 850, loss = 1.67053
I1010 14:49:05.977721  6022 solver.cpp:244]     Train net output #0: accuracy = 0.453125
I1010 14:49:05.977728  6022 solver.cpp:244]     Train net output #1: loss = 1.67053 (* 1 = 1.67053 loss)
I1010 14:49:05.977731  6022 sgd_solver.cpp:106] Iteration 850, lr = 0.0001
I1010 14:49:10.132124  6022 solver.cpp:228] Iteration 900, loss = 1.58332
I1010 14:49:10.132144  6022 solver.cpp:244]     Train net output #0: accuracy = 0.375
I1010 14:49:10.132151  6022 solver.cpp:244]     Train net output #1: loss = 1.58332 (* 1 = 1.58332 loss)
I1010 14:49:10.132154  6022 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I1010 14:49:14.282515  6022 solver.cpp:228] Iteration 950, loss = 1.4376
I1010 14:49:14.282549  6022 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I1010 14:49:14.282557  6022 solver.cpp:244]     Train net output #1: loss = 1.4376 (* 1 = 1.4376 loss)
I1010 14:49:14.282559  6022 sgd_solver.cpp:106] Iteration 950, lr = 0.0001
I1010 14:49:18.410240  6022 solver.cpp:337] Iteration 1000, Testing net (#0)
I1010 14:49:21.911448  6022 solver.cpp:404]     Test net output #0: accuracy = 0.4246
I1010 14:49:21.911484  6022 solver.cpp:404]     Test net output #1: loss = 1.88239 (* 1 = 1.88239 loss)
I1010 14:49:21.937983  6022 solver.cpp:228] Iteration 1000, loss = 1.43162
I1010 14:49:21.937997  6022 solver.cpp:244]     Train net output #0: accuracy = 0.390625
I1010 14:49:21.938025  6022 solver.cpp:244]     Train net output #1: loss = 1.43162 (* 1 = 1.43162 loss)
I1010 14:49:21.938030  6022 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I1010 14:49:26.093053  6022 solver.cpp:228] Iteration 1050, loss = 1.70166
I1010 14:49:26.093075  6022 solver.cpp:244]     Train net output #0: accuracy = 0.4375
I1010 14:49:26.093081  6022 solver.cpp:244]     Train net output #1: loss = 1.70166 (* 1 = 1.70166 loss)
I1010 14:49:26.093085  6022 sgd_solver.cpp:106] Iteration 1050, lr = 0.0001
I1010 14:49:30.350682  6022 solver.cpp:228] Iteration 1100, loss = 1.48566
I1010 14:49:30.350703  6022 solver.cpp:244]     Train net output #0: accuracy = 0.484375
I1010 14:49:30.350713  6022 solver.cpp:244]     Train net output #1: loss = 1.48566 (* 1 = 1.48566 loss)
I1010 14:49:30.350731  6022 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I1010 14:49:34.684299  6022 solver.cpp:228] Iteration 1150, loss = 1.601
I1010 14:49:34.684334  6022 solver.cpp:244]     Train net output #0: accuracy = 0.46875
I1010 14:49:34.684341  6022 solver.cpp:244]     Train net output #1: loss = 1.601 (* 1 = 1.601 loss)
I1010 14:49:34.684345  6022 sgd_solver.cpp:106] Iteration 1150, lr = 0.0001
I1010 14:49:38.915523  6022 solver.cpp:228] Iteration 1200, loss = 1.60715
I1010 14:49:38.915558  6022 solver.cpp:244]     Train net output #0: accuracy = 0.453125
I1010 14:49:38.915565  6022 solver.cpp:244]     Train net output #1: loss = 1.60715 (* 1 = 1.60715 loss)
I1010 14:49:38.915570  6022 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I1010 14:49:43.053218  6022 solver.cpp:337] Iteration 1250, Testing net (#0)
I1010 14:49:46.566862  6022 solver.cpp:404]     Test net output #0: accuracy = 0.4889
I1010 14:49:46.566897  6022 solver.cpp:404]     Test net output #1: loss = 1.51321 (* 1 = 1.51321 loss)
I1010 14:49:46.596719  6022 solver.cpp:228] Iteration 1250, loss = 1.47394
I1010 14:49:46.596766  6022 solver.cpp:244]     Train net output #0: accuracy = 0.515625
I1010 14:49:46.596774  6022 solver.cpp:244]     Train net output #1: loss = 1.47394 (* 1 = 1.47394 loss)
I1010 14:49:46.596778  6022 sgd_solver.cpp:106] Iteration 1250, lr = 0.0001
I1010 14:49:50.753890  6022 solver.cpp:228] Iteration 1300, loss = 1.45556
I1010 14:49:50.753976  6022 solver.cpp:244]     Train net output #0: accuracy = 0.453125
I1010 14:49:50.753998  6022 solver.cpp:244]     Train net output #1: loss = 1.45556 (* 1 = 1.45556 loss)
I1010 14:49:50.754001  6022 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I1010 14:49:54.915771  6022 solver.cpp:228] Iteration 1350, loss = 1.44304
I1010 14:49:54.915792  6022 solver.cpp:244]     Train net output #0: accuracy = 0.484375
I1010 14:49:54.915799  6022 solver.cpp:244]     Train net output #1: loss = 1.44304 (* 1 = 1.44304 loss)
I1010 14:49:54.915803  6022 sgd_solver.cpp:106] Iteration 1350, lr = 0.0001
I1010 14:49:59.080402  6022 solver.cpp:228] Iteration 1400, loss = 1.5682
I1010 14:49:59.080423  6022 solver.cpp:244]     Train net output #0: accuracy = 0.453125
I1010 14:49:59.080445  6022 solver.cpp:244]     Train net output #1: loss = 1.5682 (* 1 = 1.5682 loss)
I1010 14:49:59.080448  6022 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I1010 14:50:03.243625  6022 solver.cpp:228] Iteration 1450, loss = 1.58634
I1010 14:50:03.243645  6022 solver.cpp:244]     Train net output #0: accuracy = 0.484375
I1010 14:50:03.243654  6022 solver.cpp:244]     Train net output #1: loss = 1.58634 (* 1 = 1.58634 loss)
I1010 14:50:03.243671  6022 sgd_solver.cpp:106] Iteration 1450, lr = 0.0001
I1010 14:50:07.381572  6022 solver.cpp:337] Iteration 1500, Testing net (#0)
I1010 14:50:10.896396  6022 solver.cpp:404]     Test net output #0: accuracy = 0.4867
I1010 14:50:10.896419  6022 solver.cpp:404]     Test net output #1: loss = 1.52413 (* 1 = 1.52413 loss)
I1010 14:50:10.926508  6022 solver.cpp:228] Iteration 1500, loss = 1.37306
I1010 14:50:10.926528  6022 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I1010 14:50:10.926534  6022 solver.cpp:244]     Train net output #1: loss = 1.37306 (* 1 = 1.37306 loss)
I1010 14:50:10.926539  6022 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I1010 14:50:15.090700  6022 solver.cpp:228] Iteration 1550, loss = 1.37105
I1010 14:50:15.090723  6022 solver.cpp:244]     Train net output #0: accuracy = 0.546875
I1010 14:50:15.090730  6022 solver.cpp:244]     Train net output #1: loss = 1.37105 (* 1 = 1.37105 loss)
I1010 14:50:15.090749  6022 sgd_solver.cpp:106] Iteration 1550, lr = 0.0001
I1010 14:50:19.250087  6022 solver.cpp:228] Iteration 1600, loss = 1.34395
I1010 14:50:19.250109  6022 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I1010 14:50:19.250116  6022 solver.cpp:244]     Train net output #1: loss = 1.34395 (* 1 = 1.34395 loss)
I1010 14:50:19.250120  6022 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I1010 14:50:23.411725  6022 solver.cpp:228] Iteration 1650, loss = 1.32836
I1010 14:50:23.411784  6022 solver.cpp:244]     Train net output #0: accuracy = 0.578125
I1010 14:50:23.411793  6022 solver.cpp:244]     Train net output #1: loss = 1.32836 (* 1 = 1.32836 loss)
I1010 14:50:23.411798  6022 sgd_solver.cpp:106] Iteration 1650, lr = 0.0001
I1010 14:50:27.573364  6022 solver.cpp:228] Iteration 1700, loss = 1.43095
I1010 14:50:27.573385  6022 solver.cpp:244]     Train net output #0: accuracy = 0.484375
I1010 14:50:27.573392  6022 solver.cpp:244]     Train net output #1: loss = 1.43095 (* 1 = 1.43095 loss)
I1010 14:50:27.573411  6022 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I1010 14:50:31.711563  6022 solver.cpp:337] Iteration 1750, Testing net (#0)
I1010 14:50:35.222180  6022 solver.cpp:404]     Test net output #0: accuracy = 0.5212
I1010 14:50:35.222215  6022 solver.cpp:404]     Test net output #1: loss = 1.39718 (* 1 = 1.39718 loss)
I1010 14:50:35.252153  6022 solver.cpp:228] Iteration 1750, loss = 1.29854
I1010 14:50:35.252173  6022 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I1010 14:50:35.252180  6022 solver.cpp:244]     Train net output #1: loss = 1.29854 (* 1 = 1.29854 loss)
I1010 14:50:35.252185  6022 sgd_solver.cpp:106] Iteration 1750, lr = 0.0001
I1010 14:50:39.415016  6022 solver.cpp:228] Iteration 1800, loss = 1.1914
I1010 14:50:39.415038  6022 solver.cpp:244]     Train net output #0: accuracy = 0.578125
I1010 14:50:39.415045  6022 solver.cpp:244]     Train net output #1: loss = 1.1914 (* 1 = 1.1914 loss)
I1010 14:50:39.415050  6022 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I1010 14:50:43.578712  6022 solver.cpp:228] Iteration 1850, loss = 1.21087
I1010 14:50:43.578733  6022 solver.cpp:244]     Train net output #0: accuracy = 0.609375
I1010 14:50:43.578742  6022 solver.cpp:244]     Train net output #1: loss = 1.21087 (* 1 = 1.21087 loss)
I1010 14:50:43.578744  6022 sgd_solver.cpp:106] Iteration 1850, lr = 0.0001
I1010 14:50:47.744014  6022 solver.cpp:228] Iteration 1900, loss = 1.31095
I1010 14:50:47.744048  6022 solver.cpp:244]     Train net output #0: accuracy = 0.625
I1010 14:50:47.744055  6022 solver.cpp:244]     Train net output #1: loss = 1.31095 (* 1 = 1.31095 loss)
I1010 14:50:47.744071  6022 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I1010 14:50:51.904886  6022 solver.cpp:228] Iteration 1950, loss = 1.53807
I1010 14:50:51.904907  6022 solver.cpp:244]     Train net output #0: accuracy = 0.40625
I1010 14:50:51.904914  6022 solver.cpp:244]     Train net output #1: loss = 1.53807 (* 1 = 1.53807 loss)
I1010 14:50:51.904918  6022 sgd_solver.cpp:106] Iteration 1950, lr = 0.0001
I1010 14:50:56.043548  6022 solver.cpp:337] Iteration 2000, Testing net (#0)
I1010 14:50:59.559590  6022 solver.cpp:404]     Test net output #0: accuracy = 0.5409
I1010 14:50:59.559615  6022 solver.cpp:404]     Test net output #1: loss = 1.34991 (* 1 = 1.34991 loss)
I1010 14:50:59.589439  6022 solver.cpp:228] Iteration 2000, loss = 1.17704
I1010 14:50:59.589462  6022 solver.cpp:244]     Train net output #0: accuracy = 0.515625
I1010 14:50:59.589469  6022 solver.cpp:244]     Train net output #1: loss = 1.17704 (* 1 = 1.17704 loss)
I1010 14:50:59.589474  6022 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I1010 14:51:03.757798  6022 solver.cpp:228] Iteration 2050, loss = 1.2474
I1010 14:51:03.757820  6022 solver.cpp:244]     Train net output #0: accuracy = 0.515625
I1010 14:51:03.757828  6022 solver.cpp:244]     Train net output #1: loss = 1.2474 (* 1 = 1.2474 loss)
I1010 14:51:03.757846  6022 sgd_solver.cpp:106] Iteration 2050, lr = 0.0001
I1010 14:51:07.921104  6022 solver.cpp:228] Iteration 2100, loss = 1.35952
I1010 14:51:07.921125  6022 solver.cpp:244]     Train net output #0: accuracy = 0.578125
I1010 14:51:07.921133  6022 solver.cpp:244]     Train net output #1: loss = 1.35952 (* 1 = 1.35952 loss)
I1010 14:51:07.921150  6022 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I1010 14:51:12.090407  6022 solver.cpp:228] Iteration 2150, loss = 1.24363
I1010 14:51:12.090443  6022 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I1010 14:51:12.090451  6022 solver.cpp:244]     Train net output #1: loss = 1.24363 (* 1 = 1.24363 loss)
I1010 14:51:12.090467  6022 sgd_solver.cpp:106] Iteration 2150, lr = 0.0001
I1010 14:51:16.251857  6022 solver.cpp:228] Iteration 2200, loss = 1.37635
I1010 14:51:16.251878  6022 solver.cpp:244]     Train net output #0: accuracy = 0.484375
I1010 14:51:16.251884  6022 solver.cpp:244]     Train net output #1: loss = 1.37635 (* 1 = 1.37635 loss)
I1010 14:51:16.251888  6022 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I1010 14:51:20.387267  6022 solver.cpp:337] Iteration 2250, Testing net (#0)
I1010 14:51:23.901268  6022 solver.cpp:404]     Test net output #0: accuracy = 0.5634
I1010 14:51:23.901290  6022 solver.cpp:404]     Test net output #1: loss = 1.27143 (* 1 = 1.27143 loss)
I1010 14:51:23.931027  6022 solver.cpp:228] Iteration 2250, loss = 1.34659
I1010 14:51:23.931048  6022 solver.cpp:244]     Train net output #0: accuracy = 0.625
I1010 14:51:23.931056  6022 solver.cpp:244]     Train net output #1: loss = 1.34659 (* 1 = 1.34659 loss)
I1010 14:51:23.931061  6022 sgd_solver.cpp:106] Iteration 2250, lr = 0.0001
I1010 14:51:28.091852  6022 solver.cpp:228] Iteration 2300, loss = 1.24811
I1010 14:51:28.091991  6022 solver.cpp:244]     Train net output #0: accuracy = 0.546875
I1010 14:51:28.092001  6022 solver.cpp:244]     Train net output #1: loss = 1.24811 (* 1 = 1.24811 loss)
I1010 14:51:28.092018  6022 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I1010 14:51:32.254082  6022 solver.cpp:228] Iteration 2350, loss = 1.03856
I1010 14:51:32.254102  6022 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I1010 14:51:32.254109  6022 solver.cpp:244]     Train net output #1: loss = 1.03856 (* 1 = 1.03856 loss)
I1010 14:51:32.254127  6022 sgd_solver.cpp:106] Iteration 2350, lr = 0.0001
I1010 14:51:36.418741  6022 solver.cpp:228] Iteration 2400, loss = 1.2483
I1010 14:51:36.418776  6022 solver.cpp:244]     Train net output #0: accuracy = 0.5
I1010 14:51:36.418783  6022 solver.cpp:244]     Train net output #1: loss = 1.2483 (* 1 = 1.2483 loss)
I1010 14:51:36.418787  6022 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I1010 14:51:40.584198  6022 solver.cpp:228] Iteration 2450, loss = 1.29553
I1010 14:51:40.584233  6022 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I1010 14:51:40.584239  6022 solver.cpp:244]     Train net output #1: loss = 1.29553 (* 1 = 1.29553 loss)
I1010 14:51:40.584244  6022 sgd_solver.cpp:106] Iteration 2450, lr = 0.0001
I1010 14:51:44.726846  6022 solver.cpp:454] Snapshotting to binary proto file cifar-10_relu_RMSProp_iter_2500.caffemodel
I1010 14:51:44.742543  6022 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_relu_RMSProp_iter_2500.solverstate
I1010 14:51:44.778445  6022 solver.cpp:317] Iteration 2500, loss = 1.07776
I1010 14:51:44.778466  6022 solver.cpp:337] Iteration 2500, Testing net (#0)
I1010 14:51:48.289510  6022 solver.cpp:404]     Test net output #0: accuracy = 0.5654
I1010 14:51:48.289535  6022 solver.cpp:404]     Test net output #1: loss = 1.26823 (* 1 = 1.26823 loss)
I1010 14:51:48.289538  6022 solver.cpp:322] Optimization Done.
I1010 14:51:48.289541  6022 caffe.cpp:254] Optimization Done.
