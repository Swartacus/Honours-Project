I1009 17:03:39.642282  7388 caffe.cpp:217] Using GPUs 0
I1009 17:03:39.645017  7388 caffe.cpp:222] GPU 0: GeForce GTX 750 Ti
I1009 17:03:39.753008  7388 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/allcnn_relu_train.prototxt"
test_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/allcnn_relu_test.prototxt"
test_iter: 100
test_interval: 50
base_lr: 0.001
display: 50
max_iter: 250
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 5000
snapshot_prefix: "cifar-10_relu_SGD"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
type: "SGD"
I1009 17:03:39.753168  7388 solver.cpp:81] Creating training net from train_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/allcnn_relu_train.prototxt
I1009 17:03:39.753435  7388 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../data/cifar-10/cifar10_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "flatten"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1009 17:03:39.753525  7388 layer_factory.hpp:77] Creating layer data
I1009 17:03:39.753988  7388 net.cpp:100] Creating Layer data
I1009 17:03:39.754031  7388 net.cpp:408] data -> data
I1009 17:03:39.754061  7388 net.cpp:408] data -> label
I1009 17:03:39.754073  7388 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1009 17:03:39.754712  7393 db_lmdb.cpp:35] Opened lmdb ../../data/cifar-10/cifar10_train_lmdb
I1009 17:03:39.760993  7388 data_layer.cpp:41] output data size: 64,3,32,32
I1009 17:03:39.762610  7388 net.cpp:150] Setting up data
I1009 17:03:39.762629  7388 net.cpp:157] Top shape: 64 3 32 32 (196608)
I1009 17:03:39.762652  7388 net.cpp:157] Top shape: 64 (64)
I1009 17:03:39.762653  7388 net.cpp:165] Memory required for data: 786688
I1009 17:03:39.762662  7388 layer_factory.hpp:77] Creating layer conv1
I1009 17:03:39.762681  7388 net.cpp:100] Creating Layer conv1
I1009 17:03:39.762699  7388 net.cpp:434] conv1 <- data
I1009 17:03:39.762724  7388 net.cpp:408] conv1 -> conv1
I1009 17:03:39.902845  7388 net.cpp:150] Setting up conv1
I1009 17:03:39.902871  7388 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1009 17:03:39.902874  7388 net.cpp:165] Memory required for data: 22905088
I1009 17:03:39.902891  7388 layer_factory.hpp:77] Creating layer relu1
I1009 17:03:39.902900  7388 net.cpp:100] Creating Layer relu1
I1009 17:03:39.902904  7388 net.cpp:434] relu1 <- conv1
I1009 17:03:39.902907  7388 net.cpp:395] relu1 -> conv1 (in-place)
I1009 17:03:39.903095  7388 net.cpp:150] Setting up relu1
I1009 17:03:39.903100  7388 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1009 17:03:39.903102  7388 net.cpp:165] Memory required for data: 45023488
I1009 17:03:39.903105  7388 layer_factory.hpp:77] Creating layer conv2
I1009 17:03:39.903112  7388 net.cpp:100] Creating Layer conv2
I1009 17:03:39.903115  7388 net.cpp:434] conv2 <- conv1
I1009 17:03:39.903118  7388 net.cpp:408] conv2 -> conv2
I1009 17:03:39.904480  7388 net.cpp:150] Setting up conv2
I1009 17:03:39.904490  7388 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1009 17:03:39.904492  7388 net.cpp:165] Memory required for data: 64291072
I1009 17:03:39.904498  7388 layer_factory.hpp:77] Creating layer relu2
I1009 17:03:39.904503  7388 net.cpp:100] Creating Layer relu2
I1009 17:03:39.904505  7388 net.cpp:434] relu2 <- conv2
I1009 17:03:39.904508  7388 net.cpp:395] relu2 -> conv2 (in-place)
I1009 17:03:39.904709  7388 net.cpp:150] Setting up relu2
I1009 17:03:39.904716  7388 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1009 17:03:39.904717  7388 net.cpp:165] Memory required for data: 83558656
I1009 17:03:39.904734  7388 layer_factory.hpp:77] Creating layer conv3
I1009 17:03:39.904741  7388 net.cpp:100] Creating Layer conv3
I1009 17:03:39.904743  7388 net.cpp:434] conv3 <- conv2
I1009 17:03:39.904747  7388 net.cpp:408] conv3 -> conv3
I1009 17:03:39.905972  7388 net.cpp:150] Setting up conv3
I1009 17:03:39.905982  7388 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1009 17:03:39.905983  7388 net.cpp:165] Memory required for data: 87712000
I1009 17:03:39.905989  7388 layer_factory.hpp:77] Creating layer relu3
I1009 17:03:39.905993  7388 net.cpp:100] Creating Layer relu3
I1009 17:03:39.905995  7388 net.cpp:434] relu3 <- conv3
I1009 17:03:39.905998  7388 net.cpp:395] relu3 -> conv3 (in-place)
I1009 17:03:39.906236  7388 net.cpp:150] Setting up relu3
I1009 17:03:39.906244  7388 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1009 17:03:39.906246  7388 net.cpp:165] Memory required for data: 91865344
I1009 17:03:39.906249  7388 layer_factory.hpp:77] Creating layer conv4
I1009 17:03:39.906253  7388 net.cpp:100] Creating Layer conv4
I1009 17:03:39.906256  7388 net.cpp:434] conv4 <- conv3
I1009 17:03:39.906260  7388 net.cpp:408] conv4 -> conv4
I1009 17:03:39.908048  7388 net.cpp:150] Setting up conv4
I1009 17:03:39.908058  7388 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1009 17:03:39.908061  7388 net.cpp:165] Memory required for data: 97812736
I1009 17:03:39.908066  7388 layer_factory.hpp:77] Creating layer relu4
I1009 17:03:39.908071  7388 net.cpp:100] Creating Layer relu4
I1009 17:03:39.908073  7388 net.cpp:434] relu4 <- conv4
I1009 17:03:39.908087  7388 net.cpp:395] relu4 -> conv4 (in-place)
I1009 17:03:39.908257  7388 net.cpp:150] Setting up relu4
I1009 17:03:39.908262  7388 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1009 17:03:39.908264  7388 net.cpp:165] Memory required for data: 103760128
I1009 17:03:39.908267  7388 layer_factory.hpp:77] Creating layer conv5
I1009 17:03:39.908272  7388 net.cpp:100] Creating Layer conv5
I1009 17:03:39.908274  7388 net.cpp:434] conv5 <- conv4
I1009 17:03:39.908277  7388 net.cpp:408] conv5 -> conv5
I1009 17:03:39.910749  7388 net.cpp:150] Setting up conv5
I1009 17:03:39.910760  7388 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1009 17:03:39.910763  7388 net.cpp:165] Memory required for data: 107741440
I1009 17:03:39.910769  7388 layer_factory.hpp:77] Creating layer relu5
I1009 17:03:39.910773  7388 net.cpp:100] Creating Layer relu5
I1009 17:03:39.910775  7388 net.cpp:434] relu5 <- conv5
I1009 17:03:39.910778  7388 net.cpp:395] relu5 -> conv5 (in-place)
I1009 17:03:39.910935  7388 net.cpp:150] Setting up relu5
I1009 17:03:39.910941  7388 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1009 17:03:39.910943  7388 net.cpp:165] Memory required for data: 111722752
I1009 17:03:39.910945  7388 layer_factory.hpp:77] Creating layer conv6
I1009 17:03:39.910950  7388 net.cpp:100] Creating Layer conv6
I1009 17:03:39.910953  7388 net.cpp:434] conv6 <- conv5
I1009 17:03:39.910955  7388 net.cpp:408] conv6 -> conv6
I1009 17:03:39.913441  7388 net.cpp:150] Setting up conv6
I1009 17:03:39.913467  7388 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1009 17:03:39.913470  7388 net.cpp:165] Memory required for data: 112509184
I1009 17:03:39.913475  7388 layer_factory.hpp:77] Creating layer relu6
I1009 17:03:39.913480  7388 net.cpp:100] Creating Layer relu6
I1009 17:03:39.913482  7388 net.cpp:434] relu6 <- conv6
I1009 17:03:39.913486  7388 net.cpp:395] relu6 -> conv6 (in-place)
I1009 17:03:39.913743  7388 net.cpp:150] Setting up relu6
I1009 17:03:39.913765  7388 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1009 17:03:39.913767  7388 net.cpp:165] Memory required for data: 113295616
I1009 17:03:39.913769  7388 layer_factory.hpp:77] Creating layer conv7
I1009 17:03:39.913789  7388 net.cpp:100] Creating Layer conv7
I1009 17:03:39.913791  7388 net.cpp:434] conv7 <- conv6
I1009 17:03:39.913795  7388 net.cpp:408] conv7 -> conv7
I1009 17:03:39.916872  7388 net.cpp:150] Setting up conv7
I1009 17:03:39.916889  7388 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 17:03:39.916893  7388 net.cpp:165] Memory required for data: 113492224
I1009 17:03:39.916898  7388 layer_factory.hpp:77] Creating layer relu7
I1009 17:03:39.916903  7388 net.cpp:100] Creating Layer relu7
I1009 17:03:39.916906  7388 net.cpp:434] relu7 <- conv7
I1009 17:03:39.916910  7388 net.cpp:395] relu7 -> conv7 (in-place)
I1009 17:03:39.917152  7388 net.cpp:150] Setting up relu7
I1009 17:03:39.917160  7388 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 17:03:39.917162  7388 net.cpp:165] Memory required for data: 113688832
I1009 17:03:39.917165  7388 layer_factory.hpp:77] Creating layer conv8
I1009 17:03:39.917171  7388 net.cpp:100] Creating Layer conv8
I1009 17:03:39.917173  7388 net.cpp:434] conv8 <- conv7
I1009 17:03:39.917176  7388 net.cpp:408] conv8 -> conv8
I1009 17:03:39.918426  7388 net.cpp:150] Setting up conv8
I1009 17:03:39.918437  7388 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 17:03:39.918438  7388 net.cpp:165] Memory required for data: 113885440
I1009 17:03:39.918442  7388 layer_factory.hpp:77] Creating layer relu8
I1009 17:03:39.918448  7388 net.cpp:100] Creating Layer relu8
I1009 17:03:39.918450  7388 net.cpp:434] relu8 <- conv8
I1009 17:03:39.918454  7388 net.cpp:395] relu8 -> conv8 (in-place)
I1009 17:03:39.918613  7388 net.cpp:150] Setting up relu8
I1009 17:03:39.918619  7388 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 17:03:39.918622  7388 net.cpp:165] Memory required for data: 114082048
I1009 17:03:39.918623  7388 layer_factory.hpp:77] Creating layer conv9
I1009 17:03:39.918628  7388 net.cpp:100] Creating Layer conv9
I1009 17:03:39.918642  7388 net.cpp:434] conv9 <- conv8
I1009 17:03:39.918645  7388 net.cpp:408] conv9 -> conv9
I1009 17:03:39.919428  7388 net.cpp:150] Setting up conv9
I1009 17:03:39.919436  7388 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1009 17:03:39.919440  7388 net.cpp:165] Memory required for data: 114092288
I1009 17:03:39.919446  7388 layer_factory.hpp:77] Creating layer relu9
I1009 17:03:39.919450  7388 net.cpp:100] Creating Layer relu9
I1009 17:03:39.919452  7388 net.cpp:434] relu9 <- conv9
I1009 17:03:39.919456  7388 net.cpp:395] relu9 -> conv9 (in-place)
I1009 17:03:39.919711  7388 net.cpp:150] Setting up relu9
I1009 17:03:39.919718  7388 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1009 17:03:39.919721  7388 net.cpp:165] Memory required for data: 114102528
I1009 17:03:39.919723  7388 layer_factory.hpp:77] Creating layer pool
I1009 17:03:39.919728  7388 net.cpp:100] Creating Layer pool
I1009 17:03:39.919729  7388 net.cpp:434] pool <- conv9
I1009 17:03:39.919733  7388 net.cpp:408] pool -> pool
I1009 17:03:39.919948  7388 net.cpp:150] Setting up pool
I1009 17:03:39.919955  7388 net.cpp:157] Top shape: 64 10 1 1 (640)
I1009 17:03:39.919956  7388 net.cpp:165] Memory required for data: 114105088
I1009 17:03:39.919958  7388 layer_factory.hpp:77] Creating layer flatten
I1009 17:03:39.919962  7388 net.cpp:100] Creating Layer flatten
I1009 17:03:39.919965  7388 net.cpp:434] flatten <- pool
I1009 17:03:39.919967  7388 net.cpp:408] flatten -> flatten
I1009 17:03:39.919984  7388 net.cpp:150] Setting up flatten
I1009 17:03:39.919988  7388 net.cpp:157] Top shape: 64 10 (640)
I1009 17:03:39.920004  7388 net.cpp:165] Memory required for data: 114107648
I1009 17:03:39.920006  7388 layer_factory.hpp:77] Creating layer score
I1009 17:03:39.920011  7388 net.cpp:100] Creating Layer score
I1009 17:03:39.920012  7388 net.cpp:434] score <- flatten
I1009 17:03:39.920017  7388 net.cpp:408] score -> score
I1009 17:03:39.920140  7388 net.cpp:150] Setting up score
I1009 17:03:39.920145  7388 net.cpp:157] Top shape: 64 10 (640)
I1009 17:03:39.920146  7388 net.cpp:165] Memory required for data: 114110208
I1009 17:03:39.920150  7388 layer_factory.hpp:77] Creating layer loss
I1009 17:03:39.920155  7388 net.cpp:100] Creating Layer loss
I1009 17:03:39.920156  7388 net.cpp:434] loss <- score
I1009 17:03:39.920158  7388 net.cpp:434] loss <- label
I1009 17:03:39.920162  7388 net.cpp:408] loss -> loss
I1009 17:03:39.920169  7388 layer_factory.hpp:77] Creating layer loss
I1009 17:03:39.920485  7388 net.cpp:150] Setting up loss
I1009 17:03:39.920492  7388 net.cpp:157] Top shape: (1)
I1009 17:03:39.920495  7388 net.cpp:160]     with loss weight 1
I1009 17:03:39.920511  7388 net.cpp:165] Memory required for data: 114110212
I1009 17:03:39.920512  7388 net.cpp:226] loss needs backward computation.
I1009 17:03:39.920517  7388 net.cpp:226] score needs backward computation.
I1009 17:03:39.920519  7388 net.cpp:226] flatten needs backward computation.
I1009 17:03:39.920522  7388 net.cpp:226] pool needs backward computation.
I1009 17:03:39.920523  7388 net.cpp:226] relu9 needs backward computation.
I1009 17:03:39.920526  7388 net.cpp:226] conv9 needs backward computation.
I1009 17:03:39.920542  7388 net.cpp:226] relu8 needs backward computation.
I1009 17:03:39.920543  7388 net.cpp:226] conv8 needs backward computation.
I1009 17:03:39.920545  7388 net.cpp:226] relu7 needs backward computation.
I1009 17:03:39.920547  7388 net.cpp:226] conv7 needs backward computation.
I1009 17:03:39.920549  7388 net.cpp:226] relu6 needs backward computation.
I1009 17:03:39.920564  7388 net.cpp:226] conv6 needs backward computation.
I1009 17:03:39.920567  7388 net.cpp:226] relu5 needs backward computation.
I1009 17:03:39.920568  7388 net.cpp:226] conv5 needs backward computation.
I1009 17:03:39.920570  7388 net.cpp:226] relu4 needs backward computation.
I1009 17:03:39.920588  7388 net.cpp:226] conv4 needs backward computation.
I1009 17:03:39.920589  7388 net.cpp:226] relu3 needs backward computation.
I1009 17:03:39.920591  7388 net.cpp:226] conv3 needs backward computation.
I1009 17:03:39.920593  7388 net.cpp:226] relu2 needs backward computation.
I1009 17:03:39.920606  7388 net.cpp:226] conv2 needs backward computation.
I1009 17:03:39.920608  7388 net.cpp:226] relu1 needs backward computation.
I1009 17:03:39.920610  7388 net.cpp:226] conv1 needs backward computation.
I1009 17:03:39.920614  7388 net.cpp:228] data does not need backward computation.
I1009 17:03:39.920615  7388 net.cpp:270] This network produces output loss
I1009 17:03:39.920636  7388 net.cpp:283] Network initialization done.
I1009 17:03:39.920830  7388 solver.cpp:181] Creating test net (#0) specified by test_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/allcnn_relu_test.prototxt
I1009 17:03:39.920960  7388 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../data/cifar-10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "flatten"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1009 17:03:39.921000  7388 layer_factory.hpp:77] Creating layer data
I1009 17:03:39.921121  7388 net.cpp:100] Creating Layer data
I1009 17:03:39.921126  7388 net.cpp:408] data -> data
I1009 17:03:39.921139  7388 net.cpp:408] data -> label
I1009 17:03:39.921145  7388 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1009 17:03:39.921813  7395 db_lmdb.cpp:35] Opened lmdb ../../data/cifar-10/cifar10_test_lmdb
I1009 17:03:39.921949  7388 data_layer.cpp:41] output data size: 100,3,32,32
I1009 17:03:39.923853  7388 net.cpp:150] Setting up data
I1009 17:03:39.923895  7388 net.cpp:157] Top shape: 100 3 32 32 (307200)
I1009 17:03:39.923899  7388 net.cpp:157] Top shape: 100 (100)
I1009 17:03:39.923900  7388 net.cpp:165] Memory required for data: 1229200
I1009 17:03:39.923905  7388 layer_factory.hpp:77] Creating layer conv1
I1009 17:03:39.923916  7388 net.cpp:100] Creating Layer conv1
I1009 17:03:39.923919  7388 net.cpp:434] conv1 <- data
I1009 17:03:39.923938  7388 net.cpp:408] conv1 -> conv1
I1009 17:03:39.924881  7388 net.cpp:150] Setting up conv1
I1009 17:03:39.924892  7388 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1009 17:03:39.924908  7388 net.cpp:165] Memory required for data: 35789200
I1009 17:03:39.924916  7388 layer_factory.hpp:77] Creating layer relu1
I1009 17:03:39.924921  7388 net.cpp:100] Creating Layer relu1
I1009 17:03:39.924924  7388 net.cpp:434] relu1 <- conv1
I1009 17:03:39.924927  7388 net.cpp:395] relu1 -> conv1 (in-place)
I1009 17:03:39.925256  7388 net.cpp:150] Setting up relu1
I1009 17:03:39.925261  7388 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1009 17:03:39.925264  7388 net.cpp:165] Memory required for data: 70349200
I1009 17:03:39.925266  7388 layer_factory.hpp:77] Creating layer conv2
I1009 17:03:39.925272  7388 net.cpp:100] Creating Layer conv2
I1009 17:03:39.925288  7388 net.cpp:434] conv2 <- conv1
I1009 17:03:39.925292  7388 net.cpp:408] conv2 -> conv2
I1009 17:03:39.926651  7388 net.cpp:150] Setting up conv2
I1009 17:03:39.926676  7388 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1009 17:03:39.926678  7388 net.cpp:165] Memory required for data: 100454800
I1009 17:03:39.926687  7388 layer_factory.hpp:77] Creating layer relu2
I1009 17:03:39.926704  7388 net.cpp:100] Creating Layer relu2
I1009 17:03:39.926707  7388 net.cpp:434] relu2 <- conv2
I1009 17:03:39.926710  7388 net.cpp:395] relu2 -> conv2 (in-place)
I1009 17:03:39.926945  7388 net.cpp:150] Setting up relu2
I1009 17:03:39.926967  7388 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1009 17:03:39.926970  7388 net.cpp:165] Memory required for data: 130560400
I1009 17:03:39.926972  7388 layer_factory.hpp:77] Creating layer conv3
I1009 17:03:39.926978  7388 net.cpp:100] Creating Layer conv3
I1009 17:03:39.926982  7388 net.cpp:434] conv3 <- conv2
I1009 17:03:39.926986  7388 net.cpp:408] conv3 -> conv3
I1009 17:03:39.928246  7388 net.cpp:150] Setting up conv3
I1009 17:03:39.928272  7388 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1009 17:03:39.928274  7388 net.cpp:165] Memory required for data: 137050000
I1009 17:03:39.928282  7388 layer_factory.hpp:77] Creating layer relu3
I1009 17:03:39.928285  7388 net.cpp:100] Creating Layer relu3
I1009 17:03:39.928288  7388 net.cpp:434] relu3 <- conv3
I1009 17:03:39.928292  7388 net.cpp:395] relu3 -> conv3 (in-place)
I1009 17:03:39.928521  7388 net.cpp:150] Setting up relu3
I1009 17:03:39.928530  7388 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1009 17:03:39.928532  7388 net.cpp:165] Memory required for data: 143539600
I1009 17:03:39.928534  7388 layer_factory.hpp:77] Creating layer conv4
I1009 17:03:39.928541  7388 net.cpp:100] Creating Layer conv4
I1009 17:03:39.928544  7388 net.cpp:434] conv4 <- conv3
I1009 17:03:39.928547  7388 net.cpp:408] conv4 -> conv4
I1009 17:03:39.930794  7388 net.cpp:150] Setting up conv4
I1009 17:03:39.930807  7388 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1009 17:03:39.930809  7388 net.cpp:165] Memory required for data: 152832400
I1009 17:03:39.930815  7388 layer_factory.hpp:77] Creating layer relu4
I1009 17:03:39.930821  7388 net.cpp:100] Creating Layer relu4
I1009 17:03:39.930838  7388 net.cpp:434] relu4 <- conv4
I1009 17:03:39.930842  7388 net.cpp:395] relu4 -> conv4 (in-place)
I1009 17:03:39.931058  7388 net.cpp:150] Setting up relu4
I1009 17:03:39.931078  7388 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1009 17:03:39.931080  7388 net.cpp:165] Memory required for data: 162125200
I1009 17:03:39.931082  7388 layer_factory.hpp:77] Creating layer conv5
I1009 17:03:39.931088  7388 net.cpp:100] Creating Layer conv5
I1009 17:03:39.931092  7388 net.cpp:434] conv5 <- conv4
I1009 17:03:39.931097  7388 net.cpp:408] conv5 -> conv5
I1009 17:03:39.933948  7388 net.cpp:150] Setting up conv5
I1009 17:03:39.933962  7388 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1009 17:03:39.933965  7388 net.cpp:165] Memory required for data: 168346000
I1009 17:03:39.933987  7388 layer_factory.hpp:77] Creating layer relu5
I1009 17:03:39.934010  7388 net.cpp:100] Creating Layer relu5
I1009 17:03:39.934012  7388 net.cpp:434] relu5 <- conv5
I1009 17:03:39.934031  7388 net.cpp:395] relu5 -> conv5 (in-place)
I1009 17:03:39.934350  7388 net.cpp:150] Setting up relu5
I1009 17:03:39.934358  7388 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1009 17:03:39.934360  7388 net.cpp:165] Memory required for data: 174566800
I1009 17:03:39.934363  7388 layer_factory.hpp:77] Creating layer conv6
I1009 17:03:39.934382  7388 net.cpp:100] Creating Layer conv6
I1009 17:03:39.934384  7388 net.cpp:434] conv6 <- conv5
I1009 17:03:39.934388  7388 net.cpp:408] conv6 -> conv6
I1009 17:03:39.936929  7388 net.cpp:150] Setting up conv6
I1009 17:03:39.936941  7388 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1009 17:03:39.936944  7388 net.cpp:165] Memory required for data: 175795600
I1009 17:03:39.936949  7388 layer_factory.hpp:77] Creating layer relu6
I1009 17:03:39.936952  7388 net.cpp:100] Creating Layer relu6
I1009 17:03:39.936954  7388 net.cpp:434] relu6 <- conv6
I1009 17:03:39.936957  7388 net.cpp:395] relu6 -> conv6 (in-place)
I1009 17:03:39.937217  7388 net.cpp:150] Setting up relu6
I1009 17:03:39.937225  7388 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1009 17:03:39.937227  7388 net.cpp:165] Memory required for data: 177024400
I1009 17:03:39.937229  7388 layer_factory.hpp:77] Creating layer conv7
I1009 17:03:39.937237  7388 net.cpp:100] Creating Layer conv7
I1009 17:03:39.937239  7388 net.cpp:434] conv7 <- conv6
I1009 17:03:39.937242  7388 net.cpp:408] conv7 -> conv7
I1009 17:03:39.939846  7388 net.cpp:150] Setting up conv7
I1009 17:03:39.939857  7388 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 17:03:39.939859  7388 net.cpp:165] Memory required for data: 177331600
I1009 17:03:39.939863  7388 layer_factory.hpp:77] Creating layer relu7
I1009 17:03:39.939868  7388 net.cpp:100] Creating Layer relu7
I1009 17:03:39.939870  7388 net.cpp:434] relu7 <- conv7
I1009 17:03:39.939874  7388 net.cpp:395] relu7 -> conv7 (in-place)
I1009 17:03:39.940047  7388 net.cpp:150] Setting up relu7
I1009 17:03:39.940052  7388 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 17:03:39.940054  7388 net.cpp:165] Memory required for data: 177638800
I1009 17:03:39.940057  7388 layer_factory.hpp:77] Creating layer conv8
I1009 17:03:39.940062  7388 net.cpp:100] Creating Layer conv8
I1009 17:03:39.940064  7388 net.cpp:434] conv8 <- conv7
I1009 17:03:39.940069  7388 net.cpp:408] conv8 -> conv8
I1009 17:03:39.941048  7388 net.cpp:150] Setting up conv8
I1009 17:03:39.941057  7388 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 17:03:39.941059  7388 net.cpp:165] Memory required for data: 177946000
I1009 17:03:39.941064  7388 layer_factory.hpp:77] Creating layer relu8
I1009 17:03:39.941071  7388 net.cpp:100] Creating Layer relu8
I1009 17:03:39.941072  7388 net.cpp:434] relu8 <- conv8
I1009 17:03:39.941076  7388 net.cpp:395] relu8 -> conv8 (in-place)
I1009 17:03:39.941334  7388 net.cpp:150] Setting up relu8
I1009 17:03:39.941341  7388 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 17:03:39.941344  7388 net.cpp:165] Memory required for data: 178253200
I1009 17:03:39.941345  7388 layer_factory.hpp:77] Creating layer conv9
I1009 17:03:39.941351  7388 net.cpp:100] Creating Layer conv9
I1009 17:03:39.941354  7388 net.cpp:434] conv9 <- conv8
I1009 17:03:39.941357  7388 net.cpp:408] conv9 -> conv9
I1009 17:03:39.942124  7388 net.cpp:150] Setting up conv9
I1009 17:03:39.942133  7388 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1009 17:03:39.942136  7388 net.cpp:165] Memory required for data: 178269200
I1009 17:03:39.942143  7388 layer_factory.hpp:77] Creating layer relu9
I1009 17:03:39.942147  7388 net.cpp:100] Creating Layer relu9
I1009 17:03:39.942149  7388 net.cpp:434] relu9 <- conv9
I1009 17:03:39.942152  7388 net.cpp:395] relu9 -> conv9 (in-place)
I1009 17:03:39.942411  7388 net.cpp:150] Setting up relu9
I1009 17:03:39.942420  7388 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1009 17:03:39.942421  7388 net.cpp:165] Memory required for data: 178285200
I1009 17:03:39.942423  7388 layer_factory.hpp:77] Creating layer pool
I1009 17:03:39.942428  7388 net.cpp:100] Creating Layer pool
I1009 17:03:39.942430  7388 net.cpp:434] pool <- conv9
I1009 17:03:39.942435  7388 net.cpp:408] pool -> pool
I1009 17:03:39.942620  7388 net.cpp:150] Setting up pool
I1009 17:03:39.942626  7388 net.cpp:157] Top shape: 100 10 1 1 (1000)
I1009 17:03:39.942628  7388 net.cpp:165] Memory required for data: 178289200
I1009 17:03:39.942631  7388 layer_factory.hpp:77] Creating layer flatten
I1009 17:03:39.942633  7388 net.cpp:100] Creating Layer flatten
I1009 17:03:39.942636  7388 net.cpp:434] flatten <- pool
I1009 17:03:39.942639  7388 net.cpp:408] flatten -> flatten
I1009 17:03:39.942674  7388 net.cpp:150] Setting up flatten
I1009 17:03:39.942677  7388 net.cpp:157] Top shape: 100 10 (1000)
I1009 17:03:39.942679  7388 net.cpp:165] Memory required for data: 178293200
I1009 17:03:39.942682  7388 layer_factory.hpp:77] Creating layer score
I1009 17:03:39.942685  7388 net.cpp:100] Creating Layer score
I1009 17:03:39.942687  7388 net.cpp:434] score <- flatten
I1009 17:03:39.942692  7388 net.cpp:408] score -> score
I1009 17:03:39.942837  7388 net.cpp:150] Setting up score
I1009 17:03:39.942842  7388 net.cpp:157] Top shape: 100 10 (1000)
I1009 17:03:39.942843  7388 net.cpp:165] Memory required for data: 178297200
I1009 17:03:39.942847  7388 layer_factory.hpp:77] Creating layer loss
I1009 17:03:39.942852  7388 net.cpp:100] Creating Layer loss
I1009 17:03:39.942853  7388 net.cpp:434] loss <- score
I1009 17:03:39.942855  7388 net.cpp:434] loss <- label
I1009 17:03:39.942859  7388 net.cpp:408] loss -> loss
I1009 17:03:39.942864  7388 layer_factory.hpp:77] Creating layer loss
I1009 17:03:39.943197  7388 net.cpp:150] Setting up loss
I1009 17:03:39.943203  7388 net.cpp:157] Top shape: (1)
I1009 17:03:39.943205  7388 net.cpp:160]     with loss weight 1
I1009 17:03:39.943213  7388 net.cpp:165] Memory required for data: 178297204
I1009 17:03:39.943215  7388 net.cpp:226] loss needs backward computation.
I1009 17:03:39.943218  7388 net.cpp:226] score needs backward computation.
I1009 17:03:39.943219  7388 net.cpp:226] flatten needs backward computation.
I1009 17:03:39.943222  7388 net.cpp:226] pool needs backward computation.
I1009 17:03:39.943223  7388 net.cpp:226] relu9 needs backward computation.
I1009 17:03:39.943225  7388 net.cpp:226] conv9 needs backward computation.
I1009 17:03:39.943228  7388 net.cpp:226] relu8 needs backward computation.
I1009 17:03:39.943228  7388 net.cpp:226] conv8 needs backward computation.
I1009 17:03:39.943231  7388 net.cpp:226] relu7 needs backward computation.
I1009 17:03:39.943233  7388 net.cpp:226] conv7 needs backward computation.
I1009 17:03:39.943234  7388 net.cpp:226] relu6 needs backward computation.
I1009 17:03:39.943236  7388 net.cpp:226] conv6 needs backward computation.
I1009 17:03:39.943253  7388 net.cpp:226] relu5 needs backward computation.
I1009 17:03:39.943254  7388 net.cpp:226] conv5 needs backward computation.
I1009 17:03:39.943256  7388 net.cpp:226] relu4 needs backward computation.
I1009 17:03:39.943258  7388 net.cpp:226] conv4 needs backward computation.
I1009 17:03:39.943259  7388 net.cpp:226] relu3 needs backward computation.
I1009 17:03:39.943261  7388 net.cpp:226] conv3 needs backward computation.
I1009 17:03:39.943264  7388 net.cpp:226] relu2 needs backward computation.
I1009 17:03:39.943265  7388 net.cpp:226] conv2 needs backward computation.
I1009 17:03:39.943290  7388 net.cpp:226] relu1 needs backward computation.
I1009 17:03:39.943292  7388 net.cpp:226] conv1 needs backward computation.
I1009 17:03:39.943295  7388 net.cpp:228] data does not need backward computation.
I1009 17:03:39.943310  7388 net.cpp:270] This network produces output loss
I1009 17:03:39.943334  7388 net.cpp:283] Network initialization done.
I1009 17:03:39.943373  7388 solver.cpp:60] Solver scaffolding done.
I1009 17:03:39.944015  7388 caffe.cpp:251] Starting Optimization
I1009 17:03:39.944020  7388 solver.cpp:279] Solving 
I1009 17:03:39.944036  7388 solver.cpp:280] Learning Rate Policy: step
I1009 17:03:39.944875  7388 solver.cpp:337] Iteration 0, Testing net (#0)
I1009 17:03:42.851294  7388 solver.cpp:404]     Test net output #0: loss = 9.24113 (* 1 = 9.24113 loss)
I1009 17:03:42.874052  7388 solver.cpp:228] Iteration 0, loss = 9.93538
I1009 17:03:42.874078  7388 solver.cpp:244]     Train net output #0: loss = 9.93538 (* 1 = 9.93538 loss)
I1009 17:03:42.874092  7388 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1009 17:03:46.312068  7388 solver.cpp:337] Iteration 50, Testing net (#0)
I1009 17:03:49.243733  7388 solver.cpp:404]     Test net output #0: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 17:03:49.263793  7388 solver.cpp:228] Iteration 50, loss = 2.30203
I1009 17:03:49.263814  7388 solver.cpp:244]     Train net output #0: loss = 2.30203 (* 1 = 2.30203 loss)
I1009 17:03:49.263819  7388 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I1009 17:03:52.638519  7388 solver.cpp:337] Iteration 100, Testing net (#0)
I1009 17:03:55.538455  7388 solver.cpp:404]     Test net output #0: loss = 2.3026 (* 1 = 2.3026 loss)
I1009 17:03:55.558444  7388 solver.cpp:228] Iteration 100, loss = 2.30246
I1009 17:03:55.558465  7388 solver.cpp:244]     Train net output #0: loss = 2.30246 (* 1 = 2.30246 loss)
I1009 17:03:55.558470  7388 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I1009 17:03:58.933369  7388 solver.cpp:337] Iteration 150, Testing net (#0)
I1009 17:04:01.834658  7388 solver.cpp:404]     Test net output #0: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 17:04:01.854712  7388 solver.cpp:228] Iteration 150, loss = 2.30298
I1009 17:04:01.854733  7388 solver.cpp:244]     Train net output #0: loss = 2.30298 (* 1 = 2.30298 loss)
I1009 17:04:01.854738  7388 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I1009 17:04:05.229617  7388 solver.cpp:337] Iteration 200, Testing net (#0)
I1009 17:04:08.130357  7388 solver.cpp:404]     Test net output #0: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 17:04:08.150538  7388 solver.cpp:228] Iteration 200, loss = 2.30312
I1009 17:04:08.150573  7388 solver.cpp:244]     Train net output #0: loss = 2.30312 (* 1 = 2.30312 loss)
I1009 17:04:08.150579  7388 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I1009 17:04:11.525213  7388 solver.cpp:454] Snapshotting to binary proto file cifar-10_relu_SGD_iter_250.caffemodel
I1009 17:04:11.592555  7388 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_relu_SGD_iter_250.solverstate
I1009 17:04:11.620074  7388 solver.cpp:317] Iteration 250, loss = 2.30178
I1009 17:04:11.620097  7388 solver.cpp:337] Iteration 250, Testing net (#0)
I1009 17:04:14.469816  7388 solver.cpp:404]     Test net output #0: loss = 2.3026 (* 1 = 2.3026 loss)
I1009 17:04:14.469830  7388 solver.cpp:322] Optimization Done.
I1009 17:04:14.469833  7388 caffe.cpp:254] Optimization Done.
