I1009 20:07:20.729607  7775 caffe.cpp:217] Using GPUs 0
I1009 20:07:20.732316  7775 caffe.cpp:222] GPU 0: GeForce GTX 750 Ti
I1009 20:07:20.841544  7775 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt"
test_net: "/home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt"
test_iter: 100
test_interval: 25
base_lr: 0.001
display: 50
max_iter: 250
lr_policy: "step"
gamma: 0.1
weight_decay: 0.0005
stepsize: 5000
snapshot: 5000
snapshot_prefix: "cifar-10_relu_Adam"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
type: "Adam"
I1009 20:07:20.841670  7775 solver.cpp:81] Creating training net from train_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_train.prototxt
I1009 20:07:20.842031  7775 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1009 20:07:20.842155  7775 layer_factory.hpp:77] Creating layer data
I1009 20:07:20.842592  7775 net.cpp:100] Creating Layer data
I1009 20:07:20.842602  7775 net.cpp:408] data -> data
I1009 20:07:20.842639  7775 net.cpp:408] data -> label
I1009 20:07:20.842649  7775 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1009 20:07:20.845438  7780 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_train_lmdb
I1009 20:07:20.849743  7775 data_layer.cpp:41] output data size: 64,3,32,32
I1009 20:07:20.851303  7775 net.cpp:150] Setting up data
I1009 20:07:20.851318  7775 net.cpp:157] Top shape: 64 3 32 32 (196608)
I1009 20:07:20.851321  7775 net.cpp:157] Top shape: 64 (64)
I1009 20:07:20.851346  7775 net.cpp:165] Memory required for data: 786688
I1009 20:07:20.851354  7775 layer_factory.hpp:77] Creating layer label_data_1_split
I1009 20:07:20.851366  7775 net.cpp:100] Creating Layer label_data_1_split
I1009 20:07:20.851369  7775 net.cpp:434] label_data_1_split <- label
I1009 20:07:20.851395  7775 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1009 20:07:20.851418  7775 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1009 20:07:20.851495  7775 net.cpp:150] Setting up label_data_1_split
I1009 20:07:20.851501  7775 net.cpp:157] Top shape: 64 (64)
I1009 20:07:20.851516  7775 net.cpp:157] Top shape: 64 (64)
I1009 20:07:20.851518  7775 net.cpp:165] Memory required for data: 787200
I1009 20:07:20.851521  7775 layer_factory.hpp:77] Creating layer conv1
I1009 20:07:20.851546  7775 net.cpp:100] Creating Layer conv1
I1009 20:07:20.851564  7775 net.cpp:434] conv1 <- data
I1009 20:07:20.851570  7775 net.cpp:408] conv1 -> conv1
I1009 20:07:20.990463  7775 net.cpp:150] Setting up conv1
I1009 20:07:20.990486  7775 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1009 20:07:20.990489  7775 net.cpp:165] Memory required for data: 22905600
I1009 20:07:20.990506  7775 layer_factory.hpp:77] Creating layer relu1
I1009 20:07:20.990514  7775 net.cpp:100] Creating Layer relu1
I1009 20:07:20.990516  7775 net.cpp:434] relu1 <- conv1
I1009 20:07:20.990521  7775 net.cpp:395] relu1 -> conv1 (in-place)
I1009 20:07:20.990716  7775 net.cpp:150] Setting up relu1
I1009 20:07:20.990722  7775 net.cpp:157] Top shape: 64 96 30 30 (5529600)
I1009 20:07:20.990731  7775 net.cpp:165] Memory required for data: 45024000
I1009 20:07:20.990747  7775 layer_factory.hpp:77] Creating layer conv2
I1009 20:07:20.990758  7775 net.cpp:100] Creating Layer conv2
I1009 20:07:20.990761  7775 net.cpp:434] conv2 <- conv1
I1009 20:07:20.990767  7775 net.cpp:408] conv2 -> conv2
I1009 20:07:20.992177  7775 net.cpp:150] Setting up conv2
I1009 20:07:20.992187  7775 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1009 20:07:20.992189  7775 net.cpp:165] Memory required for data: 64291584
I1009 20:07:20.992195  7775 layer_factory.hpp:77] Creating layer relu2
I1009 20:07:20.992200  7775 net.cpp:100] Creating Layer relu2
I1009 20:07:20.992203  7775 net.cpp:434] relu2 <- conv2
I1009 20:07:20.992207  7775 net.cpp:395] relu2 -> conv2 (in-place)
I1009 20:07:20.992369  7775 net.cpp:150] Setting up relu2
I1009 20:07:20.992377  7775 net.cpp:157] Top shape: 64 96 28 28 (4816896)
I1009 20:07:20.992378  7775 net.cpp:165] Memory required for data: 83559168
I1009 20:07:20.992380  7775 layer_factory.hpp:77] Creating layer conv3
I1009 20:07:20.992386  7775 net.cpp:100] Creating Layer conv3
I1009 20:07:20.992389  7775 net.cpp:434] conv3 <- conv2
I1009 20:07:20.992393  7775 net.cpp:408] conv3 -> conv3
I1009 20:07:20.993599  7775 net.cpp:150] Setting up conv3
I1009 20:07:20.993608  7775 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1009 20:07:20.993612  7775 net.cpp:165] Memory required for data: 87712512
I1009 20:07:20.993618  7775 layer_factory.hpp:77] Creating layer relu3
I1009 20:07:20.993621  7775 net.cpp:100] Creating Layer relu3
I1009 20:07:20.993623  7775 net.cpp:434] relu3 <- conv3
I1009 20:07:20.993626  7775 net.cpp:395] relu3 -> conv3 (in-place)
I1009 20:07:20.993911  7775 net.cpp:150] Setting up relu3
I1009 20:07:20.993918  7775 net.cpp:157] Top shape: 64 96 13 13 (1038336)
I1009 20:07:20.993932  7775 net.cpp:165] Memory required for data: 91865856
I1009 20:07:20.993933  7775 layer_factory.hpp:77] Creating layer conv4
I1009 20:07:20.993940  7775 net.cpp:100] Creating Layer conv4
I1009 20:07:20.993942  7775 net.cpp:434] conv4 <- conv3
I1009 20:07:20.993947  7775 net.cpp:408] conv4 -> conv4
I1009 20:07:20.995740  7775 net.cpp:150] Setting up conv4
I1009 20:07:20.995751  7775 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1009 20:07:20.995754  7775 net.cpp:165] Memory required for data: 97813248
I1009 20:07:20.995759  7775 layer_factory.hpp:77] Creating layer relu4
I1009 20:07:20.995762  7775 net.cpp:100] Creating Layer relu4
I1009 20:07:20.995764  7775 net.cpp:434] relu4 <- conv4
I1009 20:07:20.995767  7775 net.cpp:395] relu4 -> conv4 (in-place)
I1009 20:07:20.995934  7775 net.cpp:150] Setting up relu4
I1009 20:07:20.995939  7775 net.cpp:157] Top shape: 64 192 11 11 (1486848)
I1009 20:07:20.995941  7775 net.cpp:165] Memory required for data: 103760640
I1009 20:07:20.995944  7775 layer_factory.hpp:77] Creating layer conv5
I1009 20:07:20.995949  7775 net.cpp:100] Creating Layer conv5
I1009 20:07:20.995950  7775 net.cpp:434] conv5 <- conv4
I1009 20:07:20.995954  7775 net.cpp:408] conv5 -> conv5
I1009 20:07:20.998447  7775 net.cpp:150] Setting up conv5
I1009 20:07:20.998457  7775 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1009 20:07:20.998459  7775 net.cpp:165] Memory required for data: 107741952
I1009 20:07:20.998466  7775 layer_factory.hpp:77] Creating layer relu5
I1009 20:07:20.998471  7775 net.cpp:100] Creating Layer relu5
I1009 20:07:20.998473  7775 net.cpp:434] relu5 <- conv5
I1009 20:07:20.998476  7775 net.cpp:395] relu5 -> conv5 (in-place)
I1009 20:07:20.998637  7775 net.cpp:150] Setting up relu5
I1009 20:07:20.998643  7775 net.cpp:157] Top shape: 64 192 9 9 (995328)
I1009 20:07:20.998646  7775 net.cpp:165] Memory required for data: 111723264
I1009 20:07:20.998647  7775 layer_factory.hpp:77] Creating layer conv6
I1009 20:07:20.998653  7775 net.cpp:100] Creating Layer conv6
I1009 20:07:20.998656  7775 net.cpp:434] conv6 <- conv5
I1009 20:07:20.998658  7775 net.cpp:408] conv6 -> conv6
I1009 20:07:21.001195  7775 net.cpp:150] Setting up conv6
I1009 20:07:21.001221  7775 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1009 20:07:21.001224  7775 net.cpp:165] Memory required for data: 112509696
I1009 20:07:21.001229  7775 layer_factory.hpp:77] Creating layer relu6
I1009 20:07:21.001246  7775 net.cpp:100] Creating Layer relu6
I1009 20:07:21.001250  7775 net.cpp:434] relu6 <- conv6
I1009 20:07:21.001266  7775 net.cpp:395] relu6 -> conv6 (in-place)
I1009 20:07:21.001502  7775 net.cpp:150] Setting up relu6
I1009 20:07:21.001524  7775 net.cpp:157] Top shape: 64 192 4 4 (196608)
I1009 20:07:21.001526  7775 net.cpp:165] Memory required for data: 113296128
I1009 20:07:21.001529  7775 layer_factory.hpp:77] Creating layer conv7
I1009 20:07:21.001535  7775 net.cpp:100] Creating Layer conv7
I1009 20:07:21.001538  7775 net.cpp:434] conv7 <- conv6
I1009 20:07:21.001543  7775 net.cpp:408] conv7 -> conv7
I1009 20:07:21.004573  7775 net.cpp:150] Setting up conv7
I1009 20:07:21.004592  7775 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:07:21.004595  7775 net.cpp:165] Memory required for data: 113492736
I1009 20:07:21.004601  7775 layer_factory.hpp:77] Creating layer relu7
I1009 20:07:21.004606  7775 net.cpp:100] Creating Layer relu7
I1009 20:07:21.004609  7775 net.cpp:434] relu7 <- conv7
I1009 20:07:21.004613  7775 net.cpp:395] relu7 -> conv7 (in-place)
I1009 20:07:21.004868  7775 net.cpp:150] Setting up relu7
I1009 20:07:21.004875  7775 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:07:21.004878  7775 net.cpp:165] Memory required for data: 113689344
I1009 20:07:21.004879  7775 layer_factory.hpp:77] Creating layer conv8
I1009 20:07:21.004889  7775 net.cpp:100] Creating Layer conv8
I1009 20:07:21.004891  7775 net.cpp:434] conv8 <- conv7
I1009 20:07:21.004896  7775 net.cpp:408] conv8 -> conv8
I1009 20:07:21.006135  7775 net.cpp:150] Setting up conv8
I1009 20:07:21.006145  7775 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:07:21.006157  7775 net.cpp:165] Memory required for data: 113885952
I1009 20:07:21.006162  7775 layer_factory.hpp:77] Creating layer relu8
I1009 20:07:21.006166  7775 net.cpp:100] Creating Layer relu8
I1009 20:07:21.006170  7775 net.cpp:434] relu8 <- conv8
I1009 20:07:21.006173  7775 net.cpp:395] relu8 -> conv8 (in-place)
I1009 20:07:21.006345  7775 net.cpp:150] Setting up relu8
I1009 20:07:21.006351  7775 net.cpp:157] Top shape: 64 192 2 2 (49152)
I1009 20:07:21.006353  7775 net.cpp:165] Memory required for data: 114082560
I1009 20:07:21.006356  7775 layer_factory.hpp:77] Creating layer conv9
I1009 20:07:21.006361  7775 net.cpp:100] Creating Layer conv9
I1009 20:07:21.006364  7775 net.cpp:434] conv9 <- conv8
I1009 20:07:21.006367  7775 net.cpp:408] conv9 -> conv9
I1009 20:07:21.007184  7775 net.cpp:150] Setting up conv9
I1009 20:07:21.007194  7775 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1009 20:07:21.007196  7775 net.cpp:165] Memory required for data: 114092800
I1009 20:07:21.007205  7775 layer_factory.hpp:77] Creating layer relu9
I1009 20:07:21.007210  7775 net.cpp:100] Creating Layer relu9
I1009 20:07:21.007213  7775 net.cpp:434] relu9 <- conv9
I1009 20:07:21.007216  7775 net.cpp:395] relu9 -> conv9 (in-place)
I1009 20:07:21.007462  7775 net.cpp:150] Setting up relu9
I1009 20:07:21.007469  7775 net.cpp:157] Top shape: 64 10 2 2 (2560)
I1009 20:07:21.007472  7775 net.cpp:165] Memory required for data: 114103040
I1009 20:07:21.007473  7775 layer_factory.hpp:77] Creating layer pool
I1009 20:07:21.007478  7775 net.cpp:100] Creating Layer pool
I1009 20:07:21.007482  7775 net.cpp:434] pool <- conv9
I1009 20:07:21.007484  7775 net.cpp:408] pool -> pool
I1009 20:07:21.007688  7775 net.cpp:150] Setting up pool
I1009 20:07:21.007694  7775 net.cpp:157] Top shape: 64 10 1 1 (640)
I1009 20:07:21.007695  7775 net.cpp:165] Memory required for data: 114105600
I1009 20:07:21.007697  7775 layer_factory.hpp:77] Creating layer score
I1009 20:07:21.007702  7775 net.cpp:100] Creating Layer score
I1009 20:07:21.007704  7775 net.cpp:434] score <- pool
I1009 20:07:21.007709  7775 net.cpp:408] score -> score
I1009 20:07:21.007861  7775 net.cpp:150] Setting up score
I1009 20:07:21.007866  7775 net.cpp:157] Top shape: 64 10 (640)
I1009 20:07:21.007869  7775 net.cpp:165] Memory required for data: 114108160
I1009 20:07:21.007872  7775 layer_factory.hpp:77] Creating layer score_score_0_split
I1009 20:07:21.007876  7775 net.cpp:100] Creating Layer score_score_0_split
I1009 20:07:21.007879  7775 net.cpp:434] score_score_0_split <- score
I1009 20:07:21.007882  7775 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1009 20:07:21.007886  7775 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1009 20:07:21.007931  7775 net.cpp:150] Setting up score_score_0_split
I1009 20:07:21.007936  7775 net.cpp:157] Top shape: 64 10 (640)
I1009 20:07:21.007937  7775 net.cpp:157] Top shape: 64 10 (640)
I1009 20:07:21.007939  7775 net.cpp:165] Memory required for data: 114113280
I1009 20:07:21.007941  7775 layer_factory.hpp:77] Creating layer accuracy
I1009 20:07:21.007946  7775 net.cpp:100] Creating Layer accuracy
I1009 20:07:21.007947  7775 net.cpp:434] accuracy <- score_score_0_split_0
I1009 20:07:21.007951  7775 net.cpp:434] accuracy <- label_data_1_split_0
I1009 20:07:21.007956  7775 net.cpp:408] accuracy -> accuracy
I1009 20:07:21.007961  7775 net.cpp:150] Setting up accuracy
I1009 20:07:21.007964  7775 net.cpp:157] Top shape: (1)
I1009 20:07:21.007966  7775 net.cpp:165] Memory required for data: 114113284
I1009 20:07:21.007967  7775 layer_factory.hpp:77] Creating layer loss
I1009 20:07:21.007971  7775 net.cpp:100] Creating Layer loss
I1009 20:07:21.007987  7775 net.cpp:434] loss <- score_score_0_split_1
I1009 20:07:21.007989  7775 net.cpp:434] loss <- label_data_1_split_1
I1009 20:07:21.008008  7775 net.cpp:408] loss -> loss
I1009 20:07:21.008015  7775 layer_factory.hpp:77] Creating layer loss
I1009 20:07:21.008370  7775 net.cpp:150] Setting up loss
I1009 20:07:21.008378  7775 net.cpp:157] Top shape: (1)
I1009 20:07:21.008380  7775 net.cpp:160]     with loss weight 1
I1009 20:07:21.008399  7775 net.cpp:165] Memory required for data: 114113288
I1009 20:07:21.008401  7775 net.cpp:226] loss needs backward computation.
I1009 20:07:21.008406  7775 net.cpp:228] accuracy does not need backward computation.
I1009 20:07:21.008409  7775 net.cpp:226] score_score_0_split needs backward computation.
I1009 20:07:21.008411  7775 net.cpp:226] score needs backward computation.
I1009 20:07:21.008414  7775 net.cpp:226] pool needs backward computation.
I1009 20:07:21.008415  7775 net.cpp:226] relu9 needs backward computation.
I1009 20:07:21.008431  7775 net.cpp:226] conv9 needs backward computation.
I1009 20:07:21.008433  7775 net.cpp:226] relu8 needs backward computation.
I1009 20:07:21.008435  7775 net.cpp:226] conv8 needs backward computation.
I1009 20:07:21.008437  7775 net.cpp:226] relu7 needs backward computation.
I1009 20:07:21.008440  7775 net.cpp:226] conv7 needs backward computation.
I1009 20:07:21.008441  7775 net.cpp:226] relu6 needs backward computation.
I1009 20:07:21.008443  7775 net.cpp:226] conv6 needs backward computation.
I1009 20:07:21.008445  7775 net.cpp:226] relu5 needs backward computation.
I1009 20:07:21.008447  7775 net.cpp:226] conv5 needs backward computation.
I1009 20:07:21.008450  7775 net.cpp:226] relu4 needs backward computation.
I1009 20:07:21.008451  7775 net.cpp:226] conv4 needs backward computation.
I1009 20:07:21.008467  7775 net.cpp:226] relu3 needs backward computation.
I1009 20:07:21.008471  7775 net.cpp:226] conv3 needs backward computation.
I1009 20:07:21.008472  7775 net.cpp:226] relu2 needs backward computation.
I1009 20:07:21.008473  7775 net.cpp:226] conv2 needs backward computation.
I1009 20:07:21.008492  7775 net.cpp:226] relu1 needs backward computation.
I1009 20:07:21.008494  7775 net.cpp:226] conv1 needs backward computation.
I1009 20:07:21.008498  7775 net.cpp:228] label_data_1_split does not need backward computation.
I1009 20:07:21.008502  7775 net.cpp:228] data does not need backward computation.
I1009 20:07:21.008517  7775 net.cpp:270] This network produces output accuracy
I1009 20:07:21.008519  7775 net.cpp:270] This network produces output loss
I1009 20:07:21.008544  7775 net.cpp:283] Network initialization done.
I1009 20:07:21.008747  7775 solver.cpp:181] Creating test net (#0) specified by test_net file: /home/adam/Honours/Honours-Project/cifar-10_allcnn/relu/allcnn_relu_test.prototxt
I1009 20:07:21.008877  7775 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../data/cifar-10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 96
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 192
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 192
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv9"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1009 20:07:21.008967  7775 layer_factory.hpp:77] Creating layer data
I1009 20:07:21.009058  7775 net.cpp:100] Creating Layer data
I1009 20:07:21.009064  7775 net.cpp:408] data -> data
I1009 20:07:21.009084  7775 net.cpp:408] data -> label
I1009 20:07:21.009104  7775 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
I1009 20:07:21.009843  7782 db_lmdb.cpp:35] Opened lmdb ../../../data/cifar-10/cifar10_test_lmdb
I1009 20:07:21.009969  7775 data_layer.cpp:41] output data size: 100,3,32,32
I1009 20:07:21.011996  7775 net.cpp:150] Setting up data
I1009 20:07:21.012037  7775 net.cpp:157] Top shape: 100 3 32 32 (307200)
I1009 20:07:21.012042  7775 net.cpp:157] Top shape: 100 (100)
I1009 20:07:21.012043  7775 net.cpp:165] Memory required for data: 1229200
I1009 20:07:21.012048  7775 layer_factory.hpp:77] Creating layer label_data_1_split
I1009 20:07:21.012058  7775 net.cpp:100] Creating Layer label_data_1_split
I1009 20:07:21.012060  7775 net.cpp:434] label_data_1_split <- label
I1009 20:07:21.012064  7775 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1009 20:07:21.012086  7775 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1009 20:07:21.012184  7775 net.cpp:150] Setting up label_data_1_split
I1009 20:07:21.012189  7775 net.cpp:157] Top shape: 100 (100)
I1009 20:07:21.012192  7775 net.cpp:157] Top shape: 100 (100)
I1009 20:07:21.012193  7775 net.cpp:165] Memory required for data: 1230000
I1009 20:07:21.012195  7775 layer_factory.hpp:77] Creating layer conv1
I1009 20:07:21.012228  7775 net.cpp:100] Creating Layer conv1
I1009 20:07:21.012230  7775 net.cpp:434] conv1 <- data
I1009 20:07:21.012248  7775 net.cpp:408] conv1 -> conv1
I1009 20:07:21.013440  7775 net.cpp:150] Setting up conv1
I1009 20:07:21.013463  7775 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1009 20:07:21.013465  7775 net.cpp:165] Memory required for data: 35790000
I1009 20:07:21.013486  7775 layer_factory.hpp:77] Creating layer relu1
I1009 20:07:21.013505  7775 net.cpp:100] Creating Layer relu1
I1009 20:07:21.013509  7775 net.cpp:434] relu1 <- conv1
I1009 20:07:21.013511  7775 net.cpp:395] relu1 -> conv1 (in-place)
I1009 20:07:21.013685  7775 net.cpp:150] Setting up relu1
I1009 20:07:21.013707  7775 net.cpp:157] Top shape: 100 96 30 30 (8640000)
I1009 20:07:21.013749  7775 net.cpp:165] Memory required for data: 70350000
I1009 20:07:21.013753  7775 layer_factory.hpp:77] Creating layer conv2
I1009 20:07:21.013766  7775 net.cpp:100] Creating Layer conv2
I1009 20:07:21.013778  7775 net.cpp:434] conv2 <- conv1
I1009 20:07:21.013784  7775 net.cpp:408] conv2 -> conv2
I1009 20:07:21.015043  7775 net.cpp:150] Setting up conv2
I1009 20:07:21.015053  7775 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1009 20:07:21.015056  7775 net.cpp:165] Memory required for data: 100455600
I1009 20:07:21.015064  7775 layer_factory.hpp:77] Creating layer relu2
I1009 20:07:21.015067  7775 net.cpp:100] Creating Layer relu2
I1009 20:07:21.015071  7775 net.cpp:434] relu2 <- conv2
I1009 20:07:21.015075  7775 net.cpp:395] relu2 -> conv2 (in-place)
I1009 20:07:21.015316  7775 net.cpp:150] Setting up relu2
I1009 20:07:21.015324  7775 net.cpp:157] Top shape: 100 96 28 28 (7526400)
I1009 20:07:21.015328  7775 net.cpp:165] Memory required for data: 130561200
I1009 20:07:21.015331  7775 layer_factory.hpp:77] Creating layer conv3
I1009 20:07:21.015337  7775 net.cpp:100] Creating Layer conv3
I1009 20:07:21.015341  7775 net.cpp:434] conv3 <- conv2
I1009 20:07:21.015346  7775 net.cpp:408] conv3 -> conv3
I1009 20:07:21.016546  7775 net.cpp:150] Setting up conv3
I1009 20:07:21.016572  7775 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1009 20:07:21.016576  7775 net.cpp:165] Memory required for data: 137050800
I1009 20:07:21.016582  7775 layer_factory.hpp:77] Creating layer relu3
I1009 20:07:21.016588  7775 net.cpp:100] Creating Layer relu3
I1009 20:07:21.016592  7775 net.cpp:434] relu3 <- conv3
I1009 20:07:21.016597  7775 net.cpp:395] relu3 -> conv3 (in-place)
I1009 20:07:21.016957  7775 net.cpp:150] Setting up relu3
I1009 20:07:21.016966  7775 net.cpp:157] Top shape: 100 96 13 13 (1622400)
I1009 20:07:21.016969  7775 net.cpp:165] Memory required for data: 143540400
I1009 20:07:21.016973  7775 layer_factory.hpp:77] Creating layer conv4
I1009 20:07:21.016980  7775 net.cpp:100] Creating Layer conv4
I1009 20:07:21.016984  7775 net.cpp:434] conv4 <- conv3
I1009 20:07:21.016989  7775 net.cpp:408] conv4 -> conv4
I1009 20:07:21.019017  7775 net.cpp:150] Setting up conv4
I1009 20:07:21.019033  7775 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1009 20:07:21.019037  7775 net.cpp:165] Memory required for data: 152833200
I1009 20:07:21.019057  7775 layer_factory.hpp:77] Creating layer relu4
I1009 20:07:21.019062  7775 net.cpp:100] Creating Layer relu4
I1009 20:07:21.019065  7775 net.cpp:434] relu4 <- conv4
I1009 20:07:21.019070  7775 net.cpp:395] relu4 -> conv4 (in-place)
I1009 20:07:21.019263  7775 net.cpp:150] Setting up relu4
I1009 20:07:21.019273  7775 net.cpp:157] Top shape: 100 192 11 11 (2323200)
I1009 20:07:21.019289  7775 net.cpp:165] Memory required for data: 162126000
I1009 20:07:21.019291  7775 layer_factory.hpp:77] Creating layer conv5
I1009 20:07:21.019311  7775 net.cpp:100] Creating Layer conv5
I1009 20:07:21.019315  7775 net.cpp:434] conv5 <- conv4
I1009 20:07:21.019320  7775 net.cpp:408] conv5 -> conv5
I1009 20:07:21.022083  7775 net.cpp:150] Setting up conv5
I1009 20:07:21.022097  7775 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1009 20:07:21.022099  7775 net.cpp:165] Memory required for data: 168346800
I1009 20:07:21.022124  7775 layer_factory.hpp:77] Creating layer relu5
I1009 20:07:21.022130  7775 net.cpp:100] Creating Layer relu5
I1009 20:07:21.022132  7775 net.cpp:434] relu5 <- conv5
I1009 20:07:21.022136  7775 net.cpp:395] relu5 -> conv5 (in-place)
I1009 20:07:21.022438  7775 net.cpp:150] Setting up relu5
I1009 20:07:21.022446  7775 net.cpp:157] Top shape: 100 192 9 9 (1555200)
I1009 20:07:21.022449  7775 net.cpp:165] Memory required for data: 174567600
I1009 20:07:21.022450  7775 layer_factory.hpp:77] Creating layer conv6
I1009 20:07:21.022456  7775 net.cpp:100] Creating Layer conv6
I1009 20:07:21.022459  7775 net.cpp:434] conv6 <- conv5
I1009 20:07:21.022462  7775 net.cpp:408] conv6 -> conv6
I1009 20:07:21.025002  7775 net.cpp:150] Setting up conv6
I1009 20:07:21.025012  7775 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1009 20:07:21.025014  7775 net.cpp:165] Memory required for data: 175796400
I1009 20:07:21.025018  7775 layer_factory.hpp:77] Creating layer relu6
I1009 20:07:21.025032  7775 net.cpp:100] Creating Layer relu6
I1009 20:07:21.025035  7775 net.cpp:434] relu6 <- conv6
I1009 20:07:21.025040  7775 net.cpp:395] relu6 -> conv6 (in-place)
I1009 20:07:21.025303  7775 net.cpp:150] Setting up relu6
I1009 20:07:21.025311  7775 net.cpp:157] Top shape: 100 192 4 4 (307200)
I1009 20:07:21.025313  7775 net.cpp:165] Memory required for data: 177025200
I1009 20:07:21.025315  7775 layer_factory.hpp:77] Creating layer conv7
I1009 20:07:21.025321  7775 net.cpp:100] Creating Layer conv7
I1009 20:07:21.025323  7775 net.cpp:434] conv7 <- conv6
I1009 20:07:21.025327  7775 net.cpp:408] conv7 -> conv7
I1009 20:07:21.027933  7775 net.cpp:150] Setting up conv7
I1009 20:07:21.027943  7775 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:07:21.027946  7775 net.cpp:165] Memory required for data: 177332400
I1009 20:07:21.027951  7775 layer_factory.hpp:77] Creating layer relu7
I1009 20:07:21.027954  7775 net.cpp:100] Creating Layer relu7
I1009 20:07:21.027956  7775 net.cpp:434] relu7 <- conv7
I1009 20:07:21.027961  7775 net.cpp:395] relu7 -> conv7 (in-place)
I1009 20:07:21.028136  7775 net.cpp:150] Setting up relu7
I1009 20:07:21.028141  7775 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:07:21.028143  7775 net.cpp:165] Memory required for data: 177639600
I1009 20:07:21.028146  7775 layer_factory.hpp:77] Creating layer conv8
I1009 20:07:21.028154  7775 net.cpp:100] Creating Layer conv8
I1009 20:07:21.028156  7775 net.cpp:434] conv8 <- conv7
I1009 20:07:21.028161  7775 net.cpp:408] conv8 -> conv8
I1009 20:07:21.029145  7775 net.cpp:150] Setting up conv8
I1009 20:07:21.029153  7775 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:07:21.029155  7775 net.cpp:165] Memory required for data: 177946800
I1009 20:07:21.029160  7775 layer_factory.hpp:77] Creating layer relu8
I1009 20:07:21.029165  7775 net.cpp:100] Creating Layer relu8
I1009 20:07:21.029166  7775 net.cpp:434] relu8 <- conv8
I1009 20:07:21.029170  7775 net.cpp:395] relu8 -> conv8 (in-place)
I1009 20:07:21.029428  7775 net.cpp:150] Setting up relu8
I1009 20:07:21.029435  7775 net.cpp:157] Top shape: 100 192 2 2 (76800)
I1009 20:07:21.029438  7775 net.cpp:165] Memory required for data: 178254000
I1009 20:07:21.029440  7775 layer_factory.hpp:77] Creating layer conv9
I1009 20:07:21.029446  7775 net.cpp:100] Creating Layer conv9
I1009 20:07:21.029448  7775 net.cpp:434] conv9 <- conv8
I1009 20:07:21.029453  7775 net.cpp:408] conv9 -> conv9
I1009 20:07:21.030208  7775 net.cpp:150] Setting up conv9
I1009 20:07:21.030216  7775 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1009 20:07:21.030218  7775 net.cpp:165] Memory required for data: 178270000
I1009 20:07:21.030226  7775 layer_factory.hpp:77] Creating layer relu9
I1009 20:07:21.030230  7775 net.cpp:100] Creating Layer relu9
I1009 20:07:21.030232  7775 net.cpp:434] relu9 <- conv9
I1009 20:07:21.030236  7775 net.cpp:395] relu9 -> conv9 (in-place)
I1009 20:07:21.030495  7775 net.cpp:150] Setting up relu9
I1009 20:07:21.030503  7775 net.cpp:157] Top shape: 100 10 2 2 (4000)
I1009 20:07:21.030505  7775 net.cpp:165] Memory required for data: 178286000
I1009 20:07:21.030508  7775 layer_factory.hpp:77] Creating layer pool
I1009 20:07:21.030511  7775 net.cpp:100] Creating Layer pool
I1009 20:07:21.030514  7775 net.cpp:434] pool <- conv9
I1009 20:07:21.030517  7775 net.cpp:408] pool -> pool
I1009 20:07:21.030755  7775 net.cpp:150] Setting up pool
I1009 20:07:21.030762  7775 net.cpp:157] Top shape: 100 10 1 1 (1000)
I1009 20:07:21.030764  7775 net.cpp:165] Memory required for data: 178290000
I1009 20:07:21.030766  7775 layer_factory.hpp:77] Creating layer score
I1009 20:07:21.030771  7775 net.cpp:100] Creating Layer score
I1009 20:07:21.030773  7775 net.cpp:434] score <- pool
I1009 20:07:21.030776  7775 net.cpp:408] score -> score
I1009 20:07:21.030921  7775 net.cpp:150] Setting up score
I1009 20:07:21.030926  7775 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:07:21.030928  7775 net.cpp:165] Memory required for data: 178294000
I1009 20:07:21.030932  7775 layer_factory.hpp:77] Creating layer score_score_0_split
I1009 20:07:21.030946  7775 net.cpp:100] Creating Layer score_score_0_split
I1009 20:07:21.030948  7775 net.cpp:434] score_score_0_split <- score
I1009 20:07:21.030951  7775 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1009 20:07:21.030956  7775 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1009 20:07:21.031030  7775 net.cpp:150] Setting up score_score_0_split
I1009 20:07:21.031036  7775 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:07:21.031039  7775 net.cpp:157] Top shape: 100 10 (1000)
I1009 20:07:21.031054  7775 net.cpp:165] Memory required for data: 178302000
I1009 20:07:21.031056  7775 layer_factory.hpp:77] Creating layer accuracy
I1009 20:07:21.031060  7775 net.cpp:100] Creating Layer accuracy
I1009 20:07:21.031062  7775 net.cpp:434] accuracy <- score_score_0_split_0
I1009 20:07:21.031065  7775 net.cpp:434] accuracy <- label_data_1_split_0
I1009 20:07:21.031069  7775 net.cpp:408] accuracy -> accuracy
I1009 20:07:21.031075  7775 net.cpp:150] Setting up accuracy
I1009 20:07:21.031092  7775 net.cpp:157] Top shape: (1)
I1009 20:07:21.031095  7775 net.cpp:165] Memory required for data: 178302004
I1009 20:07:21.031096  7775 layer_factory.hpp:77] Creating layer loss
I1009 20:07:21.031112  7775 net.cpp:100] Creating Layer loss
I1009 20:07:21.031114  7775 net.cpp:434] loss <- score_score_0_split_1
I1009 20:07:21.031117  7775 net.cpp:434] loss <- label_data_1_split_1
I1009 20:07:21.031121  7775 net.cpp:408] loss -> loss
I1009 20:07:21.031141  7775 layer_factory.hpp:77] Creating layer loss
I1009 20:07:21.031462  7775 net.cpp:150] Setting up loss
I1009 20:07:21.031471  7775 net.cpp:157] Top shape: (1)
I1009 20:07:21.031486  7775 net.cpp:160]     with loss weight 1
I1009 20:07:21.031493  7775 net.cpp:165] Memory required for data: 178302008
I1009 20:07:21.031497  7775 net.cpp:226] loss needs backward computation.
I1009 20:07:21.031499  7775 net.cpp:228] accuracy does not need backward computation.
I1009 20:07:21.031503  7775 net.cpp:226] score_score_0_split needs backward computation.
I1009 20:07:21.031520  7775 net.cpp:226] score needs backward computation.
I1009 20:07:21.031522  7775 net.cpp:226] pool needs backward computation.
I1009 20:07:21.031524  7775 net.cpp:226] relu9 needs backward computation.
I1009 20:07:21.031527  7775 net.cpp:226] conv9 needs backward computation.
I1009 20:07:21.031541  7775 net.cpp:226] relu8 needs backward computation.
I1009 20:07:21.031543  7775 net.cpp:226] conv8 needs backward computation.
I1009 20:07:21.031545  7775 net.cpp:226] relu7 needs backward computation.
I1009 20:07:21.031548  7775 net.cpp:226] conv7 needs backward computation.
I1009 20:07:21.031549  7775 net.cpp:226] relu6 needs backward computation.
I1009 20:07:21.031551  7775 net.cpp:226] conv6 needs backward computation.
I1009 20:07:21.031553  7775 net.cpp:226] relu5 needs backward computation.
I1009 20:07:21.031555  7775 net.cpp:226] conv5 needs backward computation.
I1009 20:07:21.031558  7775 net.cpp:226] relu4 needs backward computation.
I1009 20:07:21.031559  7775 net.cpp:226] conv4 needs backward computation.
I1009 20:07:21.031561  7775 net.cpp:226] relu3 needs backward computation.
I1009 20:07:21.031577  7775 net.cpp:226] conv3 needs backward computation.
I1009 20:07:21.031579  7775 net.cpp:226] relu2 needs backward computation.
I1009 20:07:21.031581  7775 net.cpp:226] conv2 needs backward computation.
I1009 20:07:21.031584  7775 net.cpp:226] relu1 needs backward computation.
I1009 20:07:21.031585  7775 net.cpp:226] conv1 needs backward computation.
I1009 20:07:21.031589  7775 net.cpp:228] label_data_1_split does not need backward computation.
I1009 20:07:21.031591  7775 net.cpp:228] data does not need backward computation.
I1009 20:07:21.031594  7775 net.cpp:270] This network produces output accuracy
I1009 20:07:21.031595  7775 net.cpp:270] This network produces output loss
I1009 20:07:21.031608  7775 net.cpp:283] Network initialization done.
I1009 20:07:21.031693  7775 solver.cpp:60] Solver scaffolding done.
I1009 20:07:21.032557  7775 caffe.cpp:251] Starting Optimization
I1009 20:07:21.032572  7775 solver.cpp:279] Solving 
I1009 20:07:21.032574  7775 solver.cpp:280] Learning Rate Policy: step
I1009 20:07:21.033385  7775 solver.cpp:337] Iteration 0, Testing net (#0)
I1009 20:07:23.892998  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1076
I1009 20:07:23.893019  7775 solver.cpp:404]     Test net output #1: loss = 4.98332 (* 1 = 4.98332 loss)
I1009 20:07:23.915380  7775 solver.cpp:228] Iteration 0, loss = 4.52844
I1009 20:07:23.915400  7775 solver.cpp:244]     Train net output #0: accuracy = 0.125
I1009 20:07:23.915407  7775 solver.cpp:244]     Train net output #1: loss = 4.52844 (* 1 = 4.52844 loss)
I1009 20:07:23.915416  7775 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1009 20:07:25.577203  7775 solver.cpp:337] Iteration 25, Testing net (#0)
I1009 20:07:28.484374  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:07:28.484422  7775 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:07:30.167080  7775 solver.cpp:337] Iteration 50, Testing net (#0)
I1009 20:07:33.073173  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:07:33.073195  7775 solver.cpp:404]     Test net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I1009 20:07:33.093587  7775 solver.cpp:228] Iteration 50, loss = 2.30252
I1009 20:07:33.093605  7775 solver.cpp:244]     Train net output #0: accuracy = 0.078125
I1009 20:07:33.093611  7775 solver.cpp:244]     Train net output #1: loss = 2.30252 (* 1 = 2.30252 loss)
I1009 20:07:33.093631  7775 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I1009 20:07:34.753049  7775 solver.cpp:337] Iteration 75, Testing net (#0)
I1009 20:07:37.661834  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:07:37.661856  7775 solver.cpp:404]     Test net output #1: loss = 2.3026 (* 1 = 2.3026 loss)
I1009 20:07:39.343101  7775 solver.cpp:337] Iteration 100, Testing net (#0)
I1009 20:07:42.254292  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:07:42.254315  7775 solver.cpp:404]     Test net output #1: loss = 2.30261 (* 1 = 2.30261 loss)
I1009 20:07:42.274549  7775 solver.cpp:228] Iteration 100, loss = 2.30299
I1009 20:07:42.274565  7775 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1009 20:07:42.274571  7775 solver.cpp:244]     Train net output #1: loss = 2.30299 (* 1 = 2.30299 loss)
I1009 20:07:42.274575  7775 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I1009 20:07:43.935328  7775 solver.cpp:337] Iteration 125, Testing net (#0)
I1009 20:07:46.842571  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:07:46.842592  7775 solver.cpp:404]     Test net output #1: loss = 2.3026 (* 1 = 2.3026 loss)
I1009 20:07:48.522053  7775 solver.cpp:337] Iteration 150, Testing net (#0)
I1009 20:07:51.428000  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:07:51.428061  7775 solver.cpp:404]     Test net output #1: loss = 2.30262 (* 1 = 2.30262 loss)
I1009 20:07:51.448302  7775 solver.cpp:228] Iteration 150, loss = 2.30248
I1009 20:07:51.448319  7775 solver.cpp:244]     Train net output #0: accuracy = 0.140625
I1009 20:07:51.448325  7775 solver.cpp:244]     Train net output #1: loss = 2.30248 (* 1 = 2.30248 loss)
I1009 20:07:51.448329  7775 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I1009 20:07:53.108887  7775 solver.cpp:337] Iteration 175, Testing net (#0)
I1009 20:07:56.016383  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:07:56.016404  7775 solver.cpp:404]     Test net output #1: loss = 2.30263 (* 1 = 2.30263 loss)
I1009 20:07:57.696614  7775 solver.cpp:337] Iteration 200, Testing net (#0)
I1009 20:08:00.603590  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:00.603613  7775 solver.cpp:404]     Test net output #1: loss = 2.30263 (* 1 = 2.30263 loss)
I1009 20:08:00.623833  7775 solver.cpp:228] Iteration 200, loss = 2.30286
I1009 20:08:00.623852  7775 solver.cpp:244]     Train net output #0: accuracy = 0.078125
I1009 20:08:00.623858  7775 solver.cpp:244]     Train net output #1: loss = 2.30286 (* 1 = 2.30286 loss)
I1009 20:08:00.623862  7775 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I1009 20:08:02.289582  7775 solver.cpp:337] Iteration 225, Testing net (#0)
I1009 20:08:05.196571  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:05.196593  7775 solver.cpp:404]     Test net output #1: loss = 2.30263 (* 1 = 2.30263 loss)
I1009 20:08:06.876768  7775 solver.cpp:454] Snapshotting to binary proto file cifar-10_relu_Adam_iter_250.caffemodel
I1009 20:08:06.950057  7775 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_relu_Adam_iter_250.solverstate
I1009 20:08:06.985389  7775 solver.cpp:317] Iteration 250, loss = 2.30171
I1009 20:08:06.985410  7775 solver.cpp:337] Iteration 250, Testing net (#0)
I1009 20:08:09.839905  7775 solver.cpp:404]     Test net output #0: accuracy = 0.1
I1009 20:08:09.839928  7775 solver.cpp:404]     Test net output #1: loss = 2.30264 (* 1 = 2.30264 loss)
I1009 20:08:09.839931  7775 solver.cpp:322] Optimization Done.
I1009 20:08:09.839933  7775 caffe.cpp:254] Optimization Done.
