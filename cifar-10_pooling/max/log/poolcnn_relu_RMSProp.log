I1020 00:57:33.244163  8342 caffe.cpp:217] Using GPUs 0
I1020 00:57:33.246747  8342 caffe.cpp:222] GPU 0: GeForce GTX 960
I1020 00:57:33.364552  8342 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/adam/Honours/Honours-Project/cifar-10_pooling/max/relu/poolcnn_relu_train.prototxt"
test_net: "/home/adam/Honours/Honours-Project/cifar-10_pooling/max/relu/poolcnn_relu_test.prototxt"
test_iter: 100
test_interval: 150
base_lr: 0.0001
display: 50
max_iter: 15000
lr_policy: "step"
gamma: 0.1
weight_decay: 0.0005
stepsize: 5000
snapshot: 5000
snapshot_prefix: "cifar-10_relu_RMSProp"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
type: "RMSProp"
I1020 00:57:33.364670  8342 solver.cpp:81] Creating training net from train_net file: /home/adam/Honours/Honours-Project/cifar-10_pooling/max/relu/poolcnn_relu_train.prototxt
I1020 00:57:33.364982  8342 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mean_file: "mean.binaryproto"
  }
  data_param {
    source: "../../../../data/cifar-10/cifar10_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 192
    kernel_size: 5
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "relu1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "drop1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2"
  top: "conv3"
  convolution_param {
    num_output: 240
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "relu3"
  top: "drop2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "drop2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool2"
  top: "conv4"
  convolution_param {
    num_output: 240
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  convolution_param {
    num_output: 260
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "relu5"
  top: "drop3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "drop3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "pool3"
  top: "conv6"
  convolution_param {
    num_output: 260
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "relu6"
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "relu6"
  top: "conv7"
  convolution_param {
    num_output: 280
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "relu7"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "relu7"
  top: "drop4"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "drop4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "pool4"
  top: "conv8"
  convolution_param {
    num_output: 280
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv8"
  top: "relu8"
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "relu8"
  top: "drop5"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "drop5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "pool5"
  top: "conv10"
  convolution_param {
    num_output: 300
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu10"
  type: "ReLU"
  bottom: "conv10"
  top: "relu10"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu10"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "drop6"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "pool6"
  top: "conv11"
  convolution_param {
    num_output: 100
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv11"
  top: "relu11"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu11"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "drop7"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool7"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1020 00:57:33.365084  8342 layer_factory.hpp:77] Creating layer data
I1020 00:57:33.365465  8342 net.cpp:100] Creating Layer data
I1020 00:57:33.365473  8342 net.cpp:408] data -> data
I1020 00:57:33.365486  8342 net.cpp:408] data -> label
I1020 00:57:33.365500  8342 data_transformer.cpp:25] Loading mean file from: mean.binaryproto
F1020 00:57:33.365510  8342 io.cpp:54] Check failed: fd != -1 (-1 vs. -1) File not found: mean.binaryproto
*** Check failure stack trace: ***
I1020 00:57:33.366116  8347 db_lmdb.cpp:35] Opened lmdb ../../../../data/cifar-10/cifar10_train_lmdb
    @     0x7ff7991b75cd  google::LogMessage::Fail()
    @     0x7ff7991b9433  google::LogMessage::SendToLog()
    @     0x7ff7991b715b  google::LogMessage::Flush()
    @     0x7ff7991b9e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7ff79980b20c  caffe::ReadProtoFromBinaryFile()
    @     0x7ff79999b31e  caffe::DataTransformer<>::DataTransformer()
    @     0x7ff79983e579  caffe::BaseDataLayer<>::LayerSetUp()
    @     0x7ff79983e6b3  caffe::BasePrefetchingDataLayer<>::LayerSetUp()
    @     0x7ff79982e9b2  caffe::Net<>::Init()
    @     0x7ff799830241  caffe::Net<>::Net()
    @     0x7ff79998ad8a  caffe::Solver<>::InitTrainNet()
    @     0x7ff79998c0f7  caffe::Solver<>::Init()
    @     0x7ff79998c49a  caffe::Solver<>::Solver()
    @     0x7ff7999848e9  caffe::Creator_RMSPropSolver<>()
    @           0x40afb9  train()
    @           0x4077c8  main
    @     0x7ff79794e830  __libc_start_main
    @           0x408099  _start
    @              (nil)  (unknown)
