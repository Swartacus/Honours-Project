I1018 19:33:25.974789  5095 caffe.cpp:217] Using GPUs 0
I1018 19:33:25.977411  5095 caffe.cpp:222] GPU 0: GeForce GTX 960
I1018 19:33:26.092641  5095 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/adam/Honours/Honours-Project/mnist_pooling/max/leakyrelu/poolcnn_leakyrelu_train.prototxt"
test_net: "/home/adam/Honours/Honours-Project/mnist_pooling/max/leakyrelu/poolcnn_leakyrelu_test.prototxt"
test_iter: 100
test_interval: 150
base_lr: 0.0001
display: 50
max_iter: 15000
lr_policy: "step"
gamma: 0.1
weight_decay: 0.0005
stepsize: 5000
snapshot: 5000
snapshot_prefix: "cifar-10_leakyrelu_RMSProp"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
type: "RMSProp"
I1018 19:33:26.092751  5095 solver.cpp:81] Creating training net from train_net file: /home/adam/Honours/Honours-Project/mnist_pooling/max/leakyrelu/poolcnn_leakyrelu_train.prototxt
I1018 19:33:26.093094  5095 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.0039215689
  }
  data_param {
    source: "../../../../data/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 192
    kernel_size: 5
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "drop1"
  top: "relu1"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1"
  top: "conv2"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 240
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv3"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "drop2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "drop2"
  top: "relu2"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu2"
  top: "conv4"
  convolution_param {
    num_output: 240
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 260
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "pool3"
  top: "drop3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "drop3"
  top: "relu3"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "relu3"
  top: "conv6"
  convolution_param {
    num_output: 260
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 280
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv7"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "pool4"
  top: "drop4"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "drop4"
  top: "relu4"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "relu4"
  top: "conv8"
  convolution_param {
    num_output: 280
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv8"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "pool5"
  top: "drop5"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "drop5"
  top: "relu5"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "relu5"
  top: "conv10"
  convolution_param {
    num_output: 300
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv10"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "drop6"
  top: "relu6"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "relu6"
  top: "conv11"
  convolution_param {
    num_output: 100
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv11"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "pool7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "drop7"
  top: "relu7"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "relu7"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "flatten"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1018 19:33:26.093196  5095 layer_factory.hpp:77] Creating layer data
I1018 19:33:26.093674  5095 net.cpp:100] Creating Layer data
I1018 19:33:26.093688  5095 net.cpp:408] data -> data
I1018 19:33:26.093706  5095 net.cpp:408] data -> label
I1018 19:33:26.094244  5101 db_lmdb.cpp:35] Opened lmdb ../../../../data/mnist/mnist_train_lmdb
I1018 19:33:26.099751  5095 data_layer.cpp:41] output data size: 64,1,28,28
I1018 19:33:26.100306  5095 net.cpp:150] Setting up data
I1018 19:33:26.100317  5095 net.cpp:157] Top shape: 64 1 28 28 (50176)
I1018 19:33:26.100319  5095 net.cpp:157] Top shape: 64 (64)
I1018 19:33:26.100322  5095 net.cpp:165] Memory required for data: 200960
I1018 19:33:26.100330  5095 layer_factory.hpp:77] Creating layer label_data_1_split
I1018 19:33:26.100347  5095 net.cpp:100] Creating Layer label_data_1_split
I1018 19:33:26.100353  5095 net.cpp:434] label_data_1_split <- label
I1018 19:33:26.100363  5095 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1018 19:33:26.100371  5095 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1018 19:33:26.100436  5095 net.cpp:150] Setting up label_data_1_split
I1018 19:33:26.100446  5095 net.cpp:157] Top shape: 64 (64)
I1018 19:33:26.100450  5095 net.cpp:157] Top shape: 64 (64)
I1018 19:33:26.100451  5095 net.cpp:165] Memory required for data: 201472
I1018 19:33:26.100453  5095 layer_factory.hpp:77] Creating layer conv1
I1018 19:33:26.100466  5095 net.cpp:100] Creating Layer conv1
I1018 19:33:26.100469  5095 net.cpp:434] conv1 <- data
I1018 19:33:26.100476  5095 net.cpp:408] conv1 -> conv1
I1018 19:33:26.218296  5095 net.cpp:150] Setting up conv1
I1018 19:33:26.218322  5095 net.cpp:157] Top shape: 64 192 24 24 (7077888)
I1018 19:33:26.218324  5095 net.cpp:165] Memory required for data: 28513024
I1018 19:33:26.218365  5095 layer_factory.hpp:77] Creating layer pool1
I1018 19:33:26.218375  5095 net.cpp:100] Creating Layer pool1
I1018 19:33:26.218379  5095 net.cpp:434] pool1 <- conv1
I1018 19:33:26.218384  5095 net.cpp:408] pool1 -> pool1
I1018 19:33:26.218428  5095 net.cpp:150] Setting up pool1
I1018 19:33:26.218432  5095 net.cpp:157] Top shape: 64 192 12 12 (1769472)
I1018 19:33:26.218435  5095 net.cpp:165] Memory required for data: 35590912
I1018 19:33:26.218436  5095 layer_factory.hpp:77] Creating layer drop1
I1018 19:33:26.218443  5095 net.cpp:100] Creating Layer drop1
I1018 19:33:26.218444  5095 net.cpp:434] drop1 <- pool1
I1018 19:33:26.218447  5095 net.cpp:408] drop1 -> drop1
I1018 19:33:26.218472  5095 net.cpp:150] Setting up drop1
I1018 19:33:26.218475  5095 net.cpp:157] Top shape: 64 192 12 12 (1769472)
I1018 19:33:26.218477  5095 net.cpp:165] Memory required for data: 42668800
I1018 19:33:26.218478  5095 layer_factory.hpp:77] Creating layer relu1
I1018 19:33:26.218482  5095 net.cpp:100] Creating Layer relu1
I1018 19:33:26.218483  5095 net.cpp:434] relu1 <- drop1
I1018 19:33:26.218487  5095 net.cpp:408] relu1 -> relu1
I1018 19:33:26.218603  5095 net.cpp:150] Setting up relu1
I1018 19:33:26.218608  5095 net.cpp:157] Top shape: 64 192 12 12 (1769472)
I1018 19:33:26.218611  5095 net.cpp:165] Memory required for data: 49746688
I1018 19:33:26.218612  5095 layer_factory.hpp:77] Creating layer conv2
I1018 19:33:26.218617  5095 net.cpp:100] Creating Layer conv2
I1018 19:33:26.218619  5095 net.cpp:434] conv2 <- relu1
I1018 19:33:26.218623  5095 net.cpp:408] conv2 -> conv2
I1018 19:33:26.219409  5095 net.cpp:150] Setting up conv2
I1018 19:33:26.219418  5095 net.cpp:157] Top shape: 64 192 12 12 (1769472)
I1018 19:33:26.219419  5095 net.cpp:165] Memory required for data: 56824576
I1018 19:33:26.219424  5095 layer_factory.hpp:77] Creating layer conv3
I1018 19:33:26.219429  5095 net.cpp:100] Creating Layer conv3
I1018 19:33:26.219431  5095 net.cpp:434] conv3 <- conv2
I1018 19:33:26.219435  5095 net.cpp:408] conv3 -> conv3
I1018 19:33:26.221822  5095 net.cpp:150] Setting up conv3
I1018 19:33:26.221832  5095 net.cpp:157] Top shape: 64 240 10 10 (1536000)
I1018 19:33:26.221833  5095 net.cpp:165] Memory required for data: 62968576
I1018 19:33:26.221838  5095 layer_factory.hpp:77] Creating layer pool2
I1018 19:33:26.221843  5095 net.cpp:100] Creating Layer pool2
I1018 19:33:26.221845  5095 net.cpp:434] pool2 <- conv3
I1018 19:33:26.221848  5095 net.cpp:408] pool2 -> pool2
I1018 19:33:26.221871  5095 net.cpp:150] Setting up pool2
I1018 19:33:26.221876  5095 net.cpp:157] Top shape: 64 240 5 5 (384000)
I1018 19:33:26.221878  5095 net.cpp:165] Memory required for data: 64504576
I1018 19:33:26.221879  5095 layer_factory.hpp:77] Creating layer drop2
I1018 19:33:26.221882  5095 net.cpp:100] Creating Layer drop2
I1018 19:33:26.221884  5095 net.cpp:434] drop2 <- pool2
I1018 19:33:26.221886  5095 net.cpp:408] drop2 -> drop2
I1018 19:33:26.221905  5095 net.cpp:150] Setting up drop2
I1018 19:33:26.221909  5095 net.cpp:157] Top shape: 64 240 5 5 (384000)
I1018 19:33:26.221910  5095 net.cpp:165] Memory required for data: 66040576
I1018 19:33:26.221911  5095 layer_factory.hpp:77] Creating layer relu2
I1018 19:33:26.221915  5095 net.cpp:100] Creating Layer relu2
I1018 19:33:26.221915  5095 net.cpp:434] relu2 <- drop2
I1018 19:33:26.221918  5095 net.cpp:408] relu2 -> relu2
I1018 19:33:26.222021  5095 net.cpp:150] Setting up relu2
I1018 19:33:26.222026  5095 net.cpp:157] Top shape: 64 240 5 5 (384000)
I1018 19:33:26.222028  5095 net.cpp:165] Memory required for data: 67576576
I1018 19:33:26.222030  5095 layer_factory.hpp:77] Creating layer conv4
I1018 19:33:26.222034  5095 net.cpp:100] Creating Layer conv4
I1018 19:33:26.222036  5095 net.cpp:434] conv4 <- relu2
I1018 19:33:26.222039  5095 net.cpp:408] conv4 -> conv4
I1018 19:33:26.222846  5095 net.cpp:150] Setting up conv4
I1018 19:33:26.222853  5095 net.cpp:157] Top shape: 64 240 5 5 (384000)
I1018 19:33:26.222854  5095 net.cpp:165] Memory required for data: 69112576
I1018 19:33:26.222858  5095 layer_factory.hpp:77] Creating layer conv5
I1018 19:33:26.222872  5095 net.cpp:100] Creating Layer conv5
I1018 19:33:26.222873  5095 net.cpp:434] conv5 <- conv4
I1018 19:33:26.222877  5095 net.cpp:408] conv5 -> conv5
I1018 19:33:26.224611  5095 net.cpp:150] Setting up conv5
I1018 19:33:26.224620  5095 net.cpp:157] Top shape: 64 260 4 4 (266240)
I1018 19:33:26.224622  5095 net.cpp:165] Memory required for data: 70177536
I1018 19:33:26.224628  5095 layer_factory.hpp:77] Creating layer pool3
I1018 19:33:26.224632  5095 net.cpp:100] Creating Layer pool3
I1018 19:33:26.224634  5095 net.cpp:434] pool3 <- conv5
I1018 19:33:26.224637  5095 net.cpp:408] pool3 -> pool3
I1018 19:33:26.224661  5095 net.cpp:150] Setting up pool3
I1018 19:33:26.224665  5095 net.cpp:157] Top shape: 64 260 2 2 (66560)
I1018 19:33:26.224668  5095 net.cpp:165] Memory required for data: 70443776
I1018 19:33:26.224669  5095 layer_factory.hpp:77] Creating layer drop3
I1018 19:33:26.224673  5095 net.cpp:100] Creating Layer drop3
I1018 19:33:26.224674  5095 net.cpp:434] drop3 <- pool3
I1018 19:33:26.224678  5095 net.cpp:408] drop3 -> drop3
I1018 19:33:26.224699  5095 net.cpp:150] Setting up drop3
I1018 19:33:26.224701  5095 net.cpp:157] Top shape: 64 260 2 2 (66560)
I1018 19:33:26.224704  5095 net.cpp:165] Memory required for data: 70710016
I1018 19:33:26.224705  5095 layer_factory.hpp:77] Creating layer relu3
I1018 19:33:26.224709  5095 net.cpp:100] Creating Layer relu3
I1018 19:33:26.224709  5095 net.cpp:434] relu3 <- drop3
I1018 19:33:26.224714  5095 net.cpp:408] relu3 -> relu3
I1018 19:33:26.224823  5095 net.cpp:150] Setting up relu3
I1018 19:33:26.224828  5095 net.cpp:157] Top shape: 64 260 2 2 (66560)
I1018 19:33:26.224830  5095 net.cpp:165] Memory required for data: 70976256
I1018 19:33:26.224833  5095 layer_factory.hpp:77] Creating layer conv6
I1018 19:33:26.224838  5095 net.cpp:100] Creating Layer conv6
I1018 19:33:26.224840  5095 net.cpp:434] conv6 <- relu3
I1018 19:33:26.224843  5095 net.cpp:408] conv6 -> conv6
I1018 19:33:26.225965  5095 net.cpp:150] Setting up conv6
I1018 19:33:26.225975  5095 net.cpp:157] Top shape: 64 260 2 2 (66560)
I1018 19:33:26.225977  5095 net.cpp:165] Memory required for data: 71242496
I1018 19:33:26.225981  5095 layer_factory.hpp:77] Creating layer conv7
I1018 19:33:26.225986  5095 net.cpp:100] Creating Layer conv7
I1018 19:33:26.225988  5095 net.cpp:434] conv7 <- conv6
I1018 19:33:26.225992  5095 net.cpp:408] conv7 -> conv7
I1018 19:33:26.227917  5095 net.cpp:150] Setting up conv7
I1018 19:33:26.227927  5095 net.cpp:157] Top shape: 64 280 1 1 (17920)
I1018 19:33:26.227929  5095 net.cpp:165] Memory required for data: 71314176
I1018 19:33:26.227933  5095 layer_factory.hpp:77] Creating layer pool4
I1018 19:33:26.227936  5095 net.cpp:100] Creating Layer pool4
I1018 19:33:26.227938  5095 net.cpp:434] pool4 <- conv7
I1018 19:33:26.227942  5095 net.cpp:408] pool4 -> pool4
I1018 19:33:26.227967  5095 net.cpp:150] Setting up pool4
I1018 19:33:26.227970  5095 net.cpp:157] Top shape: 64 280 1 1 (17920)
I1018 19:33:26.227972  5095 net.cpp:165] Memory required for data: 71385856
I1018 19:33:26.227974  5095 layer_factory.hpp:77] Creating layer drop4
I1018 19:33:26.227978  5095 net.cpp:100] Creating Layer drop4
I1018 19:33:26.227979  5095 net.cpp:434] drop4 <- pool4
I1018 19:33:26.227982  5095 net.cpp:408] drop4 -> drop4
I1018 19:33:26.228004  5095 net.cpp:150] Setting up drop4
I1018 19:33:26.228008  5095 net.cpp:157] Top shape: 64 280 1 1 (17920)
I1018 19:33:26.228008  5095 net.cpp:165] Memory required for data: 71457536
I1018 19:33:26.228010  5095 layer_factory.hpp:77] Creating layer relu4
I1018 19:33:26.228013  5095 net.cpp:100] Creating Layer relu4
I1018 19:33:26.228015  5095 net.cpp:434] relu4 <- drop4
I1018 19:33:26.228018  5095 net.cpp:408] relu4 -> relu4
I1018 19:33:26.228207  5095 net.cpp:150] Setting up relu4
I1018 19:33:26.228214  5095 net.cpp:157] Top shape: 64 280 1 1 (17920)
I1018 19:33:26.228216  5095 net.cpp:165] Memory required for data: 71529216
I1018 19:33:26.228219  5095 layer_factory.hpp:77] Creating layer conv8
I1018 19:33:26.228231  5095 net.cpp:100] Creating Layer conv8
I1018 19:33:26.228233  5095 net.cpp:434] conv8 <- relu4
I1018 19:33:26.228237  5095 net.cpp:408] conv8 -> conv8
I1018 19:33:26.229069  5095 net.cpp:150] Setting up conv8
I1018 19:33:26.229077  5095 net.cpp:157] Top shape: 64 280 1 1 (17920)
I1018 19:33:26.229080  5095 net.cpp:165] Memory required for data: 71600896
I1018 19:33:26.229084  5095 layer_factory.hpp:77] Creating layer pool5
I1018 19:33:26.229087  5095 net.cpp:100] Creating Layer pool5
I1018 19:33:26.229089  5095 net.cpp:434] pool5 <- conv8
I1018 19:33:26.229094  5095 net.cpp:408] pool5 -> pool5
I1018 19:33:26.229117  5095 net.cpp:150] Setting up pool5
I1018 19:33:26.229121  5095 net.cpp:157] Top shape: 64 280 1 1 (17920)
I1018 19:33:26.229122  5095 net.cpp:165] Memory required for data: 71672576
I1018 19:33:26.229125  5095 layer_factory.hpp:77] Creating layer drop5
I1018 19:33:26.229128  5095 net.cpp:100] Creating Layer drop5
I1018 19:33:26.229130  5095 net.cpp:434] drop5 <- pool5
I1018 19:33:26.229132  5095 net.cpp:408] drop5 -> drop5
I1018 19:33:26.229154  5095 net.cpp:150] Setting up drop5
I1018 19:33:26.229158  5095 net.cpp:157] Top shape: 64 280 1 1 (17920)
I1018 19:33:26.229159  5095 net.cpp:165] Memory required for data: 71744256
I1018 19:33:26.229161  5095 layer_factory.hpp:77] Creating layer relu5
I1018 19:33:26.229166  5095 net.cpp:100] Creating Layer relu5
I1018 19:33:26.229168  5095 net.cpp:434] relu5 <- drop5
I1018 19:33:26.229172  5095 net.cpp:408] relu5 -> relu5
I1018 19:33:26.229439  5095 net.cpp:150] Setting up relu5
I1018 19:33:26.229446  5095 net.cpp:157] Top shape: 64 280 1 1 (17920)
I1018 19:33:26.229449  5095 net.cpp:165] Memory required for data: 71815936
I1018 19:33:26.229449  5095 layer_factory.hpp:77] Creating layer conv10
I1018 19:33:26.229454  5095 net.cpp:100] Creating Layer conv10
I1018 19:33:26.229457  5095 net.cpp:434] conv10 <- relu5
I1018 19:33:26.229460  5095 net.cpp:408] conv10 -> conv10
I1018 19:33:26.230404  5095 net.cpp:150] Setting up conv10
I1018 19:33:26.230412  5095 net.cpp:157] Top shape: 64 300 1 1 (19200)
I1018 19:33:26.230415  5095 net.cpp:165] Memory required for data: 71892736
I1018 19:33:26.230422  5095 layer_factory.hpp:77] Creating layer pool6
I1018 19:33:26.230427  5095 net.cpp:100] Creating Layer pool6
I1018 19:33:26.230428  5095 net.cpp:434] pool6 <- conv10
I1018 19:33:26.230432  5095 net.cpp:408] pool6 -> pool6
I1018 19:33:26.230456  5095 net.cpp:150] Setting up pool6
I1018 19:33:26.230460  5095 net.cpp:157] Top shape: 64 300 1 1 (19200)
I1018 19:33:26.230463  5095 net.cpp:165] Memory required for data: 71969536
I1018 19:33:26.230464  5095 layer_factory.hpp:77] Creating layer drop6
I1018 19:33:26.230468  5095 net.cpp:100] Creating Layer drop6
I1018 19:33:26.230470  5095 net.cpp:434] drop6 <- pool6
I1018 19:33:26.230473  5095 net.cpp:408] drop6 -> drop6
I1018 19:33:26.230494  5095 net.cpp:150] Setting up drop6
I1018 19:33:26.230497  5095 net.cpp:157] Top shape: 64 300 1 1 (19200)
I1018 19:33:26.230499  5095 net.cpp:165] Memory required for data: 72046336
I1018 19:33:26.230501  5095 layer_factory.hpp:77] Creating layer relu6
I1018 19:33:26.230504  5095 net.cpp:100] Creating Layer relu6
I1018 19:33:26.230506  5095 net.cpp:434] relu6 <- drop6
I1018 19:33:26.230509  5095 net.cpp:408] relu6 -> relu6
I1018 19:33:26.230623  5095 net.cpp:150] Setting up relu6
I1018 19:33:26.230629  5095 net.cpp:157] Top shape: 64 300 1 1 (19200)
I1018 19:33:26.230630  5095 net.cpp:165] Memory required for data: 72123136
I1018 19:33:26.230633  5095 layer_factory.hpp:77] Creating layer conv11
I1018 19:33:26.230636  5095 net.cpp:100] Creating Layer conv11
I1018 19:33:26.230639  5095 net.cpp:434] conv11 <- relu6
I1018 19:33:26.230643  5095 net.cpp:408] conv11 -> conv11
I1018 19:33:26.231631  5095 net.cpp:150] Setting up conv11
I1018 19:33:26.231640  5095 net.cpp:157] Top shape: 64 100 1 1 (6400)
I1018 19:33:26.231643  5095 net.cpp:165] Memory required for data: 72148736
I1018 19:33:26.231647  5095 layer_factory.hpp:77] Creating layer pool7
I1018 19:33:26.231652  5095 net.cpp:100] Creating Layer pool7
I1018 19:33:26.231662  5095 net.cpp:434] pool7 <- conv11
I1018 19:33:26.231665  5095 net.cpp:408] pool7 -> pool7
I1018 19:33:26.231693  5095 net.cpp:150] Setting up pool7
I1018 19:33:26.231698  5095 net.cpp:157] Top shape: 64 100 1 1 (6400)
I1018 19:33:26.231699  5095 net.cpp:165] Memory required for data: 72174336
I1018 19:33:26.231701  5095 layer_factory.hpp:77] Creating layer drop7
I1018 19:33:26.231705  5095 net.cpp:100] Creating Layer drop7
I1018 19:33:26.231708  5095 net.cpp:434] drop7 <- pool7
I1018 19:33:26.231710  5095 net.cpp:408] drop7 -> drop7
I1018 19:33:26.231732  5095 net.cpp:150] Setting up drop7
I1018 19:33:26.231736  5095 net.cpp:157] Top shape: 64 100 1 1 (6400)
I1018 19:33:26.231739  5095 net.cpp:165] Memory required for data: 72199936
I1018 19:33:26.231740  5095 layer_factory.hpp:77] Creating layer relu7
I1018 19:33:26.231747  5095 net.cpp:100] Creating Layer relu7
I1018 19:33:26.231750  5095 net.cpp:434] relu7 <- drop7
I1018 19:33:26.231752  5095 net.cpp:408] relu7 -> relu7
I1018 19:33:26.231945  5095 net.cpp:150] Setting up relu7
I1018 19:33:26.231953  5095 net.cpp:157] Top shape: 64 100 1 1 (6400)
I1018 19:33:26.231955  5095 net.cpp:165] Memory required for data: 72225536
I1018 19:33:26.231956  5095 layer_factory.hpp:77] Creating layer pool
I1018 19:33:26.231961  5095 net.cpp:100] Creating Layer pool
I1018 19:33:26.231963  5095 net.cpp:434] pool <- relu7
I1018 19:33:26.231966  5095 net.cpp:408] pool -> pool
I1018 19:33:26.232089  5095 net.cpp:150] Setting up pool
I1018 19:33:26.232095  5095 net.cpp:157] Top shape: 64 100 1 1 (6400)
I1018 19:33:26.232097  5095 net.cpp:165] Memory required for data: 72251136
I1018 19:33:26.232100  5095 layer_factory.hpp:77] Creating layer flatten
I1018 19:33:26.232102  5095 net.cpp:100] Creating Layer flatten
I1018 19:33:26.232103  5095 net.cpp:434] flatten <- pool
I1018 19:33:26.232106  5095 net.cpp:408] flatten -> flatten
I1018 19:33:26.232122  5095 net.cpp:150] Setting up flatten
I1018 19:33:26.232125  5095 net.cpp:157] Top shape: 64 100 (6400)
I1018 19:33:26.232126  5095 net.cpp:165] Memory required for data: 72276736
I1018 19:33:26.232128  5095 layer_factory.hpp:77] Creating layer score
I1018 19:33:26.232132  5095 net.cpp:100] Creating Layer score
I1018 19:33:26.232136  5095 net.cpp:434] score <- flatten
I1018 19:33:26.232138  5095 net.cpp:408] score -> score
I1018 19:33:26.232233  5095 net.cpp:150] Setting up score
I1018 19:33:26.232236  5095 net.cpp:157] Top shape: 64 10 (640)
I1018 19:33:26.232239  5095 net.cpp:165] Memory required for data: 72279296
I1018 19:33:26.232241  5095 layer_factory.hpp:77] Creating layer score_score_0_split
I1018 19:33:26.232245  5095 net.cpp:100] Creating Layer score_score_0_split
I1018 19:33:26.232247  5095 net.cpp:434] score_score_0_split <- score
I1018 19:33:26.232251  5095 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1018 19:33:26.232255  5095 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1018 19:33:26.232277  5095 net.cpp:150] Setting up score_score_0_split
I1018 19:33:26.232281  5095 net.cpp:157] Top shape: 64 10 (640)
I1018 19:33:26.232283  5095 net.cpp:157] Top shape: 64 10 (640)
I1018 19:33:26.232285  5095 net.cpp:165] Memory required for data: 72284416
I1018 19:33:26.232287  5095 layer_factory.hpp:77] Creating layer accuracy
I1018 19:33:26.232291  5095 net.cpp:100] Creating Layer accuracy
I1018 19:33:26.232295  5095 net.cpp:434] accuracy <- score_score_0_split_0
I1018 19:33:26.232296  5095 net.cpp:434] accuracy <- label_data_1_split_0
I1018 19:33:26.232301  5095 net.cpp:408] accuracy -> accuracy
I1018 19:33:26.232306  5095 net.cpp:150] Setting up accuracy
I1018 19:33:26.232311  5095 net.cpp:157] Top shape: (1)
I1018 19:33:26.232312  5095 net.cpp:165] Memory required for data: 72284420
I1018 19:33:26.232316  5095 layer_factory.hpp:77] Creating layer loss
I1018 19:33:26.232318  5095 net.cpp:100] Creating Layer loss
I1018 19:33:26.232319  5095 net.cpp:434] loss <- score_score_0_split_1
I1018 19:33:26.232322  5095 net.cpp:434] loss <- label_data_1_split_1
I1018 19:33:26.232333  5095 net.cpp:408] loss -> loss
I1018 19:33:26.232341  5095 layer_factory.hpp:77] Creating layer loss
I1018 19:33:26.232591  5095 net.cpp:150] Setting up loss
I1018 19:33:26.232599  5095 net.cpp:157] Top shape: (1)
I1018 19:33:26.232601  5095 net.cpp:160]     with loss weight 1
I1018 19:33:26.232614  5095 net.cpp:165] Memory required for data: 72284424
I1018 19:33:26.232616  5095 net.cpp:226] loss needs backward computation.
I1018 19:33:26.232622  5095 net.cpp:228] accuracy does not need backward computation.
I1018 19:33:26.232625  5095 net.cpp:226] score_score_0_split needs backward computation.
I1018 19:33:26.232627  5095 net.cpp:226] score needs backward computation.
I1018 19:33:26.232630  5095 net.cpp:226] flatten needs backward computation.
I1018 19:33:26.232631  5095 net.cpp:226] pool needs backward computation.
I1018 19:33:26.232633  5095 net.cpp:226] relu7 needs backward computation.
I1018 19:33:26.232635  5095 net.cpp:226] drop7 needs backward computation.
I1018 19:33:26.232636  5095 net.cpp:226] pool7 needs backward computation.
I1018 19:33:26.232638  5095 net.cpp:226] conv11 needs backward computation.
I1018 19:33:26.232640  5095 net.cpp:226] relu6 needs backward computation.
I1018 19:33:26.232642  5095 net.cpp:226] drop6 needs backward computation.
I1018 19:33:26.232645  5095 net.cpp:226] pool6 needs backward computation.
I1018 19:33:26.232646  5095 net.cpp:226] conv10 needs backward computation.
I1018 19:33:26.232648  5095 net.cpp:226] relu5 needs backward computation.
I1018 19:33:26.232650  5095 net.cpp:226] drop5 needs backward computation.
I1018 19:33:26.232652  5095 net.cpp:226] pool5 needs backward computation.
I1018 19:33:26.232655  5095 net.cpp:226] conv8 needs backward computation.
I1018 19:33:26.232657  5095 net.cpp:226] relu4 needs backward computation.
I1018 19:33:26.232658  5095 net.cpp:226] drop4 needs backward computation.
I1018 19:33:26.232661  5095 net.cpp:226] pool4 needs backward computation.
I1018 19:33:26.232662  5095 net.cpp:226] conv7 needs backward computation.
I1018 19:33:26.232666  5095 net.cpp:226] conv6 needs backward computation.
I1018 19:33:26.232666  5095 net.cpp:226] relu3 needs backward computation.
I1018 19:33:26.232668  5095 net.cpp:226] drop3 needs backward computation.
I1018 19:33:26.232671  5095 net.cpp:226] pool3 needs backward computation.
I1018 19:33:26.232672  5095 net.cpp:226] conv5 needs backward computation.
I1018 19:33:26.232674  5095 net.cpp:226] conv4 needs backward computation.
I1018 19:33:26.232676  5095 net.cpp:226] relu2 needs backward computation.
I1018 19:33:26.232678  5095 net.cpp:226] drop2 needs backward computation.
I1018 19:33:26.232681  5095 net.cpp:226] pool2 needs backward computation.
I1018 19:33:26.232682  5095 net.cpp:226] conv3 needs backward computation.
I1018 19:33:26.232683  5095 net.cpp:226] conv2 needs backward computation.
I1018 19:33:26.232686  5095 net.cpp:226] relu1 needs backward computation.
I1018 19:33:26.232688  5095 net.cpp:226] drop1 needs backward computation.
I1018 19:33:26.232691  5095 net.cpp:226] pool1 needs backward computation.
I1018 19:33:26.232692  5095 net.cpp:226] conv1 needs backward computation.
I1018 19:33:26.232694  5095 net.cpp:228] label_data_1_split does not need backward computation.
I1018 19:33:26.232697  5095 net.cpp:228] data does not need backward computation.
I1018 19:33:26.232699  5095 net.cpp:270] This network produces output accuracy
I1018 19:33:26.232702  5095 net.cpp:270] This network produces output loss
I1018 19:33:26.232717  5095 net.cpp:283] Network initialization done.
I1018 19:33:26.232916  5095 solver.cpp:181] Creating test net (#0) specified by test_net file: /home/adam/Honours/Honours-Project/mnist_pooling/max/leakyrelu/poolcnn_leakyrelu_test.prototxt
I1018 19:33:26.233057  5095 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.0039215689
  }
  data_param {
    source: "../../../../data/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 192
    kernel_size: 5
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "drop1"
  top: "relu1"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1"
  top: "conv2"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 240
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv3"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "drop2"
  dropout_param {
    dropout_ratio: 0.1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "drop2"
  top: "relu2"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu2"
  top: "conv4"
  convolution_param {
    num_output: 240
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 260
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "pool3"
  top: "drop3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "drop3"
  top: "relu3"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "relu3"
  top: "conv6"
  convolution_param {
    num_output: 260
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 280
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv7"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "pool4"
  top: "drop4"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "drop4"
  top: "relu4"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "relu4"
  top: "conv8"
  convolution_param {
    num_output: 280
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv8"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "pool5"
  top: "drop5"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "drop5"
  top: "relu5"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "relu5"
  top: "conv10"
  convolution_param {
    num_output: 300
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv10"
  top: "pool6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "drop6"
  top: "relu6"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "relu6"
  top: "conv11"
  convolution_param {
    num_output: 100
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool7"
  type: "Pooling"
  bottom: "conv11"
  top: "pool7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "pool7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "drop7"
  top: "relu7"
  relu_param {
    negative_slope: 0.01
  }
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "relu7"
  top: "pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "flatten"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I1018 19:33:26.233144  5095 layer_factory.hpp:77] Creating layer data
I1018 19:33:26.233222  5095 net.cpp:100] Creating Layer data
I1018 19:33:26.233232  5095 net.cpp:408] data -> data
I1018 19:33:26.233237  5095 net.cpp:408] data -> label
I1018 19:33:26.233803  5103 db_lmdb.cpp:35] Opened lmdb ../../../../data/mnist/mnist_test_lmdb
I1018 19:33:26.233878  5095 data_layer.cpp:41] output data size: 100,1,28,28
I1018 19:33:26.234598  5095 net.cpp:150] Setting up data
I1018 19:33:26.234607  5095 net.cpp:157] Top shape: 100 1 28 28 (78400)
I1018 19:33:26.234611  5095 net.cpp:157] Top shape: 100 (100)
I1018 19:33:26.234611  5095 net.cpp:165] Memory required for data: 314000
I1018 19:33:26.234614  5095 layer_factory.hpp:77] Creating layer label_data_1_split
I1018 19:33:26.234621  5095 net.cpp:100] Creating Layer label_data_1_split
I1018 19:33:26.234623  5095 net.cpp:434] label_data_1_split <- label
I1018 19:33:26.234627  5095 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1018 19:33:26.234632  5095 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1018 19:33:26.234663  5095 net.cpp:150] Setting up label_data_1_split
I1018 19:33:26.234668  5095 net.cpp:157] Top shape: 100 (100)
I1018 19:33:26.234669  5095 net.cpp:157] Top shape: 100 (100)
I1018 19:33:26.234671  5095 net.cpp:165] Memory required for data: 314800
I1018 19:33:26.234673  5095 layer_factory.hpp:77] Creating layer conv1
I1018 19:33:26.234678  5095 net.cpp:100] Creating Layer conv1
I1018 19:33:26.234680  5095 net.cpp:434] conv1 <- data
I1018 19:33:26.234684  5095 net.cpp:408] conv1 -> conv1
I1018 19:33:26.235395  5095 net.cpp:150] Setting up conv1
I1018 19:33:26.235404  5095 net.cpp:157] Top shape: 100 192 24 24 (11059200)
I1018 19:33:26.235406  5095 net.cpp:165] Memory required for data: 44551600
I1018 19:33:26.235416  5095 layer_factory.hpp:77] Creating layer pool1
I1018 19:33:26.235421  5095 net.cpp:100] Creating Layer pool1
I1018 19:33:26.235427  5095 net.cpp:434] pool1 <- conv1
I1018 19:33:26.235430  5095 net.cpp:408] pool1 -> pool1
I1018 19:33:26.235460  5095 net.cpp:150] Setting up pool1
I1018 19:33:26.235465  5095 net.cpp:157] Top shape: 100 192 12 12 (2764800)
I1018 19:33:26.235468  5095 net.cpp:165] Memory required for data: 55610800
I1018 19:33:26.235471  5095 layer_factory.hpp:77] Creating layer drop1
I1018 19:33:26.235476  5095 net.cpp:100] Creating Layer drop1
I1018 19:33:26.235492  5095 net.cpp:434] drop1 <- pool1
I1018 19:33:26.235501  5095 net.cpp:408] drop1 -> drop1
I1018 19:33:26.235525  5095 net.cpp:150] Setting up drop1
I1018 19:33:26.235530  5095 net.cpp:157] Top shape: 100 192 12 12 (2764800)
I1018 19:33:26.235537  5095 net.cpp:165] Memory required for data: 66670000
I1018 19:33:26.235538  5095 layer_factory.hpp:77] Creating layer relu1
I1018 19:33:26.235543  5095 net.cpp:100] Creating Layer relu1
I1018 19:33:26.235545  5095 net.cpp:434] relu1 <- drop1
I1018 19:33:26.235548  5095 net.cpp:408] relu1 -> relu1
I1018 19:33:26.235771  5095 net.cpp:150] Setting up relu1
I1018 19:33:26.235786  5095 net.cpp:157] Top shape: 100 192 12 12 (2764800)
I1018 19:33:26.235790  5095 net.cpp:165] Memory required for data: 77729200
I1018 19:33:26.235792  5095 layer_factory.hpp:77] Creating layer conv2
I1018 19:33:26.235798  5095 net.cpp:100] Creating Layer conv2
I1018 19:33:26.235802  5095 net.cpp:434] conv2 <- relu1
I1018 19:33:26.235805  5095 net.cpp:408] conv2 -> conv2
I1018 19:33:26.236661  5095 net.cpp:150] Setting up conv2
I1018 19:33:26.236670  5095 net.cpp:157] Top shape: 100 192 12 12 (2764800)
I1018 19:33:26.236673  5095 net.cpp:165] Memory required for data: 88788400
I1018 19:33:26.236680  5095 layer_factory.hpp:77] Creating layer conv3
I1018 19:33:26.236686  5095 net.cpp:100] Creating Layer conv3
I1018 19:33:26.236690  5095 net.cpp:434] conv3 <- conv2
I1018 19:33:26.236696  5095 net.cpp:408] conv3 -> conv3
I1018 19:33:26.239171  5095 net.cpp:150] Setting up conv3
I1018 19:33:26.239179  5095 net.cpp:157] Top shape: 100 240 10 10 (2400000)
I1018 19:33:26.239183  5095 net.cpp:165] Memory required for data: 98388400
I1018 19:33:26.239190  5095 layer_factory.hpp:77] Creating layer pool2
I1018 19:33:26.239197  5095 net.cpp:100] Creating Layer pool2
I1018 19:33:26.239198  5095 net.cpp:434] pool2 <- conv3
I1018 19:33:26.239204  5095 net.cpp:408] pool2 -> pool2
I1018 19:33:26.239233  5095 net.cpp:150] Setting up pool2
I1018 19:33:26.239236  5095 net.cpp:157] Top shape: 100 240 5 5 (600000)
I1018 19:33:26.239238  5095 net.cpp:165] Memory required for data: 100788400
I1018 19:33:26.239241  5095 layer_factory.hpp:77] Creating layer drop2
I1018 19:33:26.239246  5095 net.cpp:100] Creating Layer drop2
I1018 19:33:26.239249  5095 net.cpp:434] drop2 <- pool2
I1018 19:33:26.239253  5095 net.cpp:408] drop2 -> drop2
I1018 19:33:26.239276  5095 net.cpp:150] Setting up drop2
I1018 19:33:26.239280  5095 net.cpp:157] Top shape: 100 240 5 5 (600000)
I1018 19:33:26.239282  5095 net.cpp:165] Memory required for data: 103188400
I1018 19:33:26.239284  5095 layer_factory.hpp:77] Creating layer relu2
I1018 19:33:26.239289  5095 net.cpp:100] Creating Layer relu2
I1018 19:33:26.239291  5095 net.cpp:434] relu2 <- drop2
I1018 19:33:26.239295  5095 net.cpp:408] relu2 -> relu2
I1018 19:33:26.239413  5095 net.cpp:150] Setting up relu2
I1018 19:33:26.239418  5095 net.cpp:157] Top shape: 100 240 5 5 (600000)
I1018 19:33:26.239420  5095 net.cpp:165] Memory required for data: 105588400
I1018 19:33:26.239423  5095 layer_factory.hpp:77] Creating layer conv4
I1018 19:33:26.239429  5095 net.cpp:100] Creating Layer conv4
I1018 19:33:26.239433  5095 net.cpp:434] conv4 <- relu2
I1018 19:33:26.239436  5095 net.cpp:408] conv4 -> conv4
I1018 19:33:26.240294  5095 net.cpp:150] Setting up conv4
I1018 19:33:26.240303  5095 net.cpp:157] Top shape: 100 240 5 5 (600000)
I1018 19:33:26.240305  5095 net.cpp:165] Memory required for data: 107988400
I1018 19:33:26.240310  5095 layer_factory.hpp:77] Creating layer conv5
I1018 19:33:26.240316  5095 net.cpp:100] Creating Layer conv5
I1018 19:33:26.240320  5095 net.cpp:434] conv5 <- conv4
I1018 19:33:26.240324  5095 net.cpp:408] conv5 -> conv5
I1018 19:33:26.242151  5095 net.cpp:150] Setting up conv5
I1018 19:33:26.242161  5095 net.cpp:157] Top shape: 100 260 4 4 (416000)
I1018 19:33:26.242162  5095 net.cpp:165] Memory required for data: 109652400
I1018 19:33:26.242169  5095 layer_factory.hpp:77] Creating layer pool3
I1018 19:33:26.242173  5095 net.cpp:100] Creating Layer pool3
I1018 19:33:26.242175  5095 net.cpp:434] pool3 <- conv5
I1018 19:33:26.242178  5095 net.cpp:408] pool3 -> pool3
I1018 19:33:26.242208  5095 net.cpp:150] Setting up pool3
I1018 19:33:26.242211  5095 net.cpp:157] Top shape: 100 260 2 2 (104000)
I1018 19:33:26.242213  5095 net.cpp:165] Memory required for data: 110068400
I1018 19:33:26.242215  5095 layer_factory.hpp:77] Creating layer drop3
I1018 19:33:26.242218  5095 net.cpp:100] Creating Layer drop3
I1018 19:33:26.242220  5095 net.cpp:434] drop3 <- pool3
I1018 19:33:26.242223  5095 net.cpp:408] drop3 -> drop3
I1018 19:33:26.242247  5095 net.cpp:150] Setting up drop3
I1018 19:33:26.242259  5095 net.cpp:157] Top shape: 100 260 2 2 (104000)
I1018 19:33:26.242261  5095 net.cpp:165] Memory required for data: 110484400
I1018 19:33:26.242264  5095 layer_factory.hpp:77] Creating layer relu3
I1018 19:33:26.242266  5095 net.cpp:100] Creating Layer relu3
I1018 19:33:26.242269  5095 net.cpp:434] relu3 <- drop3
I1018 19:33:26.242271  5095 net.cpp:408] relu3 -> relu3
I1018 19:33:26.242390  5095 net.cpp:150] Setting up relu3
I1018 19:33:26.242396  5095 net.cpp:157] Top shape: 100 260 2 2 (104000)
I1018 19:33:26.242398  5095 net.cpp:165] Memory required for data: 110900400
I1018 19:33:26.242399  5095 layer_factory.hpp:77] Creating layer conv6
I1018 19:33:26.242406  5095 net.cpp:100] Creating Layer conv6
I1018 19:33:26.242408  5095 net.cpp:434] conv6 <- relu3
I1018 19:33:26.242411  5095 net.cpp:408] conv6 -> conv6
I1018 19:33:26.243645  5095 net.cpp:150] Setting up conv6
I1018 19:33:26.243654  5095 net.cpp:157] Top shape: 100 260 2 2 (104000)
I1018 19:33:26.243656  5095 net.cpp:165] Memory required for data: 111316400
I1018 19:33:26.243660  5095 layer_factory.hpp:77] Creating layer conv7
I1018 19:33:26.243664  5095 net.cpp:100] Creating Layer conv7
I1018 19:33:26.243666  5095 net.cpp:434] conv7 <- conv6
I1018 19:33:26.243670  5095 net.cpp:408] conv7 -> conv7
I1018 19:33:26.245616  5095 net.cpp:150] Setting up conv7
I1018 19:33:26.245625  5095 net.cpp:157] Top shape: 100 280 1 1 (28000)
I1018 19:33:26.245626  5095 net.cpp:165] Memory required for data: 111428400
I1018 19:33:26.245630  5095 layer_factory.hpp:77] Creating layer pool4
I1018 19:33:26.245635  5095 net.cpp:100] Creating Layer pool4
I1018 19:33:26.245637  5095 net.cpp:434] pool4 <- conv7
I1018 19:33:26.245640  5095 net.cpp:408] pool4 -> pool4
I1018 19:33:26.245666  5095 net.cpp:150] Setting up pool4
I1018 19:33:26.245671  5095 net.cpp:157] Top shape: 100 280 1 1 (28000)
I1018 19:33:26.245673  5095 net.cpp:165] Memory required for data: 111540400
I1018 19:33:26.245674  5095 layer_factory.hpp:77] Creating layer drop4
I1018 19:33:26.245677  5095 net.cpp:100] Creating Layer drop4
I1018 19:33:26.245679  5095 net.cpp:434] drop4 <- pool4
I1018 19:33:26.245683  5095 net.cpp:408] drop4 -> drop4
I1018 19:33:26.245707  5095 net.cpp:150] Setting up drop4
I1018 19:33:26.245710  5095 net.cpp:157] Top shape: 100 280 1 1 (28000)
I1018 19:33:26.245712  5095 net.cpp:165] Memory required for data: 111652400
I1018 19:33:26.245714  5095 layer_factory.hpp:77] Creating layer relu4
I1018 19:33:26.245717  5095 net.cpp:100] Creating Layer relu4
I1018 19:33:26.245718  5095 net.cpp:434] relu4 <- drop4
I1018 19:33:26.245721  5095 net.cpp:408] relu4 -> relu4
I1018 19:33:26.245839  5095 net.cpp:150] Setting up relu4
I1018 19:33:26.245844  5095 net.cpp:157] Top shape: 100 280 1 1 (28000)
I1018 19:33:26.245846  5095 net.cpp:165] Memory required for data: 111764400
I1018 19:33:26.245848  5095 layer_factory.hpp:77] Creating layer conv8
I1018 19:33:26.245853  5095 net.cpp:100] Creating Layer conv8
I1018 19:33:26.245857  5095 net.cpp:434] conv8 <- relu4
I1018 19:33:26.245859  5095 net.cpp:408] conv8 -> conv8
I1018 19:33:26.246796  5095 net.cpp:150] Setting up conv8
I1018 19:33:26.246804  5095 net.cpp:157] Top shape: 100 280 1 1 (28000)
I1018 19:33:26.246806  5095 net.cpp:165] Memory required for data: 111876400
I1018 19:33:26.246809  5095 layer_factory.hpp:77] Creating layer pool5
I1018 19:33:26.246814  5095 net.cpp:100] Creating Layer pool5
I1018 19:33:26.246816  5095 net.cpp:434] pool5 <- conv8
I1018 19:33:26.246819  5095 net.cpp:408] pool5 -> pool5
I1018 19:33:26.246846  5095 net.cpp:150] Setting up pool5
I1018 19:33:26.246850  5095 net.cpp:157] Top shape: 100 280 1 1 (28000)
I1018 19:33:26.246852  5095 net.cpp:165] Memory required for data: 111988400
I1018 19:33:26.246855  5095 layer_factory.hpp:77] Creating layer drop5
I1018 19:33:26.246856  5095 net.cpp:100] Creating Layer drop5
I1018 19:33:26.246858  5095 net.cpp:434] drop5 <- pool5
I1018 19:33:26.246862  5095 net.cpp:408] drop5 -> drop5
I1018 19:33:26.246884  5095 net.cpp:150] Setting up drop5
I1018 19:33:26.246896  5095 net.cpp:157] Top shape: 100 280 1 1 (28000)
I1018 19:33:26.246899  5095 net.cpp:165] Memory required for data: 112100400
I1018 19:33:26.246902  5095 layer_factory.hpp:77] Creating layer relu5
I1018 19:33:26.246906  5095 net.cpp:100] Creating Layer relu5
I1018 19:33:26.246907  5095 net.cpp:434] relu5 <- drop5
I1018 19:33:26.246909  5095 net.cpp:408] relu5 -> relu5
I1018 19:33:26.247110  5095 net.cpp:150] Setting up relu5
I1018 19:33:26.247119  5095 net.cpp:157] Top shape: 100 280 1 1 (28000)
I1018 19:33:26.247120  5095 net.cpp:165] Memory required for data: 112212400
I1018 19:33:26.247123  5095 layer_factory.hpp:77] Creating layer conv10
I1018 19:33:26.247128  5095 net.cpp:100] Creating Layer conv10
I1018 19:33:26.247130  5095 net.cpp:434] conv10 <- relu5
I1018 19:33:26.247133  5095 net.cpp:408] conv10 -> conv10
I1018 19:33:26.249047  5095 net.cpp:150] Setting up conv10
I1018 19:33:26.249056  5095 net.cpp:157] Top shape: 100 300 1 1 (30000)
I1018 19:33:26.249058  5095 net.cpp:165] Memory required for data: 112332400
I1018 19:33:26.249064  5095 layer_factory.hpp:77] Creating layer pool6
I1018 19:33:26.249069  5095 net.cpp:100] Creating Layer pool6
I1018 19:33:26.249070  5095 net.cpp:434] pool6 <- conv10
I1018 19:33:26.249073  5095 net.cpp:408] pool6 -> pool6
I1018 19:33:26.249100  5095 net.cpp:150] Setting up pool6
I1018 19:33:26.249105  5095 net.cpp:157] Top shape: 100 300 1 1 (30000)
I1018 19:33:26.249106  5095 net.cpp:165] Memory required for data: 112452400
I1018 19:33:26.249109  5095 layer_factory.hpp:77] Creating layer drop6
I1018 19:33:26.249111  5095 net.cpp:100] Creating Layer drop6
I1018 19:33:26.249114  5095 net.cpp:434] drop6 <- pool6
I1018 19:33:26.249116  5095 net.cpp:408] drop6 -> drop6
I1018 19:33:26.249140  5095 net.cpp:150] Setting up drop6
I1018 19:33:26.249142  5095 net.cpp:157] Top shape: 100 300 1 1 (30000)
I1018 19:33:26.249145  5095 net.cpp:165] Memory required for data: 112572400
I1018 19:33:26.249146  5095 layer_factory.hpp:77] Creating layer relu6
I1018 19:33:26.249150  5095 net.cpp:100] Creating Layer relu6
I1018 19:33:26.249152  5095 net.cpp:434] relu6 <- drop6
I1018 19:33:26.249156  5095 net.cpp:408] relu6 -> relu6
I1018 19:33:26.249272  5095 net.cpp:150] Setting up relu6
I1018 19:33:26.249277  5095 net.cpp:157] Top shape: 100 300 1 1 (30000)
I1018 19:33:26.249279  5095 net.cpp:165] Memory required for data: 112692400
I1018 19:33:26.249281  5095 layer_factory.hpp:77] Creating layer conv11
I1018 19:33:26.249286  5095 net.cpp:100] Creating Layer conv11
I1018 19:33:26.249289  5095 net.cpp:434] conv11 <- relu6
I1018 19:33:26.249291  5095 net.cpp:408] conv11 -> conv11
I1018 19:33:26.250056  5095 net.cpp:150] Setting up conv11
I1018 19:33:26.250062  5095 net.cpp:157] Top shape: 100 100 1 1 (10000)
I1018 19:33:26.250064  5095 net.cpp:165] Memory required for data: 112732400
I1018 19:33:26.250067  5095 layer_factory.hpp:77] Creating layer pool7
I1018 19:33:26.250072  5095 net.cpp:100] Creating Layer pool7
I1018 19:33:26.250073  5095 net.cpp:434] pool7 <- conv11
I1018 19:33:26.250077  5095 net.cpp:408] pool7 -> pool7
I1018 19:33:26.250107  5095 net.cpp:150] Setting up pool7
I1018 19:33:26.250111  5095 net.cpp:157] Top shape: 100 100 1 1 (10000)
I1018 19:33:26.250113  5095 net.cpp:165] Memory required for data: 112772400
I1018 19:33:26.250115  5095 layer_factory.hpp:77] Creating layer drop7
I1018 19:33:26.250118  5095 net.cpp:100] Creating Layer drop7
I1018 19:33:26.250121  5095 net.cpp:434] drop7 <- pool7
I1018 19:33:26.250124  5095 net.cpp:408] drop7 -> drop7
I1018 19:33:26.250149  5095 net.cpp:150] Setting up drop7
I1018 19:33:26.250151  5095 net.cpp:157] Top shape: 100 100 1 1 (10000)
I1018 19:33:26.250154  5095 net.cpp:165] Memory required for data: 112812400
I1018 19:33:26.250155  5095 layer_factory.hpp:77] Creating layer relu7
I1018 19:33:26.250161  5095 net.cpp:100] Creating Layer relu7
I1018 19:33:26.250164  5095 net.cpp:434] relu7 <- drop7
I1018 19:33:26.250166  5095 net.cpp:408] relu7 -> relu7
I1018 19:33:26.250284  5095 net.cpp:150] Setting up relu7
I1018 19:33:26.250290  5095 net.cpp:157] Top shape: 100 100 1 1 (10000)
I1018 19:33:26.250298  5095 net.cpp:165] Memory required for data: 112852400
I1018 19:33:26.250300  5095 layer_factory.hpp:77] Creating layer pool
I1018 19:33:26.250304  5095 net.cpp:100] Creating Layer pool
I1018 19:33:26.250306  5095 net.cpp:434] pool <- relu7
I1018 19:33:26.250309  5095 net.cpp:408] pool -> pool
I1018 19:33:26.250505  5095 net.cpp:150] Setting up pool
I1018 19:33:26.250512  5095 net.cpp:157] Top shape: 100 100 1 1 (10000)
I1018 19:33:26.250514  5095 net.cpp:165] Memory required for data: 112892400
I1018 19:33:26.250516  5095 layer_factory.hpp:77] Creating layer flatten
I1018 19:33:26.250520  5095 net.cpp:100] Creating Layer flatten
I1018 19:33:26.250522  5095 net.cpp:434] flatten <- pool
I1018 19:33:26.250524  5095 net.cpp:408] flatten -> flatten
I1018 19:33:26.250541  5095 net.cpp:150] Setting up flatten
I1018 19:33:26.250545  5095 net.cpp:157] Top shape: 100 100 (10000)
I1018 19:33:26.250546  5095 net.cpp:165] Memory required for data: 112932400
I1018 19:33:26.250548  5095 layer_factory.hpp:77] Creating layer score
I1018 19:33:26.250551  5095 net.cpp:100] Creating Layer score
I1018 19:33:26.250555  5095 net.cpp:434] score <- flatten
I1018 19:33:26.250558  5095 net.cpp:408] score -> score
I1018 19:33:26.250640  5095 net.cpp:150] Setting up score
I1018 19:33:26.250644  5095 net.cpp:157] Top shape: 100 10 (1000)
I1018 19:33:26.250646  5095 net.cpp:165] Memory required for data: 112936400
I1018 19:33:26.250650  5095 layer_factory.hpp:77] Creating layer score_score_0_split
I1018 19:33:26.250653  5095 net.cpp:100] Creating Layer score_score_0_split
I1018 19:33:26.250655  5095 net.cpp:434] score_score_0_split <- score
I1018 19:33:26.250658  5095 net.cpp:408] score_score_0_split -> score_score_0_split_0
I1018 19:33:26.250663  5095 net.cpp:408] score_score_0_split -> score_score_0_split_1
I1018 19:33:26.250686  5095 net.cpp:150] Setting up score_score_0_split
I1018 19:33:26.250689  5095 net.cpp:157] Top shape: 100 10 (1000)
I1018 19:33:26.250692  5095 net.cpp:157] Top shape: 100 10 (1000)
I1018 19:33:26.250694  5095 net.cpp:165] Memory required for data: 112944400
I1018 19:33:26.250695  5095 layer_factory.hpp:77] Creating layer accuracy
I1018 19:33:26.250699  5095 net.cpp:100] Creating Layer accuracy
I1018 19:33:26.250700  5095 net.cpp:434] accuracy <- score_score_0_split_0
I1018 19:33:26.250704  5095 net.cpp:434] accuracy <- label_data_1_split_0
I1018 19:33:26.250706  5095 net.cpp:408] accuracy -> accuracy
I1018 19:33:26.250711  5095 net.cpp:150] Setting up accuracy
I1018 19:33:26.250715  5095 net.cpp:157] Top shape: (1)
I1018 19:33:26.250715  5095 net.cpp:165] Memory required for data: 112944404
I1018 19:33:26.250717  5095 layer_factory.hpp:77] Creating layer loss
I1018 19:33:26.250720  5095 net.cpp:100] Creating Layer loss
I1018 19:33:26.250721  5095 net.cpp:434] loss <- score_score_0_split_1
I1018 19:33:26.250725  5095 net.cpp:434] loss <- label_data_1_split_1
I1018 19:33:26.250727  5095 net.cpp:408] loss -> loss
I1018 19:33:26.250731  5095 layer_factory.hpp:77] Creating layer loss
I1018 19:33:26.250900  5095 net.cpp:150] Setting up loss
I1018 19:33:26.250905  5095 net.cpp:157] Top shape: (1)
I1018 19:33:26.250906  5095 net.cpp:160]     with loss weight 1
I1018 19:33:26.250915  5095 net.cpp:165] Memory required for data: 112944408
I1018 19:33:26.250917  5095 net.cpp:226] loss needs backward computation.
I1018 19:33:26.250919  5095 net.cpp:228] accuracy does not need backward computation.
I1018 19:33:26.250922  5095 net.cpp:226] score_score_0_split needs backward computation.
I1018 19:33:26.250923  5095 net.cpp:226] score needs backward computation.
I1018 19:33:26.250926  5095 net.cpp:226] flatten needs backward computation.
I1018 19:33:26.250927  5095 net.cpp:226] pool needs backward computation.
I1018 19:33:26.250929  5095 net.cpp:226] relu7 needs backward computation.
I1018 19:33:26.250931  5095 net.cpp:226] drop7 needs backward computation.
I1018 19:33:26.250934  5095 net.cpp:226] pool7 needs backward computation.
I1018 19:33:26.250936  5095 net.cpp:226] conv11 needs backward computation.
I1018 19:33:26.250942  5095 net.cpp:226] relu6 needs backward computation.
I1018 19:33:26.250944  5095 net.cpp:226] drop6 needs backward computation.
I1018 19:33:26.250946  5095 net.cpp:226] pool6 needs backward computation.
I1018 19:33:26.250948  5095 net.cpp:226] conv10 needs backward computation.
I1018 19:33:26.250951  5095 net.cpp:226] relu5 needs backward computation.
I1018 19:33:26.250952  5095 net.cpp:226] drop5 needs backward computation.
I1018 19:33:26.250953  5095 net.cpp:226] pool5 needs backward computation.
I1018 19:33:26.250955  5095 net.cpp:226] conv8 needs backward computation.
I1018 19:33:26.250957  5095 net.cpp:226] relu4 needs backward computation.
I1018 19:33:26.250958  5095 net.cpp:226] drop4 needs backward computation.
I1018 19:33:26.250960  5095 net.cpp:226] pool4 needs backward computation.
I1018 19:33:26.250962  5095 net.cpp:226] conv7 needs backward computation.
I1018 19:33:26.250963  5095 net.cpp:226] conv6 needs backward computation.
I1018 19:33:26.250965  5095 net.cpp:226] relu3 needs backward computation.
I1018 19:33:26.250968  5095 net.cpp:226] drop3 needs backward computation.
I1018 19:33:26.250969  5095 net.cpp:226] pool3 needs backward computation.
I1018 19:33:26.250972  5095 net.cpp:226] conv5 needs backward computation.
I1018 19:33:26.250973  5095 net.cpp:226] conv4 needs backward computation.
I1018 19:33:26.250977  5095 net.cpp:226] relu2 needs backward computation.
I1018 19:33:26.250978  5095 net.cpp:226] drop2 needs backward computation.
I1018 19:33:26.250980  5095 net.cpp:226] pool2 needs backward computation.
I1018 19:33:26.250982  5095 net.cpp:226] conv3 needs backward computation.
I1018 19:33:26.250985  5095 net.cpp:226] conv2 needs backward computation.
I1018 19:33:26.250986  5095 net.cpp:226] relu1 needs backward computation.
I1018 19:33:26.250988  5095 net.cpp:226] drop1 needs backward computation.
I1018 19:33:26.250990  5095 net.cpp:226] pool1 needs backward computation.
I1018 19:33:26.250993  5095 net.cpp:226] conv1 needs backward computation.
I1018 19:33:26.250995  5095 net.cpp:228] label_data_1_split does not need backward computation.
I1018 19:33:26.250998  5095 net.cpp:228] data does not need backward computation.
I1018 19:33:26.250999  5095 net.cpp:270] This network produces output accuracy
I1018 19:33:26.251001  5095 net.cpp:270] This network produces output loss
I1018 19:33:26.251018  5095 net.cpp:283] Network initialization done.
I1018 19:33:26.251072  5095 solver.cpp:60] Solver scaffolding done.
I1018 19:33:26.251595  5095 caffe.cpp:251] Starting Optimization
I1018 19:33:26.251600  5095 solver.cpp:279] Solving 
I1018 19:33:26.251601  5095 solver.cpp:280] Learning Rate Policy: step
I1018 19:33:26.252305  5095 solver.cpp:337] Iteration 0, Testing net (#0)
I1018 19:33:27.330107  5095 solver.cpp:404]     Test net output #0: accuracy = 0.0958
I1018 19:33:27.330129  5095 solver.cpp:404]     Test net output #1: loss = 2.62564 (* 1 = 2.62564 loss)
I1018 19:33:27.346279  5095 solver.cpp:228] Iteration 0, loss = 4.29423
I1018 19:33:27.346292  5095 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1018 19:33:27.346298  5095 solver.cpp:244]     Train net output #1: loss = 4.29423 (* 1 = 4.29423 loss)
I1018 19:33:27.346307  5095 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I1018 19:33:28.548053  5095 solver.cpp:228] Iteration 50, loss = 2.29935
I1018 19:33:28.548074  5095 solver.cpp:244]     Train net output #0: accuracy = 0.109375
I1018 19:33:28.548079  5095 solver.cpp:244]     Train net output #1: loss = 2.29935 (* 1 = 2.29935 loss)
I1018 19:33:28.548084  5095 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
I1018 19:33:29.749856  5095 solver.cpp:228] Iteration 100, loss = 1.93873
I1018 19:33:29.749877  5095 solver.cpp:244]     Train net output #0: accuracy = 0.265625
I1018 19:33:29.749883  5095 solver.cpp:244]     Train net output #1: loss = 1.93873 (* 1 = 1.93873 loss)
I1018 19:33:29.749887  5095 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I1018 19:33:30.927243  5095 solver.cpp:337] Iteration 150, Testing net (#0)
I1018 19:33:32.016644  5095 solver.cpp:404]     Test net output #0: accuracy = 0.6378
I1018 19:33:32.016666  5095 solver.cpp:404]     Test net output #1: loss = 1.38627 (* 1 = 1.38627 loss)
I1018 19:33:32.024703  5095 solver.cpp:228] Iteration 150, loss = 1.61523
I1018 19:33:32.024714  5095 solver.cpp:244]     Train net output #0: accuracy = 0.34375
I1018 19:33:32.024719  5095 solver.cpp:244]     Train net output #1: loss = 1.61523 (* 1 = 1.61523 loss)
I1018 19:33:32.024724  5095 sgd_solver.cpp:106] Iteration 150, lr = 0.0001
I1018 19:33:33.224800  5095 solver.cpp:228] Iteration 200, loss = 1.50227
I1018 19:33:33.224827  5095 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I1018 19:33:33.224835  5095 solver.cpp:244]     Train net output #1: loss = 1.50227 (* 1 = 1.50227 loss)
I1018 19:33:33.224838  5095 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I1018 19:33:34.423979  5095 solver.cpp:228] Iteration 250, loss = 1.29598
I1018 19:33:34.424000  5095 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I1018 19:33:34.424005  5095 solver.cpp:244]     Train net output #1: loss = 1.29598 (* 1 = 1.29598 loss)
I1018 19:33:34.424008  5095 sgd_solver.cpp:106] Iteration 250, lr = 0.0001
I1018 19:33:35.600558  5095 solver.cpp:337] Iteration 300, Testing net (#0)
I1018 19:33:36.690013  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9064
I1018 19:33:36.690035  5095 solver.cpp:404]     Test net output #1: loss = 0.37312 (* 1 = 0.37312 loss)
I1018 19:33:36.698132  5095 solver.cpp:228] Iteration 300, loss = 0.926773
I1018 19:33:36.698143  5095 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I1018 19:33:36.698148  5095 solver.cpp:244]     Train net output #1: loss = 0.926773 (* 1 = 0.926773 loss)
I1018 19:33:36.698153  5095 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I1018 19:33:37.898718  5095 solver.cpp:228] Iteration 350, loss = 0.574623
I1018 19:33:37.898739  5095 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I1018 19:33:37.898746  5095 solver.cpp:244]     Train net output #1: loss = 0.574623 (* 1 = 0.574623 loss)
I1018 19:33:37.898748  5095 sgd_solver.cpp:106] Iteration 350, lr = 0.0001
I1018 19:33:39.100181  5095 solver.cpp:228] Iteration 400, loss = 0.53923
I1018 19:33:39.100205  5095 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I1018 19:33:39.100211  5095 solver.cpp:244]     Train net output #1: loss = 0.53923 (* 1 = 0.53923 loss)
I1018 19:33:39.100214  5095 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I1018 19:33:40.277562  5095 solver.cpp:337] Iteration 450, Testing net (#0)
I1018 19:33:41.366987  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I1018 19:33:41.367009  5095 solver.cpp:404]     Test net output #1: loss = 0.174252 (* 1 = 0.174252 loss)
I1018 19:33:41.375051  5095 solver.cpp:228] Iteration 450, loss = 0.434668
I1018 19:33:41.375062  5095 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I1018 19:33:41.375067  5095 solver.cpp:244]     Train net output #1: loss = 0.434668 (* 1 = 0.434668 loss)
I1018 19:33:41.375072  5095 sgd_solver.cpp:106] Iteration 450, lr = 0.0001
I1018 19:33:42.576719  5095 solver.cpp:228] Iteration 500, loss = 0.488757
I1018 19:33:42.576740  5095 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I1018 19:33:42.576745  5095 solver.cpp:244]     Train net output #1: loss = 0.488757 (* 1 = 0.488757 loss)
I1018 19:33:42.576748  5095 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I1018 19:33:43.776260  5095 solver.cpp:228] Iteration 550, loss = 0.416436
I1018 19:33:43.776283  5095 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I1018 19:33:43.776289  5095 solver.cpp:244]     Train net output #1: loss = 0.416436 (* 1 = 0.416436 loss)
I1018 19:33:43.776293  5095 sgd_solver.cpp:106] Iteration 550, lr = 0.0001
I1018 19:33:44.952589  5095 solver.cpp:337] Iteration 600, Testing net (#0)
I1018 19:33:46.042044  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9711
I1018 19:33:46.042067  5095 solver.cpp:404]     Test net output #1: loss = 0.103734 (* 1 = 0.103734 loss)
I1018 19:33:46.050053  5095 solver.cpp:228] Iteration 600, loss = 0.151846
I1018 19:33:46.050065  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:33:46.050071  5095 solver.cpp:244]     Train net output #1: loss = 0.151846 (* 1 = 0.151846 loss)
I1018 19:33:46.050076  5095 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I1018 19:33:47.250680  5095 solver.cpp:228] Iteration 650, loss = 0.191307
I1018 19:33:47.250700  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:33:47.250706  5095 solver.cpp:244]     Train net output #1: loss = 0.191307 (* 1 = 0.191307 loss)
I1018 19:33:47.250710  5095 sgd_solver.cpp:106] Iteration 650, lr = 0.0001
I1018 19:33:48.452217  5095 solver.cpp:228] Iteration 700, loss = 0.274744
I1018 19:33:48.452240  5095 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I1018 19:33:48.452249  5095 solver.cpp:244]     Train net output #1: loss = 0.274744 (* 1 = 0.274744 loss)
I1018 19:33:48.452251  5095 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I1018 19:33:49.629573  5095 solver.cpp:337] Iteration 750, Testing net (#0)
I1018 19:33:50.718667  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9554
I1018 19:33:50.718689  5095 solver.cpp:404]     Test net output #1: loss = 0.147848 (* 1 = 0.147848 loss)
I1018 19:33:50.726590  5095 solver.cpp:228] Iteration 750, loss = 0.426493
I1018 19:33:50.726601  5095 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I1018 19:33:50.726606  5095 solver.cpp:244]     Train net output #1: loss = 0.426493 (* 1 = 0.426493 loss)
I1018 19:33:50.726611  5095 sgd_solver.cpp:106] Iteration 750, lr = 0.0001
I1018 19:33:51.925550  5095 solver.cpp:228] Iteration 800, loss = 0.504122
I1018 19:33:51.925575  5095 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I1018 19:33:51.925581  5095 solver.cpp:244]     Train net output #1: loss = 0.504122 (* 1 = 0.504122 loss)
I1018 19:33:51.925585  5095 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I1018 19:33:53.125643  5095 solver.cpp:228] Iteration 850, loss = 0.220967
I1018 19:33:53.125663  5095 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I1018 19:33:53.125670  5095 solver.cpp:244]     Train net output #1: loss = 0.220967 (* 1 = 0.220967 loss)
I1018 19:33:53.125674  5095 sgd_solver.cpp:106] Iteration 850, lr = 0.0001
I1018 19:33:54.302706  5095 solver.cpp:337] Iteration 900, Testing net (#0)
I1018 19:33:55.392510  5095 solver.cpp:404]     Test net output #0: accuracy = 0.978
I1018 19:33:55.392534  5095 solver.cpp:404]     Test net output #1: loss = 0.0814892 (* 1 = 0.0814892 loss)
I1018 19:33:55.400501  5095 solver.cpp:228] Iteration 900, loss = 0.233812
I1018 19:33:55.400511  5095 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I1018 19:33:55.400516  5095 solver.cpp:244]     Train net output #1: loss = 0.233812 (* 1 = 0.233812 loss)
I1018 19:33:55.400521  5095 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I1018 19:33:56.601120  5095 solver.cpp:228] Iteration 950, loss = 0.365929
I1018 19:33:56.601248  5095 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I1018 19:33:56.601255  5095 solver.cpp:244]     Train net output #1: loss = 0.365929 (* 1 = 0.365929 loss)
I1018 19:33:56.601258  5095 sgd_solver.cpp:106] Iteration 950, lr = 0.0001
I1018 19:33:57.803084  5095 solver.cpp:228] Iteration 1000, loss = 0.100802
I1018 19:33:57.803107  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:33:57.803113  5095 solver.cpp:244]     Train net output #1: loss = 0.100802 (* 1 = 0.100802 loss)
I1018 19:33:57.803117  5095 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I1018 19:33:58.981752  5095 solver.cpp:337] Iteration 1050, Testing net (#0)
I1018 19:34:00.070497  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9799
I1018 19:34:00.070519  5095 solver.cpp:404]     Test net output #1: loss = 0.0637052 (* 1 = 0.0637052 loss)
I1018 19:34:00.078601  5095 solver.cpp:228] Iteration 1050, loss = 0.193024
I1018 19:34:00.078611  5095 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I1018 19:34:00.078616  5095 solver.cpp:244]     Train net output #1: loss = 0.193024 (* 1 = 0.193024 loss)
I1018 19:34:00.078621  5095 sgd_solver.cpp:106] Iteration 1050, lr = 0.0001
I1018 19:34:01.278853  5095 solver.cpp:228] Iteration 1100, loss = 0.0817199
I1018 19:34:01.278875  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:34:01.278882  5095 solver.cpp:244]     Train net output #1: loss = 0.08172 (* 1 = 0.08172 loss)
I1018 19:34:01.278883  5095 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I1018 19:34:02.481142  5095 solver.cpp:228] Iteration 1150, loss = 0.0547343
I1018 19:34:02.481165  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:02.481173  5095 solver.cpp:244]     Train net output #1: loss = 0.0547345 (* 1 = 0.0547345 loss)
I1018 19:34:02.481175  5095 sgd_solver.cpp:106] Iteration 1150, lr = 0.0001
I1018 19:34:03.657464  5095 solver.cpp:337] Iteration 1200, Testing net (#0)
I1018 19:34:04.747028  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9763
I1018 19:34:04.747051  5095 solver.cpp:404]     Test net output #1: loss = 0.0802577 (* 1 = 0.0802577 loss)
I1018 19:34:04.755170  5095 solver.cpp:228] Iteration 1200, loss = 0.098638
I1018 19:34:04.755180  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:04.755187  5095 solver.cpp:244]     Train net output #1: loss = 0.0986382 (* 1 = 0.0986382 loss)
I1018 19:34:04.755192  5095 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I1018 19:34:05.956415  5095 solver.cpp:228] Iteration 1250, loss = 0.400822
I1018 19:34:05.956436  5095 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I1018 19:34:05.956444  5095 solver.cpp:244]     Train net output #1: loss = 0.400823 (* 1 = 0.400823 loss)
I1018 19:34:05.956446  5095 sgd_solver.cpp:106] Iteration 1250, lr = 0.0001
I1018 19:34:07.157609  5095 solver.cpp:228] Iteration 1300, loss = 0.0470599
I1018 19:34:07.157627  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:07.157634  5095 solver.cpp:244]     Train net output #1: loss = 0.04706 (* 1 = 0.04706 loss)
I1018 19:34:07.157636  5095 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I1018 19:34:08.334720  5095 solver.cpp:337] Iteration 1350, Testing net (#0)
I1018 19:34:09.423774  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9831
I1018 19:34:09.423795  5095 solver.cpp:404]     Test net output #1: loss = 0.0630467 (* 1 = 0.0630467 loss)
I1018 19:34:09.431738  5095 solver.cpp:228] Iteration 1350, loss = 0.115813
I1018 19:34:09.431748  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:09.431753  5095 solver.cpp:244]     Train net output #1: loss = 0.115813 (* 1 = 0.115813 loss)
I1018 19:34:09.431758  5095 sgd_solver.cpp:106] Iteration 1350, lr = 0.0001
I1018 19:34:10.631520  5095 solver.cpp:228] Iteration 1400, loss = 0.0304932
I1018 19:34:10.631542  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:10.631551  5095 solver.cpp:244]     Train net output #1: loss = 0.0304934 (* 1 = 0.0304934 loss)
I1018 19:34:10.631572  5095 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I1018 19:34:11.831472  5095 solver.cpp:228] Iteration 1450, loss = 0.0704076
I1018 19:34:11.831495  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:11.831501  5095 solver.cpp:244]     Train net output #1: loss = 0.0704079 (* 1 = 0.0704079 loss)
I1018 19:34:11.831504  5095 sgd_solver.cpp:106] Iteration 1450, lr = 0.0001
I1018 19:34:13.008155  5095 solver.cpp:337] Iteration 1500, Testing net (#0)
I1018 19:34:14.097642  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9827
I1018 19:34:14.097666  5095 solver.cpp:404]     Test net output #1: loss = 0.0657188 (* 1 = 0.0657188 loss)
I1018 19:34:14.105602  5095 solver.cpp:228] Iteration 1500, loss = 0.112929
I1018 19:34:14.105613  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:14.105618  5095 solver.cpp:244]     Train net output #1: loss = 0.112929 (* 1 = 0.112929 loss)
I1018 19:34:14.105623  5095 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I1018 19:34:15.306922  5095 solver.cpp:228] Iteration 1550, loss = 0.153765
I1018 19:34:15.306944  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:15.306951  5095 solver.cpp:244]     Train net output #1: loss = 0.153765 (* 1 = 0.153765 loss)
I1018 19:34:15.306953  5095 sgd_solver.cpp:106] Iteration 1550, lr = 0.0001
I1018 19:34:16.508551  5095 solver.cpp:228] Iteration 1600, loss = 0.287161
I1018 19:34:16.508574  5095 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I1018 19:34:16.508581  5095 solver.cpp:244]     Train net output #1: loss = 0.287161 (* 1 = 0.287161 loss)
I1018 19:34:16.508584  5095 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I1018 19:34:17.686746  5095 solver.cpp:337] Iteration 1650, Testing net (#0)
I1018 19:34:18.775495  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9844
I1018 19:34:18.775517  5095 solver.cpp:404]     Test net output #1: loss = 0.0589709 (* 1 = 0.0589709 loss)
I1018 19:34:18.783480  5095 solver.cpp:228] Iteration 1650, loss = 0.403004
I1018 19:34:18.783490  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:34:18.783495  5095 solver.cpp:244]     Train net output #1: loss = 0.403004 (* 1 = 0.403004 loss)
I1018 19:34:18.783499  5095 sgd_solver.cpp:106] Iteration 1650, lr = 0.0001
I1018 19:34:19.983445  5095 solver.cpp:228] Iteration 1700, loss = 0.180261
I1018 19:34:19.983467  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:19.983474  5095 solver.cpp:244]     Train net output #1: loss = 0.180261 (* 1 = 0.180261 loss)
I1018 19:34:19.983480  5095 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I1018 19:34:21.183544  5095 solver.cpp:228] Iteration 1750, loss = 0.0404158
I1018 19:34:21.183564  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:21.183569  5095 solver.cpp:244]     Train net output #1: loss = 0.040416 (* 1 = 0.040416 loss)
I1018 19:34:21.183573  5095 sgd_solver.cpp:106] Iteration 1750, lr = 0.0001
I1018 19:34:22.359148  5095 solver.cpp:337] Iteration 1800, Testing net (#0)
I1018 19:34:23.448213  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9841
I1018 19:34:23.448235  5095 solver.cpp:404]     Test net output #1: loss = 0.0620052 (* 1 = 0.0620052 loss)
I1018 19:34:23.456224  5095 solver.cpp:228] Iteration 1800, loss = 0.0214126
I1018 19:34:23.456235  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:23.456240  5095 solver.cpp:244]     Train net output #1: loss = 0.0214128 (* 1 = 0.0214128 loss)
I1018 19:34:23.456244  5095 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I1018 19:34:24.657738  5095 solver.cpp:228] Iteration 1850, loss = 0.0958663
I1018 19:34:24.657759  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:34:24.657765  5095 solver.cpp:244]     Train net output #1: loss = 0.0958665 (* 1 = 0.0958665 loss)
I1018 19:34:24.657768  5095 sgd_solver.cpp:106] Iteration 1850, lr = 0.0001
I1018 19:34:25.858439  5095 solver.cpp:228] Iteration 1900, loss = 0.432312
I1018 19:34:25.858475  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:25.858482  5095 solver.cpp:244]     Train net output #1: loss = 0.432312 (* 1 = 0.432312 loss)
I1018 19:34:25.858485  5095 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I1018 19:34:27.035558  5095 solver.cpp:337] Iteration 1950, Testing net (#0)
I1018 19:34:28.124685  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9845
I1018 19:34:28.124706  5095 solver.cpp:404]     Test net output #1: loss = 0.0538979 (* 1 = 0.0538979 loss)
I1018 19:34:28.132642  5095 solver.cpp:228] Iteration 1950, loss = 0.0452386
I1018 19:34:28.132652  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:28.132658  5095 solver.cpp:244]     Train net output #1: loss = 0.0452388 (* 1 = 0.0452388 loss)
I1018 19:34:28.132663  5095 sgd_solver.cpp:106] Iteration 1950, lr = 0.0001
I1018 19:34:29.332780  5095 solver.cpp:228] Iteration 2000, loss = 0.213894
I1018 19:34:29.332803  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:29.332809  5095 solver.cpp:244]     Train net output #1: loss = 0.213894 (* 1 = 0.213894 loss)
I1018 19:34:29.332813  5095 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I1018 19:34:30.532598  5095 solver.cpp:228] Iteration 2050, loss = 0.0489273
I1018 19:34:30.532624  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:30.532630  5095 solver.cpp:244]     Train net output #1: loss = 0.0489274 (* 1 = 0.0489274 loss)
I1018 19:34:30.532634  5095 sgd_solver.cpp:106] Iteration 2050, lr = 0.0001
I1018 19:34:31.708328  5095 solver.cpp:337] Iteration 2100, Testing net (#0)
I1018 19:34:32.797632  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9869
I1018 19:34:32.797654  5095 solver.cpp:404]     Test net output #1: loss = 0.0471349 (* 1 = 0.0471349 loss)
I1018 19:34:32.805774  5095 solver.cpp:228] Iteration 2100, loss = 0.0196097
I1018 19:34:32.805784  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:34:32.805788  5095 solver.cpp:244]     Train net output #1: loss = 0.0196097 (* 1 = 0.0196097 loss)
I1018 19:34:32.805794  5095 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I1018 19:34:34.007822  5095 solver.cpp:228] Iteration 2150, loss = 0.0420707
I1018 19:34:34.007843  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:34.007850  5095 solver.cpp:244]     Train net output #1: loss = 0.0420708 (* 1 = 0.0420708 loss)
I1018 19:34:34.007853  5095 sgd_solver.cpp:106] Iteration 2150, lr = 0.0001
I1018 19:34:35.208751  5095 solver.cpp:228] Iteration 2200, loss = 0.0766234
I1018 19:34:35.208772  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:35.208778  5095 solver.cpp:244]     Train net output #1: loss = 0.0766234 (* 1 = 0.0766234 loss)
I1018 19:34:35.208782  5095 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I1018 19:34:36.385417  5095 solver.cpp:337] Iteration 2250, Testing net (#0)
I1018 19:34:37.474504  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9841
I1018 19:34:37.474525  5095 solver.cpp:404]     Test net output #1: loss = 0.05912 (* 1 = 0.05912 loss)
I1018 19:34:37.482455  5095 solver.cpp:228] Iteration 2250, loss = 0.260698
I1018 19:34:37.482466  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:34:37.482471  5095 solver.cpp:244]     Train net output #1: loss = 0.260698 (* 1 = 0.260698 loss)
I1018 19:34:37.482475  5095 sgd_solver.cpp:106] Iteration 2250, lr = 0.0001
I1018 19:34:38.682858  5095 solver.cpp:228] Iteration 2300, loss = 0.236396
I1018 19:34:38.682878  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:34:38.682883  5095 solver.cpp:244]     Train net output #1: loss = 0.236396 (* 1 = 0.236396 loss)
I1018 19:34:38.682886  5095 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I1018 19:34:39.882055  5095 solver.cpp:228] Iteration 2350, loss = 0.0282564
I1018 19:34:39.882076  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:39.882082  5095 solver.cpp:244]     Train net output #1: loss = 0.0282564 (* 1 = 0.0282564 loss)
I1018 19:34:39.882086  5095 sgd_solver.cpp:106] Iteration 2350, lr = 0.0001
I1018 19:34:41.059061  5095 solver.cpp:337] Iteration 2400, Testing net (#0)
I1018 19:34:42.148721  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9862
I1018 19:34:42.148742  5095 solver.cpp:404]     Test net output #1: loss = 0.0508246 (* 1 = 0.0508246 loss)
I1018 19:34:42.156884  5095 solver.cpp:228] Iteration 2400, loss = 0.159096
I1018 19:34:42.156895  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:42.156900  5095 solver.cpp:244]     Train net output #1: loss = 0.159096 (* 1 = 0.159096 loss)
I1018 19:34:42.156904  5095 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I1018 19:34:43.358464  5095 solver.cpp:228] Iteration 2450, loss = 0.171792
I1018 19:34:43.358486  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:34:43.358492  5095 solver.cpp:244]     Train net output #1: loss = 0.171792 (* 1 = 0.171792 loss)
I1018 19:34:43.358495  5095 sgd_solver.cpp:106] Iteration 2450, lr = 0.0001
I1018 19:34:44.559592  5095 solver.cpp:228] Iteration 2500, loss = 0.137341
I1018 19:34:44.559615  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:44.559623  5095 solver.cpp:244]     Train net output #1: loss = 0.137341 (* 1 = 0.137341 loss)
I1018 19:34:44.559626  5095 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I1018 19:34:45.735908  5095 solver.cpp:337] Iteration 2550, Testing net (#0)
I1018 19:34:46.825135  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9866
I1018 19:34:46.825156  5095 solver.cpp:404]     Test net output #1: loss = 0.0417723 (* 1 = 0.0417723 loss)
I1018 19:34:46.833118  5095 solver.cpp:228] Iteration 2550, loss = 0.210937
I1018 19:34:46.833129  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:34:46.833134  5095 solver.cpp:244]     Train net output #1: loss = 0.210937 (* 1 = 0.210937 loss)
I1018 19:34:46.833139  5095 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I1018 19:34:48.033596  5095 solver.cpp:228] Iteration 2600, loss = 0.238954
I1018 19:34:48.033615  5095 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I1018 19:34:48.033622  5095 solver.cpp:244]     Train net output #1: loss = 0.238954 (* 1 = 0.238954 loss)
I1018 19:34:48.033625  5095 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I1018 19:34:49.233747  5095 solver.cpp:228] Iteration 2650, loss = 0.0880605
I1018 19:34:49.233770  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:49.233777  5095 solver.cpp:244]     Train net output #1: loss = 0.0880605 (* 1 = 0.0880605 loss)
I1018 19:34:49.233780  5095 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I1018 19:34:50.411006  5095 solver.cpp:337] Iteration 2700, Testing net (#0)
I1018 19:34:51.500340  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9849
I1018 19:34:51.500363  5095 solver.cpp:404]     Test net output #1: loss = 0.0518029 (* 1 = 0.0518029 loss)
I1018 19:34:51.508580  5095 solver.cpp:228] Iteration 2700, loss = 0.387392
I1018 19:34:51.508592  5095 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I1018 19:34:51.508599  5095 solver.cpp:244]     Train net output #1: loss = 0.387392 (* 1 = 0.387392 loss)
I1018 19:34:51.508605  5095 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I1018 19:34:52.708272  5095 solver.cpp:228] Iteration 2750, loss = 0.134436
I1018 19:34:52.708294  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:34:52.708300  5095 solver.cpp:244]     Train net output #1: loss = 0.134436 (* 1 = 0.134436 loss)
I1018 19:34:52.708303  5095 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I1018 19:34:53.909329  5095 solver.cpp:228] Iteration 2800, loss = 0.00168473
I1018 19:34:53.909354  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:34:53.909363  5095 solver.cpp:244]     Train net output #1: loss = 0.00168468 (* 1 = 0.00168468 loss)
I1018 19:34:53.909365  5095 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I1018 19:34:55.086768  5095 solver.cpp:337] Iteration 2850, Testing net (#0)
I1018 19:34:56.175493  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9866
I1018 19:34:56.175515  5095 solver.cpp:404]     Test net output #1: loss = 0.0467114 (* 1 = 0.0467114 loss)
I1018 19:34:56.183624  5095 solver.cpp:228] Iteration 2850, loss = 0.147256
I1018 19:34:56.183635  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:56.183652  5095 solver.cpp:244]     Train net output #1: loss = 0.147256 (* 1 = 0.147256 loss)
I1018 19:34:56.183657  5095 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I1018 19:34:57.386085  5095 solver.cpp:228] Iteration 2900, loss = 0.128579
I1018 19:34:57.386173  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:34:57.386181  5095 solver.cpp:244]     Train net output #1: loss = 0.128579 (* 1 = 0.128579 loss)
I1018 19:34:57.386184  5095 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I1018 19:34:58.587034  5095 solver.cpp:228] Iteration 2950, loss = 0.0848953
I1018 19:34:58.587059  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:34:58.587066  5095 solver.cpp:244]     Train net output #1: loss = 0.0848952 (* 1 = 0.0848952 loss)
I1018 19:34:58.587069  5095 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I1018 19:34:59.763586  5095 solver.cpp:337] Iteration 3000, Testing net (#0)
I1018 19:35:00.853025  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9855
I1018 19:35:00.853047  5095 solver.cpp:404]     Test net output #1: loss = 0.0450673 (* 1 = 0.0450673 loss)
I1018 19:35:00.861107  5095 solver.cpp:228] Iteration 3000, loss = 0.00352487
I1018 19:35:00.861117  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:35:00.861122  5095 solver.cpp:244]     Train net output #1: loss = 0.0035248 (* 1 = 0.0035248 loss)
I1018 19:35:00.861127  5095 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I1018 19:35:02.062387  5095 solver.cpp:228] Iteration 3050, loss = 0.0578085
I1018 19:35:02.062409  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:02.062415  5095 solver.cpp:244]     Train net output #1: loss = 0.0578085 (* 1 = 0.0578085 loss)
I1018 19:35:02.062418  5095 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I1018 19:35:03.262812  5095 solver.cpp:228] Iteration 3100, loss = 0.0444579
I1018 19:35:03.262833  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:03.262840  5095 solver.cpp:244]     Train net output #1: loss = 0.0444579 (* 1 = 0.0444579 loss)
I1018 19:35:03.262842  5095 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I1018 19:35:04.440192  5095 solver.cpp:337] Iteration 3150, Testing net (#0)
I1018 19:35:05.528501  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9881
I1018 19:35:05.528522  5095 solver.cpp:404]     Test net output #1: loss = 0.0369685 (* 1 = 0.0369685 loss)
I1018 19:35:05.536576  5095 solver.cpp:228] Iteration 3150, loss = 0.0331431
I1018 19:35:05.536586  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:05.536592  5095 solver.cpp:244]     Train net output #1: loss = 0.0331431 (* 1 = 0.0331431 loss)
I1018 19:35:05.536595  5095 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I1018 19:35:06.737668  5095 solver.cpp:228] Iteration 3200, loss = 0.0487906
I1018 19:35:06.737687  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:06.737694  5095 solver.cpp:244]     Train net output #1: loss = 0.0487906 (* 1 = 0.0487906 loss)
I1018 19:35:06.737696  5095 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I1018 19:35:07.937636  5095 solver.cpp:228] Iteration 3250, loss = 0.260625
I1018 19:35:07.937659  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:07.937664  5095 solver.cpp:244]     Train net output #1: loss = 0.260625 (* 1 = 0.260625 loss)
I1018 19:35:07.937667  5095 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I1018 19:35:09.114076  5095 solver.cpp:337] Iteration 3300, Testing net (#0)
I1018 19:35:10.203271  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9895
I1018 19:35:10.203294  5095 solver.cpp:404]     Test net output #1: loss = 0.0334825 (* 1 = 0.0334825 loss)
I1018 19:35:10.211377  5095 solver.cpp:228] Iteration 3300, loss = 0.0539552
I1018 19:35:10.211388  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:10.211393  5095 solver.cpp:244]     Train net output #1: loss = 0.0539551 (* 1 = 0.0539551 loss)
I1018 19:35:10.211397  5095 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I1018 19:35:11.412973  5095 solver.cpp:228] Iteration 3350, loss = 0.187333
I1018 19:35:11.412995  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:35:11.413002  5095 solver.cpp:244]     Train net output #1: loss = 0.187333 (* 1 = 0.187333 loss)
I1018 19:35:11.413022  5095 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I1018 19:35:12.613281  5095 solver.cpp:228] Iteration 3400, loss = 0.0161802
I1018 19:35:12.613306  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:35:12.613314  5095 solver.cpp:244]     Train net output #1: loss = 0.0161802 (* 1 = 0.0161802 loss)
I1018 19:35:12.613318  5095 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I1018 19:35:13.790343  5095 solver.cpp:337] Iteration 3450, Testing net (#0)
I1018 19:35:14.878989  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9865
I1018 19:35:14.879011  5095 solver.cpp:404]     Test net output #1: loss = 0.0407175 (* 1 = 0.0407175 loss)
I1018 19:35:14.886970  5095 solver.cpp:228] Iteration 3450, loss = 0.101502
I1018 19:35:14.886979  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:14.886986  5095 solver.cpp:244]     Train net output #1: loss = 0.101502 (* 1 = 0.101502 loss)
I1018 19:35:14.886991  5095 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I1018 19:35:16.088018  5095 solver.cpp:228] Iteration 3500, loss = 0.0571471
I1018 19:35:16.088040  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:16.088047  5095 solver.cpp:244]     Train net output #1: loss = 0.0571471 (* 1 = 0.0571471 loss)
I1018 19:35:16.088049  5095 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I1018 19:35:17.288357  5095 solver.cpp:228] Iteration 3550, loss = 0.167725
I1018 19:35:17.288377  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:35:17.288383  5095 solver.cpp:244]     Train net output #1: loss = 0.167725 (* 1 = 0.167725 loss)
I1018 19:35:17.288388  5095 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I1018 19:35:18.465497  5095 solver.cpp:337] Iteration 3600, Testing net (#0)
I1018 19:35:19.554352  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9868
I1018 19:35:19.554373  5095 solver.cpp:404]     Test net output #1: loss = 0.0415004 (* 1 = 0.0415004 loss)
I1018 19:35:19.562476  5095 solver.cpp:228] Iteration 3600, loss = 0.168525
I1018 19:35:19.562486  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:35:19.562491  5095 solver.cpp:244]     Train net output #1: loss = 0.168525 (* 1 = 0.168525 loss)
I1018 19:35:19.562496  5095 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I1018 19:35:20.762369  5095 solver.cpp:228] Iteration 3650, loss = 0.134583
I1018 19:35:20.762390  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:20.762398  5095 solver.cpp:244]     Train net output #1: loss = 0.134583 (* 1 = 0.134583 loss)
I1018 19:35:20.762399  5095 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I1018 19:35:21.963955  5095 solver.cpp:228] Iteration 3700, loss = 0.127235
I1018 19:35:21.963978  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:35:21.963984  5095 solver.cpp:244]     Train net output #1: loss = 0.127235 (* 1 = 0.127235 loss)
I1018 19:35:21.963989  5095 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I1018 19:35:23.139812  5095 solver.cpp:337] Iteration 3750, Testing net (#0)
I1018 19:35:24.229266  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9846
I1018 19:35:24.229290  5095 solver.cpp:404]     Test net output #1: loss = 0.0504803 (* 1 = 0.0504803 loss)
I1018 19:35:24.237218  5095 solver.cpp:228] Iteration 3750, loss = 0.032129
I1018 19:35:24.237229  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:24.237234  5095 solver.cpp:244]     Train net output #1: loss = 0.0321291 (* 1 = 0.0321291 loss)
I1018 19:35:24.237239  5095 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I1018 19:35:25.438163  5095 solver.cpp:228] Iteration 3800, loss = 0.0315064
I1018 19:35:25.438184  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:25.438190  5095 solver.cpp:244]     Train net output #1: loss = 0.0315064 (* 1 = 0.0315064 loss)
I1018 19:35:25.438194  5095 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I1018 19:35:26.639102  5095 solver.cpp:228] Iteration 3850, loss = 0.0632424
I1018 19:35:26.639143  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:26.639152  5095 solver.cpp:244]     Train net output #1: loss = 0.0632425 (* 1 = 0.0632425 loss)
I1018 19:35:26.639154  5095 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I1018 19:35:27.816272  5095 solver.cpp:337] Iteration 3900, Testing net (#0)
I1018 19:35:28.905659  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9859
I1018 19:35:28.905681  5095 solver.cpp:404]     Test net output #1: loss = 0.0427885 (* 1 = 0.0427885 loss)
I1018 19:35:28.913825  5095 solver.cpp:228] Iteration 3900, loss = 0.0355208
I1018 19:35:28.913836  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:28.913841  5095 solver.cpp:244]     Train net output #1: loss = 0.0355209 (* 1 = 0.0355209 loss)
I1018 19:35:28.913846  5095 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I1018 19:35:30.113967  5095 solver.cpp:228] Iteration 3950, loss = 0.0562243
I1018 19:35:30.113991  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:30.113997  5095 solver.cpp:244]     Train net output #1: loss = 0.0562244 (* 1 = 0.0562244 loss)
I1018 19:35:30.114001  5095 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I1018 19:35:31.314002  5095 solver.cpp:228] Iteration 4000, loss = 0.0519492
I1018 19:35:31.314021  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:31.314028  5095 solver.cpp:244]     Train net output #1: loss = 0.0519493 (* 1 = 0.0519493 loss)
I1018 19:35:31.314031  5095 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I1018 19:35:32.492307  5095 solver.cpp:337] Iteration 4050, Testing net (#0)
I1018 19:35:33.580991  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9893
I1018 19:35:33.581013  5095 solver.cpp:404]     Test net output #1: loss = 0.0367084 (* 1 = 0.0367084 loss)
I1018 19:35:33.589078  5095 solver.cpp:228] Iteration 4050, loss = 0.117508
I1018 19:35:33.589089  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:33.589094  5095 solver.cpp:244]     Train net output #1: loss = 0.117508 (* 1 = 0.117508 loss)
I1018 19:35:33.589099  5095 sgd_solver.cpp:106] Iteration 4050, lr = 0.0001
I1018 19:35:34.790788  5095 solver.cpp:228] Iteration 4100, loss = 0.0442976
I1018 19:35:34.790808  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:34.790814  5095 solver.cpp:244]     Train net output #1: loss = 0.0442977 (* 1 = 0.0442977 loss)
I1018 19:35:34.790817  5095 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I1018 19:35:35.991977  5095 solver.cpp:228] Iteration 4150, loss = 0.00513028
I1018 19:35:35.991999  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:35:35.992005  5095 solver.cpp:244]     Train net output #1: loss = 0.00513038 (* 1 = 0.00513038 loss)
I1018 19:35:35.992008  5095 sgd_solver.cpp:106] Iteration 4150, lr = 0.0001
I1018 19:35:37.170305  5095 solver.cpp:337] Iteration 4200, Testing net (#0)
I1018 19:35:38.259668  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9844
I1018 19:35:38.259691  5095 solver.cpp:404]     Test net output #1: loss = 0.0534519 (* 1 = 0.0534519 loss)
I1018 19:35:38.267611  5095 solver.cpp:228] Iteration 4200, loss = 0.126571
I1018 19:35:38.267621  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:38.267627  5095 solver.cpp:244]     Train net output #1: loss = 0.126571 (* 1 = 0.126571 loss)
I1018 19:35:38.267630  5095 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I1018 19:35:39.468220  5095 solver.cpp:228] Iteration 4250, loss = 0.00229198
I1018 19:35:39.468240  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:35:39.468247  5095 solver.cpp:244]     Train net output #1: loss = 0.00229208 (* 1 = 0.00229208 loss)
I1018 19:35:39.468250  5095 sgd_solver.cpp:106] Iteration 4250, lr = 0.0001
I1018 19:35:40.667989  5095 solver.cpp:228] Iteration 4300, loss = 0.0893567
I1018 19:35:40.668011  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:40.668017  5095 solver.cpp:244]     Train net output #1: loss = 0.0893568 (* 1 = 0.0893568 loss)
I1018 19:35:40.668020  5095 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I1018 19:35:41.846191  5095 solver.cpp:337] Iteration 4350, Testing net (#0)
I1018 19:35:42.935228  5095 solver.cpp:404]     Test net output #0: accuracy = 0.987
I1018 19:35:42.935250  5095 solver.cpp:404]     Test net output #1: loss = 0.0386958 (* 1 = 0.0386958 loss)
I1018 19:35:42.943373  5095 solver.cpp:228] Iteration 4350, loss = 0.0276666
I1018 19:35:42.943384  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:35:42.943389  5095 solver.cpp:244]     Train net output #1: loss = 0.0276667 (* 1 = 0.0276667 loss)
I1018 19:35:42.943393  5095 sgd_solver.cpp:106] Iteration 4350, lr = 0.0001
I1018 19:35:44.145072  5095 solver.cpp:228] Iteration 4400, loss = 0.0211551
I1018 19:35:44.145099  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:35:44.145105  5095 solver.cpp:244]     Train net output #1: loss = 0.0211552 (* 1 = 0.0211552 loss)
I1018 19:35:44.145109  5095 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I1018 19:35:45.345708  5095 solver.cpp:228] Iteration 4450, loss = 0.04158
I1018 19:35:45.345731  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:45.345739  5095 solver.cpp:244]     Train net output #1: loss = 0.04158 (* 1 = 0.04158 loss)
I1018 19:35:45.345743  5095 sgd_solver.cpp:106] Iteration 4450, lr = 0.0001
I1018 19:35:46.523241  5095 solver.cpp:337] Iteration 4500, Testing net (#0)
I1018 19:35:47.612221  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9872
I1018 19:35:47.612246  5095 solver.cpp:404]     Test net output #1: loss = 0.037429 (* 1 = 0.037429 loss)
I1018 19:35:47.620208  5095 solver.cpp:228] Iteration 4500, loss = 0.0599809
I1018 19:35:47.620218  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:35:47.620223  5095 solver.cpp:244]     Train net output #1: loss = 0.0599809 (* 1 = 0.0599809 loss)
I1018 19:35:47.620228  5095 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I1018 19:35:48.821069  5095 solver.cpp:228] Iteration 4550, loss = 0.0577193
I1018 19:35:48.821091  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:48.821097  5095 solver.cpp:244]     Train net output #1: loss = 0.0577194 (* 1 = 0.0577194 loss)
I1018 19:35:48.821101  5095 sgd_solver.cpp:106] Iteration 4550, lr = 0.0001
I1018 19:35:50.023006  5095 solver.cpp:228] Iteration 4600, loss = 0.0140847
I1018 19:35:50.023027  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:35:50.023033  5095 solver.cpp:244]     Train net output #1: loss = 0.0140848 (* 1 = 0.0140848 loss)
I1018 19:35:50.023036  5095 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I1018 19:35:51.199537  5095 solver.cpp:337] Iteration 4650, Testing net (#0)
I1018 19:35:52.288089  5095 solver.cpp:404]     Test net output #0: accuracy = 0.983
I1018 19:35:52.288111  5095 solver.cpp:404]     Test net output #1: loss = 0.0612991 (* 1 = 0.0612991 loss)
I1018 19:35:52.296176  5095 solver.cpp:228] Iteration 4650, loss = 0.0991984
I1018 19:35:52.296186  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:35:52.296191  5095 solver.cpp:244]     Train net output #1: loss = 0.0991985 (* 1 = 0.0991985 loss)
I1018 19:35:52.296195  5095 sgd_solver.cpp:106] Iteration 4650, lr = 0.0001
I1018 19:35:53.497151  5095 solver.cpp:228] Iteration 4700, loss = 0.0818111
I1018 19:35:53.497172  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:53.497179  5095 solver.cpp:244]     Train net output #1: loss = 0.0818112 (* 1 = 0.0818112 loss)
I1018 19:35:53.497181  5095 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I1018 19:35:54.696652  5095 solver.cpp:228] Iteration 4750, loss = 0.0726827
I1018 19:35:54.696674  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:54.696679  5095 solver.cpp:244]     Train net output #1: loss = 0.0726828 (* 1 = 0.0726828 loss)
I1018 19:35:54.696682  5095 sgd_solver.cpp:106] Iteration 4750, lr = 0.0001
I1018 19:35:55.872741  5095 solver.cpp:337] Iteration 4800, Testing net (#0)
I1018 19:35:56.961756  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9877
I1018 19:35:56.961777  5095 solver.cpp:404]     Test net output #1: loss = 0.0372313 (* 1 = 0.0372313 loss)
I1018 19:35:56.969828  5095 solver.cpp:228] Iteration 4800, loss = 0.0871194
I1018 19:35:56.969840  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:56.969856  5095 solver.cpp:244]     Train net output #1: loss = 0.0871195 (* 1 = 0.0871195 loss)
I1018 19:35:56.969861  5095 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I1018 19:35:58.170807  5095 solver.cpp:228] Iteration 4850, loss = 0.00166225
I1018 19:35:58.170861  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:35:58.170871  5095 solver.cpp:244]     Train net output #1: loss = 0.00166241 (* 1 = 0.00166241 loss)
I1018 19:35:58.170873  5095 sgd_solver.cpp:106] Iteration 4850, lr = 0.0001
I1018 19:35:59.371975  5095 solver.cpp:228] Iteration 4900, loss = 0.0294531
I1018 19:35:59.371999  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:35:59.372005  5095 solver.cpp:244]     Train net output #1: loss = 0.0294532 (* 1 = 0.0294532 loss)
I1018 19:35:59.372009  5095 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I1018 19:36:00.548705  5095 solver.cpp:337] Iteration 4950, Testing net (#0)
I1018 19:36:01.637397  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9874
I1018 19:36:01.637418  5095 solver.cpp:404]     Test net output #1: loss = 0.0405408 (* 1 = 0.0405408 loss)
I1018 19:36:01.645328  5095 solver.cpp:228] Iteration 4950, loss = 0.00307069
I1018 19:36:01.645339  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:01.645344  5095 solver.cpp:244]     Train net output #1: loss = 0.0030708 (* 1 = 0.0030708 loss)
I1018 19:36:01.645347  5095 sgd_solver.cpp:106] Iteration 4950, lr = 0.0001
I1018 19:36:02.822819  5095 solver.cpp:454] Snapshotting to binary proto file cifar-10_leakyrelu_RMSProp_iter_5000.caffemodel
I1018 19:36:02.850896  5095 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_leakyrelu_RMSProp_iter_5000.solverstate
I1018 19:36:02.863929  5095 solver.cpp:228] Iteration 5000, loss = 0.28319
I1018 19:36:02.863950  5095 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I1018 19:36:02.863956  5095 solver.cpp:244]     Train net output #1: loss = 0.28319 (* 1 = 0.28319 loss)
I1018 19:36:02.863961  5095 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I1018 19:36:04.063794  5095 solver.cpp:228] Iteration 5050, loss = 0.010028
I1018 19:36:04.063817  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:04.063825  5095 solver.cpp:244]     Train net output #1: loss = 0.0100281 (* 1 = 0.0100281 loss)
I1018 19:36:04.063828  5095 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I1018 19:36:05.240528  5095 solver.cpp:337] Iteration 5100, Testing net (#0)
I1018 19:36:06.329826  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9895
I1018 19:36:06.329849  5095 solver.cpp:404]     Test net output #1: loss = 0.0290848 (* 1 = 0.0290848 loss)
I1018 19:36:06.337800  5095 solver.cpp:228] Iteration 5100, loss = 0.0691197
I1018 19:36:06.337811  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:06.337816  5095 solver.cpp:244]     Train net output #1: loss = 0.0691199 (* 1 = 0.0691199 loss)
I1018 19:36:06.337821  5095 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I1018 19:36:07.540634  5095 solver.cpp:228] Iteration 5150, loss = 0.0032974
I1018 19:36:07.540654  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:07.540659  5095 solver.cpp:244]     Train net output #1: loss = 0.00329756 (* 1 = 0.00329756 loss)
I1018 19:36:07.540663  5095 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I1018 19:36:08.743345  5095 solver.cpp:228] Iteration 5200, loss = 0.271653
I1018 19:36:08.743366  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:36:08.743371  5095 solver.cpp:244]     Train net output #1: loss = 0.271653 (* 1 = 0.271653 loss)
I1018 19:36:08.743374  5095 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I1018 19:36:09.921061  5095 solver.cpp:337] Iteration 5250, Testing net (#0)
I1018 19:36:11.009594  5095 solver.cpp:404]     Test net output #0: accuracy = 0.99
I1018 19:36:11.009614  5095 solver.cpp:404]     Test net output #1: loss = 0.0287263 (* 1 = 0.0287263 loss)
I1018 19:36:11.017568  5095 solver.cpp:228] Iteration 5250, loss = 0.0136583
I1018 19:36:11.017580  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:11.017585  5095 solver.cpp:244]     Train net output #1: loss = 0.0136584 (* 1 = 0.0136584 loss)
I1018 19:36:11.017588  5095 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I1018 19:36:12.218298  5095 solver.cpp:228] Iteration 5300, loss = 0.0143989
I1018 19:36:12.218317  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:12.218323  5095 solver.cpp:244]     Train net output #1: loss = 0.014399 (* 1 = 0.014399 loss)
I1018 19:36:12.218327  5095 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I1018 19:36:13.418659  5095 solver.cpp:228] Iteration 5350, loss = 0.0568885
I1018 19:36:13.418683  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:36:13.418689  5095 solver.cpp:244]     Train net output #1: loss = 0.0568886 (* 1 = 0.0568886 loss)
I1018 19:36:13.418694  5095 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I1018 19:36:14.596468  5095 solver.cpp:337] Iteration 5400, Testing net (#0)
I1018 19:36:15.685011  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9897
I1018 19:36:15.685034  5095 solver.cpp:404]     Test net output #1: loss = 0.0285821 (* 1 = 0.0285821 loss)
I1018 19:36:15.693150  5095 solver.cpp:228] Iteration 5400, loss = 0.113642
I1018 19:36:15.693162  5095 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I1018 19:36:15.693167  5095 solver.cpp:244]     Train net output #1: loss = 0.113642 (* 1 = 0.113642 loss)
I1018 19:36:15.693171  5095 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I1018 19:36:16.895050  5095 solver.cpp:228] Iteration 5450, loss = 0.0315365
I1018 19:36:16.895068  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:16.895074  5095 solver.cpp:244]     Train net output #1: loss = 0.0315366 (* 1 = 0.0315366 loss)
I1018 19:36:16.895077  5095 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I1018 19:36:18.097703  5095 solver.cpp:228] Iteration 5500, loss = 0.0183281
I1018 19:36:18.097728  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:18.097734  5095 solver.cpp:244]     Train net output #1: loss = 0.0183281 (* 1 = 0.0183281 loss)
I1018 19:36:18.097738  5095 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I1018 19:36:19.276126  5095 solver.cpp:337] Iteration 5550, Testing net (#0)
I1018 19:36:20.365883  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9901
I1018 19:36:20.365906  5095 solver.cpp:404]     Test net output #1: loss = 0.0283581 (* 1 = 0.0283581 loss)
I1018 19:36:20.373881  5095 solver.cpp:228] Iteration 5550, loss = 0.00407207
I1018 19:36:20.373893  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:20.373898  5095 solver.cpp:244]     Train net output #1: loss = 0.00407208 (* 1 = 0.00407208 loss)
I1018 19:36:20.373903  5095 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I1018 19:36:21.573128  5095 solver.cpp:228] Iteration 5600, loss = 0.00454477
I1018 19:36:21.573149  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:21.573156  5095 solver.cpp:244]     Train net output #1: loss = 0.00454476 (* 1 = 0.00454476 loss)
I1018 19:36:21.573158  5095 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I1018 19:36:22.772960  5095 solver.cpp:228] Iteration 5650, loss = 0.14508
I1018 19:36:22.772981  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:36:22.772987  5095 solver.cpp:244]     Train net output #1: loss = 0.14508 (* 1 = 0.14508 loss)
I1018 19:36:22.772990  5095 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I1018 19:36:23.948850  5095 solver.cpp:337] Iteration 5700, Testing net (#0)
I1018 19:36:25.038014  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9897
I1018 19:36:25.038036  5095 solver.cpp:404]     Test net output #1: loss = 0.0290779 (* 1 = 0.0290779 loss)
I1018 19:36:25.046121  5095 solver.cpp:228] Iteration 5700, loss = 0.00272908
I1018 19:36:25.046130  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:25.046135  5095 solver.cpp:244]     Train net output #1: loss = 0.002729 (* 1 = 0.002729 loss)
I1018 19:36:25.046139  5095 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I1018 19:36:26.247876  5095 solver.cpp:228] Iteration 5750, loss = 0.0250412
I1018 19:36:26.247898  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:26.247927  5095 solver.cpp:244]     Train net output #1: loss = 0.0250412 (* 1 = 0.0250412 loss)
I1018 19:36:26.247931  5095 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I1018 19:36:27.450508  5095 solver.cpp:228] Iteration 5800, loss = 0.0772628
I1018 19:36:27.450527  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:27.450533  5095 solver.cpp:244]     Train net output #1: loss = 0.0772627 (* 1 = 0.0772627 loss)
I1018 19:36:27.450536  5095 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I1018 19:36:28.628407  5095 solver.cpp:337] Iteration 5850, Testing net (#0)
I1018 19:36:29.717346  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9899
I1018 19:36:29.717370  5095 solver.cpp:404]     Test net output #1: loss = 0.0293859 (* 1 = 0.0293859 loss)
I1018 19:36:29.725507  5095 solver.cpp:228] Iteration 5850, loss = 0.00122155
I1018 19:36:29.725518  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:29.725523  5095 solver.cpp:244]     Train net output #1: loss = 0.00122151 (* 1 = 0.00122151 loss)
I1018 19:36:29.725529  5095 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I1018 19:36:30.925395  5095 solver.cpp:228] Iteration 5900, loss = 0.0115011
I1018 19:36:30.925415  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:30.925421  5095 solver.cpp:244]     Train net output #1: loss = 0.011501 (* 1 = 0.011501 loss)
I1018 19:36:30.925424  5095 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I1018 19:36:32.125496  5095 solver.cpp:228] Iteration 5950, loss = 0.00644263
I1018 19:36:32.125515  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:32.125521  5095 solver.cpp:244]     Train net output #1: loss = 0.0064426 (* 1 = 0.0064426 loss)
I1018 19:36:32.125525  5095 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I1018 19:36:33.300348  5095 solver.cpp:337] Iteration 6000, Testing net (#0)
I1018 19:36:34.389835  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9896
I1018 19:36:34.389859  5095 solver.cpp:404]     Test net output #1: loss = 0.0299755 (* 1 = 0.0299755 loss)
I1018 19:36:34.397792  5095 solver.cpp:228] Iteration 6000, loss = 0.0832883
I1018 19:36:34.397802  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:34.397809  5095 solver.cpp:244]     Train net output #1: loss = 0.0832882 (* 1 = 0.0832882 loss)
I1018 19:36:34.397814  5095 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I1018 19:36:35.599627  5095 solver.cpp:228] Iteration 6050, loss = 0.230965
I1018 19:36:35.599648  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:36:35.599654  5095 solver.cpp:244]     Train net output #1: loss = 0.230965 (* 1 = 0.230965 loss)
I1018 19:36:35.599658  5095 sgd_solver.cpp:106] Iteration 6050, lr = 1e-05
I1018 19:36:36.801604  5095 solver.cpp:228] Iteration 6100, loss = 0.0252049
I1018 19:36:36.801625  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:36.801630  5095 solver.cpp:244]     Train net output #1: loss = 0.0252049 (* 1 = 0.0252049 loss)
I1018 19:36:36.801633  5095 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I1018 19:36:37.979504  5095 solver.cpp:337] Iteration 6150, Testing net (#0)
I1018 19:36:39.068542  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:36:39.068564  5095 solver.cpp:404]     Test net output #1: loss = 0.0296043 (* 1 = 0.0296043 loss)
I1018 19:36:39.076566  5095 solver.cpp:228] Iteration 6150, loss = 0.00931797
I1018 19:36:39.076577  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:39.076582  5095 solver.cpp:244]     Train net output #1: loss = 0.00931791 (* 1 = 0.00931791 loss)
I1018 19:36:39.076586  5095 sgd_solver.cpp:106] Iteration 6150, lr = 1e-05
I1018 19:36:40.277926  5095 solver.cpp:228] Iteration 6200, loss = 0.0343257
I1018 19:36:40.277947  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:40.277953  5095 solver.cpp:244]     Train net output #1: loss = 0.0343257 (* 1 = 0.0343257 loss)
I1018 19:36:40.277956  5095 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I1018 19:36:41.477784  5095 solver.cpp:228] Iteration 6250, loss = 0.0506188
I1018 19:36:41.477805  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:41.477813  5095 solver.cpp:244]     Train net output #1: loss = 0.0506188 (* 1 = 0.0506188 loss)
I1018 19:36:41.477814  5095 sgd_solver.cpp:106] Iteration 6250, lr = 1e-05
I1018 19:36:42.653472  5095 solver.cpp:337] Iteration 6300, Testing net (#0)
I1018 19:36:43.742343  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9894
I1018 19:36:43.742367  5095 solver.cpp:404]     Test net output #1: loss = 0.029275 (* 1 = 0.029275 loss)
I1018 19:36:43.750371  5095 solver.cpp:228] Iteration 6300, loss = 0.0727266
I1018 19:36:43.750382  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:36:43.750387  5095 solver.cpp:244]     Train net output #1: loss = 0.0727266 (* 1 = 0.0727266 loss)
I1018 19:36:43.750391  5095 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I1018 19:36:44.952574  5095 solver.cpp:228] Iteration 6350, loss = 0.0861068
I1018 19:36:44.952595  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:36:44.952602  5095 solver.cpp:244]     Train net output #1: loss = 0.0861068 (* 1 = 0.0861068 loss)
I1018 19:36:44.952605  5095 sgd_solver.cpp:106] Iteration 6350, lr = 1e-05
I1018 19:36:46.154384  5095 solver.cpp:228] Iteration 6400, loss = 0.0609006
I1018 19:36:46.154405  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:46.154412  5095 solver.cpp:244]     Train net output #1: loss = 0.0609005 (* 1 = 0.0609005 loss)
I1018 19:36:46.154415  5095 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I1018 19:36:47.331796  5095 solver.cpp:337] Iteration 6450, Testing net (#0)
I1018 19:36:48.420866  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9901
I1018 19:36:48.420888  5095 solver.cpp:404]     Test net output #1: loss = 0.0283194 (* 1 = 0.0283194 loss)
I1018 19:36:48.428982  5095 solver.cpp:228] Iteration 6450, loss = 0.182522
I1018 19:36:48.428992  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:36:48.428997  5095 solver.cpp:244]     Train net output #1: loss = 0.182522 (* 1 = 0.182522 loss)
I1018 19:36:48.429003  5095 sgd_solver.cpp:106] Iteration 6450, lr = 1e-05
I1018 19:36:49.629020  5095 solver.cpp:228] Iteration 6500, loss = 0.0705442
I1018 19:36:49.629042  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:49.629050  5095 solver.cpp:244]     Train net output #1: loss = 0.0705441 (* 1 = 0.0705441 loss)
I1018 19:36:49.629052  5095 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I1018 19:36:50.829100  5095 solver.cpp:228] Iteration 6550, loss = 0.00112944
I1018 19:36:50.829121  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:50.829126  5095 solver.cpp:244]     Train net output #1: loss = 0.00112938 (* 1 = 0.00112938 loss)
I1018 19:36:50.829130  5095 sgd_solver.cpp:106] Iteration 6550, lr = 1e-05
I1018 19:36:52.005270  5095 solver.cpp:337] Iteration 6600, Testing net (#0)
I1018 19:36:53.094533  5095 solver.cpp:404]     Test net output #0: accuracy = 0.99
I1018 19:36:53.094555  5095 solver.cpp:404]     Test net output #1: loss = 0.0286851 (* 1 = 0.0286851 loss)
I1018 19:36:53.102659  5095 solver.cpp:228] Iteration 6600, loss = 0.0915246
I1018 19:36:53.102669  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:36:53.102675  5095 solver.cpp:244]     Train net output #1: loss = 0.0915246 (* 1 = 0.0915246 loss)
I1018 19:36:53.102679  5095 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I1018 19:36:54.304165  5095 solver.cpp:228] Iteration 6650, loss = 0.0849372
I1018 19:36:54.304188  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:36:54.304194  5095 solver.cpp:244]     Train net output #1: loss = 0.0849371 (* 1 = 0.0849371 loss)
I1018 19:36:54.304198  5095 sgd_solver.cpp:106] Iteration 6650, lr = 1e-05
I1018 19:36:55.505873  5095 solver.cpp:228] Iteration 6700, loss = 0.0444782
I1018 19:36:55.505895  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:36:55.505902  5095 solver.cpp:244]     Train net output #1: loss = 0.0444782 (* 1 = 0.0444782 loss)
I1018 19:36:55.505904  5095 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I1018 19:36:56.684525  5095 solver.cpp:337] Iteration 6750, Testing net (#0)
I1018 19:36:57.773730  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9899
I1018 19:36:57.773752  5095 solver.cpp:404]     Test net output #1: loss = 0.028644 (* 1 = 0.028644 loss)
I1018 19:36:57.781677  5095 solver.cpp:228] Iteration 6750, loss = 0.0108863
I1018 19:36:57.781688  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:57.781705  5095 solver.cpp:244]     Train net output #1: loss = 0.0108863 (* 1 = 0.0108863 loss)
I1018 19:36:57.781710  5095 sgd_solver.cpp:106] Iteration 6750, lr = 1e-05
I1018 19:36:58.981780  5095 solver.cpp:228] Iteration 6800, loss = 0.00415582
I1018 19:36:58.981859  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:36:58.981866  5095 solver.cpp:244]     Train net output #1: loss = 0.00415576 (* 1 = 0.00415576 loss)
I1018 19:36:58.981869  5095 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I1018 19:37:00.181761  5095 solver.cpp:228] Iteration 6850, loss = 0.00770293
I1018 19:37:00.181782  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:00.181789  5095 solver.cpp:244]     Train net output #1: loss = 0.00770284 (* 1 = 0.00770284 loss)
I1018 19:37:00.181792  5095 sgd_solver.cpp:106] Iteration 6850, lr = 1e-05
I1018 19:37:01.358394  5095 solver.cpp:337] Iteration 6900, Testing net (#0)
I1018 19:37:02.448729  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:37:02.448751  5095 solver.cpp:404]     Test net output #1: loss = 0.0282166 (* 1 = 0.0282166 loss)
I1018 19:37:02.456713  5095 solver.cpp:228] Iteration 6900, loss = 0.00366042
I1018 19:37:02.456723  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:02.456728  5095 solver.cpp:244]     Train net output #1: loss = 0.00366032 (* 1 = 0.00366032 loss)
I1018 19:37:02.456733  5095 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I1018 19:37:03.658653  5095 solver.cpp:228] Iteration 6950, loss = 0.011123
I1018 19:37:03.658674  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:03.658679  5095 solver.cpp:244]     Train net output #1: loss = 0.0111229 (* 1 = 0.0111229 loss)
I1018 19:37:03.658684  5095 sgd_solver.cpp:106] Iteration 6950, lr = 1e-05
I1018 19:37:04.860721  5095 solver.cpp:228] Iteration 7000, loss = 0.0291975
I1018 19:37:04.860744  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:04.860750  5095 solver.cpp:244]     Train net output #1: loss = 0.0291974 (* 1 = 0.0291974 loss)
I1018 19:37:04.860754  5095 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I1018 19:37:06.039624  5095 solver.cpp:337] Iteration 7050, Testing net (#0)
I1018 19:37:07.128509  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9897
I1018 19:37:07.128530  5095 solver.cpp:404]     Test net output #1: loss = 0.0283333 (* 1 = 0.0283333 loss)
I1018 19:37:07.136488  5095 solver.cpp:228] Iteration 7050, loss = 0.0147191
I1018 19:37:07.136498  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:07.136503  5095 solver.cpp:244]     Train net output #1: loss = 0.0147191 (* 1 = 0.0147191 loss)
I1018 19:37:07.136507  5095 sgd_solver.cpp:106] Iteration 7050, lr = 1e-05
I1018 19:37:08.336074  5095 solver.cpp:228] Iteration 7100, loss = 0.0764813
I1018 19:37:08.336097  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:37:08.336103  5095 solver.cpp:244]     Train net output #1: loss = 0.0764812 (* 1 = 0.0764812 loss)
I1018 19:37:08.336107  5095 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I1018 19:37:09.535323  5095 solver.cpp:228] Iteration 7150, loss = 0.00279156
I1018 19:37:09.535346  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:09.535351  5095 solver.cpp:244]     Train net output #1: loss = 0.00279147 (* 1 = 0.00279147 loss)
I1018 19:37:09.535354  5095 sgd_solver.cpp:106] Iteration 7150, lr = 1e-05
I1018 19:37:10.712491  5095 solver.cpp:337] Iteration 7200, Testing net (#0)
I1018 19:37:11.801897  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:37:11.801918  5095 solver.cpp:404]     Test net output #1: loss = 0.0284911 (* 1 = 0.0284911 loss)
I1018 19:37:11.809844  5095 solver.cpp:228] Iteration 7200, loss = 0.0222203
I1018 19:37:11.809854  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:11.809859  5095 solver.cpp:244]     Train net output #1: loss = 0.0222202 (* 1 = 0.0222202 loss)
I1018 19:37:11.809864  5095 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I1018 19:37:13.012303  5095 solver.cpp:228] Iteration 7250, loss = 0.0553109
I1018 19:37:13.012326  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:13.012333  5095 solver.cpp:244]     Train net output #1: loss = 0.0553108 (* 1 = 0.0553108 loss)
I1018 19:37:13.012357  5095 sgd_solver.cpp:106] Iteration 7250, lr = 1e-05
I1018 19:37:14.212879  5095 solver.cpp:228] Iteration 7300, loss = 0.220221
I1018 19:37:14.212906  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:37:14.212913  5095 solver.cpp:244]     Train net output #1: loss = 0.220221 (* 1 = 0.220221 loss)
I1018 19:37:14.212916  5095 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I1018 19:37:15.390406  5095 solver.cpp:337] Iteration 7350, Testing net (#0)
I1018 19:37:16.479964  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:37:16.479987  5095 solver.cpp:404]     Test net output #1: loss = 0.0272524 (* 1 = 0.0272524 loss)
I1018 19:37:16.488093  5095 solver.cpp:228] Iteration 7350, loss = 0.0513225
I1018 19:37:16.488104  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:16.488109  5095 solver.cpp:244]     Train net output #1: loss = 0.0513224 (* 1 = 0.0513224 loss)
I1018 19:37:16.488114  5095 sgd_solver.cpp:106] Iteration 7350, lr = 1e-05
I1018 19:37:17.688884  5095 solver.cpp:228] Iteration 7400, loss = 0.127203
I1018 19:37:17.688905  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:37:17.688911  5095 solver.cpp:244]     Train net output #1: loss = 0.127203 (* 1 = 0.127203 loss)
I1018 19:37:17.688915  5095 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I1018 19:37:18.889113  5095 solver.cpp:228] Iteration 7450, loss = 0.0963692
I1018 19:37:18.889137  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:37:18.889142  5095 solver.cpp:244]     Train net output #1: loss = 0.0963691 (* 1 = 0.0963691 loss)
I1018 19:37:18.889147  5095 sgd_solver.cpp:106] Iteration 7450, lr = 1e-05
I1018 19:37:20.065671  5095 solver.cpp:337] Iteration 7500, Testing net (#0)
I1018 19:37:21.153820  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:37:21.153842  5095 solver.cpp:404]     Test net output #1: loss = 0.0285418 (* 1 = 0.0285418 loss)
I1018 19:37:21.161936  5095 solver.cpp:228] Iteration 7500, loss = 0.0307587
I1018 19:37:21.161947  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:21.161952  5095 solver.cpp:244]     Train net output #1: loss = 0.0307587 (* 1 = 0.0307587 loss)
I1018 19:37:21.161957  5095 sgd_solver.cpp:106] Iteration 7500, lr = 1e-05
I1018 19:37:22.362922  5095 solver.cpp:228] Iteration 7550, loss = 0.0801339
I1018 19:37:22.362941  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:37:22.362947  5095 solver.cpp:244]     Train net output #1: loss = 0.0801338 (* 1 = 0.0801338 loss)
I1018 19:37:22.362951  5095 sgd_solver.cpp:106] Iteration 7550, lr = 1e-05
I1018 19:37:23.563396  5095 solver.cpp:228] Iteration 7600, loss = 0.0530746
I1018 19:37:23.563418  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:23.563424  5095 solver.cpp:244]     Train net output #1: loss = 0.0530745 (* 1 = 0.0530745 loss)
I1018 19:37:23.563427  5095 sgd_solver.cpp:106] Iteration 7600, lr = 1e-05
I1018 19:37:24.739995  5095 solver.cpp:337] Iteration 7650, Testing net (#0)
I1018 19:37:25.829258  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9898
I1018 19:37:25.829280  5095 solver.cpp:404]     Test net output #1: loss = 0.0290692 (* 1 = 0.0290692 loss)
I1018 19:37:25.837249  5095 solver.cpp:228] Iteration 7650, loss = 0.0883711
I1018 19:37:25.837260  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:37:25.837265  5095 solver.cpp:244]     Train net output #1: loss = 0.088371 (* 1 = 0.088371 loss)
I1018 19:37:25.837270  5095 sgd_solver.cpp:106] Iteration 7650, lr = 1e-05
I1018 19:37:27.036984  5095 solver.cpp:228] Iteration 7700, loss = 0.0332216
I1018 19:37:27.037003  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:27.037010  5095 solver.cpp:244]     Train net output #1: loss = 0.0332215 (* 1 = 0.0332215 loss)
I1018 19:37:27.037014  5095 sgd_solver.cpp:106] Iteration 7700, lr = 1e-05
I1018 19:37:28.237062  5095 solver.cpp:228] Iteration 7750, loss = 0.0208375
I1018 19:37:28.237102  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:28.237109  5095 solver.cpp:244]     Train net output #1: loss = 0.0208374 (* 1 = 0.0208374 loss)
I1018 19:37:28.237112  5095 sgd_solver.cpp:106] Iteration 7750, lr = 1e-05
I1018 19:37:29.414019  5095 solver.cpp:337] Iteration 7800, Testing net (#0)
I1018 19:37:30.502301  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9905
I1018 19:37:30.502324  5095 solver.cpp:404]     Test net output #1: loss = 0.0290421 (* 1 = 0.0290421 loss)
I1018 19:37:30.510426  5095 solver.cpp:228] Iteration 7800, loss = 0.135213
I1018 19:37:30.510437  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:30.510442  5095 solver.cpp:244]     Train net output #1: loss = 0.135213 (* 1 = 0.135213 loss)
I1018 19:37:30.510447  5095 sgd_solver.cpp:106] Iteration 7800, lr = 1e-05
I1018 19:37:31.711113  5095 solver.cpp:228] Iteration 7850, loss = 0.0254383
I1018 19:37:31.711133  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:31.711139  5095 solver.cpp:244]     Train net output #1: loss = 0.0254382 (* 1 = 0.0254382 loss)
I1018 19:37:31.711143  5095 sgd_solver.cpp:106] Iteration 7850, lr = 1e-05
I1018 19:37:32.911715  5095 solver.cpp:228] Iteration 7900, loss = 0.0023651
I1018 19:37:32.911736  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:32.911742  5095 solver.cpp:244]     Train net output #1: loss = 0.00236498 (* 1 = 0.00236498 loss)
I1018 19:37:32.911746  5095 sgd_solver.cpp:106] Iteration 7900, lr = 1e-05
I1018 19:37:34.087260  5095 solver.cpp:337] Iteration 7950, Testing net (#0)
I1018 19:37:35.176725  5095 solver.cpp:404]     Test net output #0: accuracy = 0.99
I1018 19:37:35.176746  5095 solver.cpp:404]     Test net output #1: loss = 0.0290598 (* 1 = 0.0290598 loss)
I1018 19:37:35.184836  5095 solver.cpp:228] Iteration 7950, loss = 0.00172257
I1018 19:37:35.184847  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:35.184852  5095 solver.cpp:244]     Train net output #1: loss = 0.00172243 (* 1 = 0.00172243 loss)
I1018 19:37:35.184856  5095 sgd_solver.cpp:106] Iteration 7950, lr = 1e-05
I1018 19:37:36.385362  5095 solver.cpp:228] Iteration 8000, loss = 0.00879084
I1018 19:37:36.385382  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:36.385388  5095 solver.cpp:244]     Train net output #1: loss = 0.00879074 (* 1 = 0.00879074 loss)
I1018 19:37:36.385392  5095 sgd_solver.cpp:106] Iteration 8000, lr = 1e-05
I1018 19:37:37.585335  5095 solver.cpp:228] Iteration 8050, loss = 0.113728
I1018 19:37:37.585355  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:37:37.585360  5095 solver.cpp:244]     Train net output #1: loss = 0.113728 (* 1 = 0.113728 loss)
I1018 19:37:37.585363  5095 sgd_solver.cpp:106] Iteration 8050, lr = 1e-05
I1018 19:37:38.762502  5095 solver.cpp:337] Iteration 8100, Testing net (#0)
I1018 19:37:39.851008  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:37:39.851032  5095 solver.cpp:404]     Test net output #1: loss = 0.0281229 (* 1 = 0.0281229 loss)
I1018 19:37:39.859094  5095 solver.cpp:228] Iteration 8100, loss = 0.00376844
I1018 19:37:39.859104  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:39.859110  5095 solver.cpp:244]     Train net output #1: loss = 0.00376831 (* 1 = 0.00376831 loss)
I1018 19:37:39.859114  5095 sgd_solver.cpp:106] Iteration 8100, lr = 1e-05
I1018 19:37:41.059928  5095 solver.cpp:228] Iteration 8150, loss = 0.00919105
I1018 19:37:41.059949  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:41.059955  5095 solver.cpp:244]     Train net output #1: loss = 0.00919091 (* 1 = 0.00919091 loss)
I1018 19:37:41.059958  5095 sgd_solver.cpp:106] Iteration 8150, lr = 1e-05
I1018 19:37:42.260416  5095 solver.cpp:228] Iteration 8200, loss = 0.0686988
I1018 19:37:42.260437  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:37:42.260443  5095 solver.cpp:244]     Train net output #1: loss = 0.0686986 (* 1 = 0.0686986 loss)
I1018 19:37:42.260447  5095 sgd_solver.cpp:106] Iteration 8200, lr = 1e-05
I1018 19:37:43.436635  5095 solver.cpp:337] Iteration 8250, Testing net (#0)
I1018 19:37:44.525584  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9904
I1018 19:37:44.525607  5095 solver.cpp:404]     Test net output #1: loss = 0.0273129 (* 1 = 0.0273129 loss)
I1018 19:37:44.533581  5095 solver.cpp:228] Iteration 8250, loss = 0.114363
I1018 19:37:44.533592  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:44.533597  5095 solver.cpp:244]     Train net output #1: loss = 0.114363 (* 1 = 0.114363 loss)
I1018 19:37:44.533602  5095 sgd_solver.cpp:106] Iteration 8250, lr = 1e-05
I1018 19:37:45.733680  5095 solver.cpp:228] Iteration 8300, loss = 0.165676
I1018 19:37:45.733701  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:37:45.733708  5095 solver.cpp:244]     Train net output #1: loss = 0.165676 (* 1 = 0.165676 loss)
I1018 19:37:45.733711  5095 sgd_solver.cpp:106] Iteration 8300, lr = 1e-05
I1018 19:37:46.934176  5095 solver.cpp:228] Iteration 8350, loss = 0.0345229
I1018 19:37:46.934198  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:37:46.934206  5095 solver.cpp:244]     Train net output #1: loss = 0.0345227 (* 1 = 0.0345227 loss)
I1018 19:37:46.934208  5095 sgd_solver.cpp:106] Iteration 8350, lr = 1e-05
I1018 19:37:48.135246  5095 solver.cpp:337] Iteration 8400, Testing net (#0)
I1018 19:37:49.223919  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9901
I1018 19:37:49.223942  5095 solver.cpp:404]     Test net output #1: loss = 0.028868 (* 1 = 0.028868 loss)
I1018 19:37:49.232017  5095 solver.cpp:228] Iteration 8400, loss = 0.103854
I1018 19:37:49.232028  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:37:49.232034  5095 solver.cpp:244]     Train net output #1: loss = 0.103854 (* 1 = 0.103854 loss)
I1018 19:37:49.232039  5095 sgd_solver.cpp:106] Iteration 8400, lr = 1e-05
I1018 19:37:50.432200  5095 solver.cpp:228] Iteration 8450, loss = 0.104971
I1018 19:37:50.432221  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:37:50.432229  5095 solver.cpp:244]     Train net output #1: loss = 0.104971 (* 1 = 0.104971 loss)
I1018 19:37:50.432231  5095 sgd_solver.cpp:106] Iteration 8450, lr = 1e-05
I1018 19:37:51.632051  5095 solver.cpp:228] Iteration 8500, loss = 0.0225765
I1018 19:37:51.632073  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:51.632079  5095 solver.cpp:244]     Train net output #1: loss = 0.0225763 (* 1 = 0.0225763 loss)
I1018 19:37:51.632082  5095 sgd_solver.cpp:106] Iteration 8500, lr = 1e-05
I1018 19:37:52.807865  5095 solver.cpp:337] Iteration 8550, Testing net (#0)
I1018 19:37:53.897254  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9898
I1018 19:37:53.897277  5095 solver.cpp:404]     Test net output #1: loss = 0.0284714 (* 1 = 0.0284714 loss)
I1018 19:37:53.905222  5095 solver.cpp:228] Iteration 8550, loss = 0.0697918
I1018 19:37:53.905233  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:37:53.905238  5095 solver.cpp:244]     Train net output #1: loss = 0.0697917 (* 1 = 0.0697917 loss)
I1018 19:37:53.905243  5095 sgd_solver.cpp:106] Iteration 8550, lr = 1e-05
I1018 19:37:55.106986  5095 solver.cpp:228] Iteration 8600, loss = 0.00256091
I1018 19:37:55.107005  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:55.107012  5095 solver.cpp:244]     Train net output #1: loss = 0.00256073 (* 1 = 0.00256073 loss)
I1018 19:37:55.107015  5095 sgd_solver.cpp:106] Iteration 8600, lr = 1e-05
I1018 19:37:56.307288  5095 solver.cpp:228] Iteration 8650, loss = 0.0134323
I1018 19:37:56.307312  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:56.307318  5095 solver.cpp:244]     Train net output #1: loss = 0.0134321 (* 1 = 0.0134321 loss)
I1018 19:37:56.307322  5095 sgd_solver.cpp:106] Iteration 8650, lr = 1e-05
I1018 19:37:57.483651  5095 solver.cpp:337] Iteration 8700, Testing net (#0)
I1018 19:37:58.572860  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9901
I1018 19:37:58.572883  5095 solver.cpp:404]     Test net output #1: loss = 0.0289948 (* 1 = 0.0289948 loss)
I1018 19:37:58.580826  5095 solver.cpp:228] Iteration 8700, loss = 0.00505646
I1018 19:37:58.580837  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:37:58.580852  5095 solver.cpp:244]     Train net output #1: loss = 0.0050563 (* 1 = 0.0050563 loss)
I1018 19:37:58.580857  5095 sgd_solver.cpp:106] Iteration 8700, lr = 1e-05
I1018 19:37:59.781956  5095 solver.cpp:228] Iteration 8750, loss = 0.0958452
I1018 19:37:59.782032  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:37:59.782038  5095 solver.cpp:244]     Train net output #1: loss = 0.095845 (* 1 = 0.095845 loss)
I1018 19:37:59.782042  5095 sgd_solver.cpp:106] Iteration 8750, lr = 1e-05
I1018 19:38:00.981659  5095 solver.cpp:228] Iteration 8800, loss = 0.00194286
I1018 19:38:00.981680  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:00.981686  5095 solver.cpp:244]     Train net output #1: loss = 0.0019427 (* 1 = 0.0019427 loss)
I1018 19:38:00.981689  5095 sgd_solver.cpp:106] Iteration 8800, lr = 1e-05
I1018 19:38:02.160188  5095 solver.cpp:337] Iteration 8850, Testing net (#0)
I1018 19:38:03.249413  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9896
I1018 19:38:03.249435  5095 solver.cpp:404]     Test net output #1: loss = 0.0273344 (* 1 = 0.0273344 loss)
I1018 19:38:03.257524  5095 solver.cpp:228] Iteration 8850, loss = 0.020655
I1018 19:38:03.257535  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:03.257540  5095 solver.cpp:244]     Train net output #1: loss = 0.0206549 (* 1 = 0.0206549 loss)
I1018 19:38:03.257545  5095 sgd_solver.cpp:106] Iteration 8850, lr = 1e-05
I1018 19:38:04.458585  5095 solver.cpp:228] Iteration 8900, loss = 0.00359856
I1018 19:38:04.458608  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:04.458614  5095 solver.cpp:244]     Train net output #1: loss = 0.00359841 (* 1 = 0.00359841 loss)
I1018 19:38:04.458617  5095 sgd_solver.cpp:106] Iteration 8900, lr = 1e-05
I1018 19:38:05.658557  5095 solver.cpp:228] Iteration 8950, loss = 0.0464971
I1018 19:38:05.658581  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:05.658586  5095 solver.cpp:244]     Train net output #1: loss = 0.046497 (* 1 = 0.046497 loss)
I1018 19:38:05.658589  5095 sgd_solver.cpp:106] Iteration 8950, lr = 1e-05
I1018 19:38:06.834851  5095 solver.cpp:337] Iteration 9000, Testing net (#0)
I1018 19:38:07.923538  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:38:07.923562  5095 solver.cpp:404]     Test net output #1: loss = 0.0283087 (* 1 = 0.0283087 loss)
I1018 19:38:07.931432  5095 solver.cpp:228] Iteration 9000, loss = 0.018229
I1018 19:38:07.931442  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:07.931447  5095 solver.cpp:244]     Train net output #1: loss = 0.0182288 (* 1 = 0.0182288 loss)
I1018 19:38:07.931452  5095 sgd_solver.cpp:106] Iteration 9000, lr = 1e-05
I1018 19:38:09.131675  5095 solver.cpp:228] Iteration 9050, loss = 0.00597645
I1018 19:38:09.131696  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:09.131703  5095 solver.cpp:244]     Train net output #1: loss = 0.00597633 (* 1 = 0.00597633 loss)
I1018 19:38:09.131706  5095 sgd_solver.cpp:106] Iteration 9050, lr = 1e-05
I1018 19:38:10.332185  5095 solver.cpp:228] Iteration 9100, loss = 0.0439273
I1018 19:38:10.332209  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:10.332218  5095 solver.cpp:244]     Train net output #1: loss = 0.0439272 (* 1 = 0.0439272 loss)
I1018 19:38:10.332222  5095 sgd_solver.cpp:106] Iteration 9100, lr = 1e-05
I1018 19:38:11.508357  5095 solver.cpp:337] Iteration 9150, Testing net (#0)
I1018 19:38:12.597731  5095 solver.cpp:404]     Test net output #0: accuracy = 0.991
I1018 19:38:12.597754  5095 solver.cpp:404]     Test net output #1: loss = 0.0276467 (* 1 = 0.0276467 loss)
I1018 19:38:12.605844  5095 solver.cpp:228] Iteration 9150, loss = 0.129156
I1018 19:38:12.605854  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:38:12.605859  5095 solver.cpp:244]     Train net output #1: loss = 0.129156 (* 1 = 0.129156 loss)
I1018 19:38:12.605865  5095 sgd_solver.cpp:106] Iteration 9150, lr = 1e-05
I1018 19:38:13.807849  5095 solver.cpp:228] Iteration 9200, loss = 0.008866
I1018 19:38:13.807873  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:13.807880  5095 solver.cpp:244]     Train net output #1: loss = 0.00886584 (* 1 = 0.00886584 loss)
I1018 19:38:13.807904  5095 sgd_solver.cpp:106] Iteration 9200, lr = 1e-05
I1018 19:38:15.009124  5095 solver.cpp:228] Iteration 9250, loss = 0.0280776
I1018 19:38:15.009146  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:15.009152  5095 solver.cpp:244]     Train net output #1: loss = 0.0280775 (* 1 = 0.0280775 loss)
I1018 19:38:15.009156  5095 sgd_solver.cpp:106] Iteration 9250, lr = 1e-05
I1018 19:38:16.187250  5095 solver.cpp:337] Iteration 9300, Testing net (#0)
I1018 19:38:17.276053  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9905
I1018 19:38:17.276074  5095 solver.cpp:404]     Test net output #1: loss = 0.0270676 (* 1 = 0.0270676 loss)
I1018 19:38:17.283993  5095 solver.cpp:228] Iteration 9300, loss = 0.00867136
I1018 19:38:17.284004  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:17.284009  5095 solver.cpp:244]     Train net output #1: loss = 0.00867122 (* 1 = 0.00867122 loss)
I1018 19:38:17.284014  5095 sgd_solver.cpp:106] Iteration 9300, lr = 1e-05
I1018 19:38:18.485240  5095 solver.cpp:228] Iteration 9350, loss = 0.0012383
I1018 19:38:18.485261  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:18.485268  5095 solver.cpp:244]     Train net output #1: loss = 0.00123815 (* 1 = 0.00123815 loss)
I1018 19:38:18.485271  5095 sgd_solver.cpp:106] Iteration 9350, lr = 1e-05
I1018 19:38:19.686880  5095 solver.cpp:228] Iteration 9400, loss = 0.18764
I1018 19:38:19.686904  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:38:19.686910  5095 solver.cpp:244]     Train net output #1: loss = 0.18764 (* 1 = 0.18764 loss)
I1018 19:38:19.686913  5095 sgd_solver.cpp:106] Iteration 9400, lr = 1e-05
I1018 19:38:20.863984  5095 solver.cpp:337] Iteration 9450, Testing net (#0)
I1018 19:38:21.953625  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9905
I1018 19:38:21.953649  5095 solver.cpp:404]     Test net output #1: loss = 0.0279489 (* 1 = 0.0279489 loss)
I1018 19:38:21.961607  5095 solver.cpp:228] Iteration 9450, loss = 0.00374805
I1018 19:38:21.961617  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:21.961622  5095 solver.cpp:244]     Train net output #1: loss = 0.00374794 (* 1 = 0.00374794 loss)
I1018 19:38:21.961627  5095 sgd_solver.cpp:106] Iteration 9450, lr = 1e-05
I1018 19:38:23.164042  5095 solver.cpp:228] Iteration 9500, loss = 0.0433768
I1018 19:38:23.164063  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:23.164070  5095 solver.cpp:244]     Train net output #1: loss = 0.0433766 (* 1 = 0.0433766 loss)
I1018 19:38:23.164073  5095 sgd_solver.cpp:106] Iteration 9500, lr = 1e-05
I1018 19:38:24.364480  5095 solver.cpp:228] Iteration 9550, loss = 0.0437607
I1018 19:38:24.364502  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:38:24.364508  5095 solver.cpp:244]     Train net output #1: loss = 0.0437606 (* 1 = 0.0437606 loss)
I1018 19:38:24.364511  5095 sgd_solver.cpp:106] Iteration 9550, lr = 1e-05
I1018 19:38:25.542182  5095 solver.cpp:337] Iteration 9600, Testing net (#0)
I1018 19:38:26.631134  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:38:26.631155  5095 solver.cpp:404]     Test net output #1: loss = 0.0280969 (* 1 = 0.0280969 loss)
I1018 19:38:26.639073  5095 solver.cpp:228] Iteration 9600, loss = 0.00221467
I1018 19:38:26.639083  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:26.639088  5095 solver.cpp:244]     Train net output #1: loss = 0.00221453 (* 1 = 0.00221453 loss)
I1018 19:38:26.639093  5095 sgd_solver.cpp:106] Iteration 9600, lr = 1e-05
I1018 19:38:27.839840  5095 solver.cpp:228] Iteration 9650, loss = 0.00659321
I1018 19:38:27.839864  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:27.839869  5095 solver.cpp:244]     Train net output #1: loss = 0.00659306 (* 1 = 0.00659306 loss)
I1018 19:38:27.839872  5095 sgd_solver.cpp:106] Iteration 9650, lr = 1e-05
I1018 19:38:29.039775  5095 solver.cpp:228] Iteration 9700, loss = 0.00478703
I1018 19:38:29.039821  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:29.039827  5095 solver.cpp:244]     Train net output #1: loss = 0.00478689 (* 1 = 0.00478689 loss)
I1018 19:38:29.039831  5095 sgd_solver.cpp:106] Iteration 9700, lr = 1e-05
I1018 19:38:30.215819  5095 solver.cpp:337] Iteration 9750, Testing net (#0)
I1018 19:38:31.305021  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9904
I1018 19:38:31.305042  5095 solver.cpp:404]     Test net output #1: loss = 0.0290246 (* 1 = 0.0290246 loss)
I1018 19:38:31.313019  5095 solver.cpp:228] Iteration 9750, loss = 0.152627
I1018 19:38:31.313030  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:38:31.313035  5095 solver.cpp:244]     Train net output #1: loss = 0.152627 (* 1 = 0.152627 loss)
I1018 19:38:31.313038  5095 sgd_solver.cpp:106] Iteration 9750, lr = 1e-05
I1018 19:38:32.515282  5095 solver.cpp:228] Iteration 9800, loss = 0.0981472
I1018 19:38:32.515300  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:38:32.515306  5095 solver.cpp:244]     Train net output #1: loss = 0.0981471 (* 1 = 0.0981471 loss)
I1018 19:38:32.515310  5095 sgd_solver.cpp:106] Iteration 9800, lr = 1e-05
I1018 19:38:33.716943  5095 solver.cpp:228] Iteration 9850, loss = 0.106695
I1018 19:38:33.716966  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:38:33.716974  5095 solver.cpp:244]     Train net output #1: loss = 0.106695 (* 1 = 0.106695 loss)
I1018 19:38:33.716977  5095 sgd_solver.cpp:106] Iteration 9850, lr = 1e-05
I1018 19:38:34.894590  5095 solver.cpp:337] Iteration 9900, Testing net (#0)
I1018 19:38:35.983364  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9907
I1018 19:38:35.983386  5095 solver.cpp:404]     Test net output #1: loss = 0.0275791 (* 1 = 0.0275791 loss)
I1018 19:38:35.991456  5095 solver.cpp:228] Iteration 9900, loss = 0.0135867
I1018 19:38:35.991466  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:35.991471  5095 solver.cpp:244]     Train net output #1: loss = 0.0135867 (* 1 = 0.0135867 loss)
I1018 19:38:35.991474  5095 sgd_solver.cpp:106] Iteration 9900, lr = 1e-05
I1018 19:38:37.191763  5095 solver.cpp:228] Iteration 9950, loss = 0.109754
I1018 19:38:37.191782  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:37.191789  5095 solver.cpp:244]     Train net output #1: loss = 0.109754 (* 1 = 0.109754 loss)
I1018 19:38:37.191792  5095 sgd_solver.cpp:106] Iteration 9950, lr = 1e-05
I1018 19:38:38.367499  5095 solver.cpp:454] Snapshotting to binary proto file cifar-10_leakyrelu_RMSProp_iter_10000.caffemodel
I1018 19:38:38.394500  5095 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_leakyrelu_RMSProp_iter_10000.solverstate
I1018 19:38:38.409463  5095 solver.cpp:228] Iteration 10000, loss = 0.0128647
I1018 19:38:38.409487  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:38.409493  5095 solver.cpp:244]     Train net output #1: loss = 0.0128646 (* 1 = 0.0128646 loss)
I1018 19:38:38.409499  5095 sgd_solver.cpp:106] Iteration 10000, lr = 1e-06
I1018 19:38:39.587827  5095 solver.cpp:337] Iteration 10050, Testing net (#0)
I1018 19:38:40.676992  5095 solver.cpp:404]     Test net output #0: accuracy = 0.99
I1018 19:38:40.677014  5095 solver.cpp:404]     Test net output #1: loss = 0.0277127 (* 1 = 0.0277127 loss)
I1018 19:38:40.685108  5095 solver.cpp:228] Iteration 10050, loss = 0.0131615
I1018 19:38:40.685119  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:40.685124  5095 solver.cpp:244]     Train net output #1: loss = 0.0131613 (* 1 = 0.0131613 loss)
I1018 19:38:40.685128  5095 sgd_solver.cpp:106] Iteration 10050, lr = 1e-06
I1018 19:38:41.884850  5095 solver.cpp:228] Iteration 10100, loss = 0.104299
I1018 19:38:41.884870  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:38:41.884876  5095 solver.cpp:244]     Train net output #1: loss = 0.104299 (* 1 = 0.104299 loss)
I1018 19:38:41.884878  5095 sgd_solver.cpp:106] Iteration 10100, lr = 1e-06
I1018 19:38:43.085925  5095 solver.cpp:228] Iteration 10150, loss = 0.0912129
I1018 19:38:43.085947  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:38:43.085954  5095 solver.cpp:244]     Train net output #1: loss = 0.0912128 (* 1 = 0.0912128 loss)
I1018 19:38:43.085958  5095 sgd_solver.cpp:106] Iteration 10150, lr = 1e-06
I1018 19:38:44.264426  5095 solver.cpp:337] Iteration 10200, Testing net (#0)
I1018 19:38:45.353833  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:38:45.353858  5095 solver.cpp:404]     Test net output #1: loss = 0.0274588 (* 1 = 0.0274588 loss)
I1018 19:38:45.361919  5095 solver.cpp:228] Iteration 10200, loss = 0.0857742
I1018 19:38:45.361932  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:38:45.361938  5095 solver.cpp:244]     Train net output #1: loss = 0.0857741 (* 1 = 0.0857741 loss)
I1018 19:38:45.361943  5095 sgd_solver.cpp:106] Iteration 10200, lr = 1e-06
I1018 19:38:46.562589  5095 solver.cpp:228] Iteration 10250, loss = 0.161548
I1018 19:38:46.562611  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:46.562618  5095 solver.cpp:244]     Train net output #1: loss = 0.161548 (* 1 = 0.161548 loss)
I1018 19:38:46.562620  5095 sgd_solver.cpp:106] Iteration 10250, lr = 1e-06
I1018 19:38:47.763381  5095 solver.cpp:228] Iteration 10300, loss = 0.000587019
I1018 19:38:47.763402  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:47.763408  5095 solver.cpp:244]     Train net output #1: loss = 0.000586901 (* 1 = 0.000586901 loss)
I1018 19:38:47.763411  5095 sgd_solver.cpp:106] Iteration 10300, lr = 1e-06
I1018 19:38:48.940651  5095 solver.cpp:337] Iteration 10350, Testing net (#0)
I1018 19:38:50.029925  5095 solver.cpp:404]     Test net output #0: accuracy = 0.99
I1018 19:38:50.029950  5095 solver.cpp:404]     Test net output #1: loss = 0.027597 (* 1 = 0.027597 loss)
I1018 19:38:50.037988  5095 solver.cpp:228] Iteration 10350, loss = 0.139389
I1018 19:38:50.037999  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:38:50.038007  5095 solver.cpp:244]     Train net output #1: loss = 0.139389 (* 1 = 0.139389 loss)
I1018 19:38:50.038012  5095 sgd_solver.cpp:106] Iteration 10350, lr = 1e-06
I1018 19:38:51.238090  5095 solver.cpp:228] Iteration 10400, loss = 0.0974151
I1018 19:38:51.238109  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:38:51.238116  5095 solver.cpp:244]     Train net output #1: loss = 0.097415 (* 1 = 0.097415 loss)
I1018 19:38:51.238118  5095 sgd_solver.cpp:106] Iteration 10400, lr = 1e-06
I1018 19:38:52.440843  5095 solver.cpp:228] Iteration 10450, loss = 0.0396316
I1018 19:38:52.440865  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:52.440871  5095 solver.cpp:244]     Train net output #1: loss = 0.0396314 (* 1 = 0.0396314 loss)
I1018 19:38:52.440876  5095 sgd_solver.cpp:106] Iteration 10450, lr = 1e-06
I1018 19:38:53.626709  5095 solver.cpp:337] Iteration 10500, Testing net (#0)
I1018 19:38:54.732817  5095 solver.cpp:404]     Test net output #0: accuracy = 0.99
I1018 19:38:54.732839  5095 solver.cpp:404]     Test net output #1: loss = 0.0274918 (* 1 = 0.0274918 loss)
I1018 19:38:54.740804  5095 solver.cpp:228] Iteration 10500, loss = 0.0127739
I1018 19:38:54.740814  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:54.740820  5095 solver.cpp:244]     Train net output #1: loss = 0.0127738 (* 1 = 0.0127738 loss)
I1018 19:38:54.740824  5095 sgd_solver.cpp:106] Iteration 10500, lr = 1e-06
I1018 19:38:55.956135  5095 solver.cpp:228] Iteration 10550, loss = 0.00249405
I1018 19:38:55.956157  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:55.956163  5095 solver.cpp:244]     Train net output #1: loss = 0.00249389 (* 1 = 0.00249389 loss)
I1018 19:38:55.956166  5095 sgd_solver.cpp:106] Iteration 10550, lr = 1e-06
I1018 19:38:57.158465  5095 solver.cpp:228] Iteration 10600, loss = 0.0399252
I1018 19:38:57.158485  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:38:57.158493  5095 solver.cpp:244]     Train net output #1: loss = 0.039925 (* 1 = 0.039925 loss)
I1018 19:38:57.158495  5095 sgd_solver.cpp:106] Iteration 10600, lr = 1e-06
I1018 19:38:58.336540  5095 solver.cpp:337] Iteration 10650, Testing net (#0)
I1018 19:38:59.445410  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:38:59.445456  5095 solver.cpp:404]     Test net output #1: loss = 0.0274408 (* 1 = 0.0274408 loss)
I1018 19:38:59.454536  5095 solver.cpp:228] Iteration 10650, loss = 0.00141506
I1018 19:38:59.454546  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:38:59.454551  5095 solver.cpp:244]     Train net output #1: loss = 0.0014149 (* 1 = 0.0014149 loss)
I1018 19:38:59.454556  5095 sgd_solver.cpp:106] Iteration 10650, lr = 1e-06
I1018 19:39:00.686161  5095 solver.cpp:228] Iteration 10700, loss = 0.023329
I1018 19:39:00.686283  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:00.686291  5095 solver.cpp:244]     Train net output #1: loss = 0.0233288 (* 1 = 0.0233288 loss)
I1018 19:39:00.686295  5095 sgd_solver.cpp:106] Iteration 10700, lr = 1e-06
I1018 19:39:01.887311  5095 solver.cpp:228] Iteration 10750, loss = 0.00365209
I1018 19:39:01.887334  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:01.887341  5095 solver.cpp:244]     Train net output #1: loss = 0.00365194 (* 1 = 0.00365194 loss)
I1018 19:39:01.887344  5095 sgd_solver.cpp:106] Iteration 10750, lr = 1e-06
I1018 19:39:03.064764  5095 solver.cpp:337] Iteration 10800, Testing net (#0)
I1018 19:39:04.166112  5095 solver.cpp:404]     Test net output #0: accuracy = 0.99
I1018 19:39:04.166137  5095 solver.cpp:404]     Test net output #1: loss = 0.0277495 (* 1 = 0.0277495 loss)
I1018 19:39:04.174083  5095 solver.cpp:228] Iteration 10800, loss = 0.00313972
I1018 19:39:04.174095  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:04.174100  5095 solver.cpp:244]     Train net output #1: loss = 0.00313954 (* 1 = 0.00313954 loss)
I1018 19:39:04.174104  5095 sgd_solver.cpp:106] Iteration 10800, lr = 1e-06
I1018 19:39:05.376441  5095 solver.cpp:228] Iteration 10850, loss = 0.10264
I1018 19:39:05.376463  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:39:05.376471  5095 solver.cpp:244]     Train net output #1: loss = 0.10264 (* 1 = 0.10264 loss)
I1018 19:39:05.376472  5095 sgd_solver.cpp:106] Iteration 10850, lr = 1e-06
I1018 19:39:06.579064  5095 solver.cpp:228] Iteration 10900, loss = 0.0014811
I1018 19:39:06.579085  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:06.579092  5095 solver.cpp:244]     Train net output #1: loss = 0.0014809 (* 1 = 0.0014809 loss)
I1018 19:39:06.579095  5095 sgd_solver.cpp:106] Iteration 10900, lr = 1e-06
I1018 19:39:07.757479  5095 solver.cpp:337] Iteration 10950, Testing net (#0)
I1018 19:39:08.846925  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:39:08.846948  5095 solver.cpp:404]     Test net output #1: loss = 0.0274595 (* 1 = 0.0274595 loss)
I1018 19:39:08.854869  5095 solver.cpp:228] Iteration 10950, loss = 0.00609517
I1018 19:39:08.854881  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:08.854885  5095 solver.cpp:244]     Train net output #1: loss = 0.00609496 (* 1 = 0.00609496 loss)
I1018 19:39:08.854890  5095 sgd_solver.cpp:106] Iteration 10950, lr = 1e-06
I1018 19:39:10.056526  5095 solver.cpp:228] Iteration 11000, loss = 0.0369805
I1018 19:39:10.056547  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:10.056555  5095 solver.cpp:244]     Train net output #1: loss = 0.0369802 (* 1 = 0.0369802 loss)
I1018 19:39:10.056557  5095 sgd_solver.cpp:106] Iteration 11000, lr = 1e-06
I1018 19:39:11.257179  5095 solver.cpp:228] Iteration 11050, loss = 0.153966
I1018 19:39:11.257199  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:39:11.257205  5095 solver.cpp:244]     Train net output #1: loss = 0.153966 (* 1 = 0.153966 loss)
I1018 19:39:11.257207  5095 sgd_solver.cpp:106] Iteration 11050, lr = 1e-06
I1018 19:39:12.434414  5095 solver.cpp:337] Iteration 11100, Testing net (#0)
I1018 19:39:13.524010  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:39:13.524034  5095 solver.cpp:404]     Test net output #1: loss = 0.0269005 (* 1 = 0.0269005 loss)
I1018 19:39:13.532097  5095 solver.cpp:228] Iteration 11100, loss = 0.059697
I1018 19:39:13.532109  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:39:13.532114  5095 solver.cpp:244]     Train net output #1: loss = 0.0596968 (* 1 = 0.0596968 loss)
I1018 19:39:13.532119  5095 sgd_solver.cpp:106] Iteration 11100, lr = 1e-06
I1018 19:39:14.733898  5095 solver.cpp:228] Iteration 11150, loss = 0.127896
I1018 19:39:14.733922  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:14.733927  5095 solver.cpp:244]     Train net output #1: loss = 0.127896 (* 1 = 0.127896 loss)
I1018 19:39:14.733950  5095 sgd_solver.cpp:106] Iteration 11150, lr = 1e-06
I1018 19:39:15.935868  5095 solver.cpp:228] Iteration 11200, loss = 0.0943321
I1018 19:39:15.935889  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:39:15.935895  5095 solver.cpp:244]     Train net output #1: loss = 0.0943319 (* 1 = 0.0943319 loss)
I1018 19:39:15.935899  5095 sgd_solver.cpp:106] Iteration 11200, lr = 1e-06
I1018 19:39:17.114593  5095 solver.cpp:337] Iteration 11250, Testing net (#0)
I1018 19:39:18.203889  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:39:18.203912  5095 solver.cpp:404]     Test net output #1: loss = 0.0272018 (* 1 = 0.0272018 loss)
I1018 19:39:18.211879  5095 solver.cpp:228] Iteration 11250, loss = 0.011519
I1018 19:39:18.211891  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:18.211896  5095 solver.cpp:244]     Train net output #1: loss = 0.0115188 (* 1 = 0.0115188 loss)
I1018 19:39:18.211901  5095 sgd_solver.cpp:106] Iteration 11250, lr = 1e-06
I1018 19:39:19.413106  5095 solver.cpp:228] Iteration 11300, loss = 0.0585664
I1018 19:39:19.413130  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:19.413137  5095 solver.cpp:244]     Train net output #1: loss = 0.0585662 (* 1 = 0.0585662 loss)
I1018 19:39:19.413139  5095 sgd_solver.cpp:106] Iteration 11300, lr = 1e-06
I1018 19:39:20.613461  5095 solver.cpp:228] Iteration 11350, loss = 0.0409724
I1018 19:39:20.613482  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:20.613488  5095 solver.cpp:244]     Train net output #1: loss = 0.0409722 (* 1 = 0.0409722 loss)
I1018 19:39:20.613492  5095 sgd_solver.cpp:106] Iteration 11350, lr = 1e-06
I1018 19:39:21.790969  5095 solver.cpp:337] Iteration 11400, Testing net (#0)
I1018 19:39:22.880317  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:39:22.880339  5095 solver.cpp:404]     Test net output #1: loss = 0.0271466 (* 1 = 0.0271466 loss)
I1018 19:39:22.888293  5095 solver.cpp:228] Iteration 11400, loss = 0.0621737
I1018 19:39:22.888303  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:22.888309  5095 solver.cpp:244]     Train net output #1: loss = 0.0621735 (* 1 = 0.0621735 loss)
I1018 19:39:22.888314  5095 sgd_solver.cpp:106] Iteration 11400, lr = 1e-06
I1018 19:39:24.089138  5095 solver.cpp:228] Iteration 11450, loss = 0.0179882
I1018 19:39:24.089160  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:24.089166  5095 solver.cpp:244]     Train net output #1: loss = 0.0179879 (* 1 = 0.0179879 loss)
I1018 19:39:24.089169  5095 sgd_solver.cpp:106] Iteration 11450, lr = 1e-06
I1018 19:39:25.290858  5095 solver.cpp:228] Iteration 11500, loss = 0.0383194
I1018 19:39:25.290880  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:25.290886  5095 solver.cpp:244]     Train net output #1: loss = 0.0383191 (* 1 = 0.0383191 loss)
I1018 19:39:25.290889  5095 sgd_solver.cpp:106] Iteration 11500, lr = 1e-06
I1018 19:39:26.467584  5095 solver.cpp:337] Iteration 11550, Testing net (#0)
I1018 19:39:27.556987  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:39:27.557031  5095 solver.cpp:404]     Test net output #1: loss = 0.0270444 (* 1 = 0.0270444 loss)
I1018 19:39:27.565074  5095 solver.cpp:228] Iteration 11550, loss = 0.12323
I1018 19:39:27.565085  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:27.565091  5095 solver.cpp:244]     Train net output #1: loss = 0.12323 (* 1 = 0.12323 loss)
I1018 19:39:27.565095  5095 sgd_solver.cpp:106] Iteration 11550, lr = 1e-06
I1018 19:39:28.765952  5095 solver.cpp:228] Iteration 11600, loss = 0.0136897
I1018 19:39:28.765974  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:28.765980  5095 solver.cpp:244]     Train net output #1: loss = 0.0136895 (* 1 = 0.0136895 loss)
I1018 19:39:28.765982  5095 sgd_solver.cpp:106] Iteration 11600, lr = 1e-06
I1018 19:39:29.966790  5095 solver.cpp:228] Iteration 11650, loss = 0.0122957
I1018 19:39:29.966830  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:29.966838  5095 solver.cpp:244]     Train net output #1: loss = 0.0122955 (* 1 = 0.0122955 loss)
I1018 19:39:29.966841  5095 sgd_solver.cpp:106] Iteration 11650, lr = 1e-06
I1018 19:39:31.143492  5095 solver.cpp:337] Iteration 11700, Testing net (#0)
I1018 19:39:32.233191  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9905
I1018 19:39:32.233213  5095 solver.cpp:404]     Test net output #1: loss = 0.026902 (* 1 = 0.026902 loss)
I1018 19:39:32.241173  5095 solver.cpp:228] Iteration 11700, loss = 0.00426272
I1018 19:39:32.241184  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:32.241189  5095 solver.cpp:244]     Train net output #1: loss = 0.00426255 (* 1 = 0.00426255 loss)
I1018 19:39:32.241194  5095 sgd_solver.cpp:106] Iteration 11700, lr = 1e-06
I1018 19:39:33.442880  5095 solver.cpp:228] Iteration 11750, loss = 0.0035394
I1018 19:39:33.442903  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:33.442909  5095 solver.cpp:244]     Train net output #1: loss = 0.00353923 (* 1 = 0.00353923 loss)
I1018 19:39:33.442911  5095 sgd_solver.cpp:106] Iteration 11750, lr = 1e-06
I1018 19:39:34.645123  5095 solver.cpp:228] Iteration 11800, loss = 0.118212
I1018 19:39:34.645148  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:34.645153  5095 solver.cpp:244]     Train net output #1: loss = 0.118211 (* 1 = 0.118211 loss)
I1018 19:39:34.645156  5095 sgd_solver.cpp:106] Iteration 11800, lr = 1e-06
I1018 19:39:35.823750  5095 solver.cpp:337] Iteration 11850, Testing net (#0)
I1018 19:39:36.913141  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9908
I1018 19:39:36.913163  5095 solver.cpp:404]     Test net output #1: loss = 0.0269077 (* 1 = 0.0269077 loss)
I1018 19:39:36.921264  5095 solver.cpp:228] Iteration 11850, loss = 0.0337891
I1018 19:39:36.921275  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:36.921281  5095 solver.cpp:244]     Train net output #1: loss = 0.0337889 (* 1 = 0.0337889 loss)
I1018 19:39:36.921285  5095 sgd_solver.cpp:106] Iteration 11850, lr = 1e-06
I1018 19:39:38.120945  5095 solver.cpp:228] Iteration 11900, loss = 0.0565202
I1018 19:39:38.120967  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:38.120975  5095 solver.cpp:244]     Train net output #1: loss = 0.05652 (* 1 = 0.05652 loss)
I1018 19:39:38.120977  5095 sgd_solver.cpp:106] Iteration 11900, lr = 1e-06
I1018 19:39:39.322135  5095 solver.cpp:228] Iteration 11950, loss = 0.0719841
I1018 19:39:39.322161  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:39:39.322168  5095 solver.cpp:244]     Train net output #1: loss = 0.0719839 (* 1 = 0.0719839 loss)
I1018 19:39:39.322172  5095 sgd_solver.cpp:106] Iteration 11950, lr = 1e-06
I1018 19:39:40.498203  5095 solver.cpp:337] Iteration 12000, Testing net (#0)
I1018 19:39:41.587610  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9904
I1018 19:39:41.587632  5095 solver.cpp:404]     Test net output #1: loss = 0.0266222 (* 1 = 0.0266222 loss)
I1018 19:39:41.595616  5095 solver.cpp:228] Iteration 12000, loss = 0.0470495
I1018 19:39:41.595628  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:39:41.595633  5095 solver.cpp:244]     Train net output #1: loss = 0.0470493 (* 1 = 0.0470493 loss)
I1018 19:39:41.595638  5095 sgd_solver.cpp:106] Iteration 12000, lr = 1e-06
I1018 19:39:42.796769  5095 solver.cpp:228] Iteration 12050, loss = 0.118084
I1018 19:39:42.796790  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:39:42.796797  5095 solver.cpp:244]     Train net output #1: loss = 0.118084 (* 1 = 0.118084 loss)
I1018 19:39:42.796800  5095 sgd_solver.cpp:106] Iteration 12050, lr = 1e-06
I1018 19:39:43.996784  5095 solver.cpp:228] Iteration 12100, loss = 0.0104768
I1018 19:39:43.996805  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:43.996811  5095 solver.cpp:244]     Train net output #1: loss = 0.0104765 (* 1 = 0.0104765 loss)
I1018 19:39:43.996815  5095 sgd_solver.cpp:106] Iteration 12100, lr = 1e-06
I1018 19:39:45.175384  5095 solver.cpp:337] Iteration 12150, Testing net (#0)
I1018 19:39:46.264950  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:39:46.264971  5095 solver.cpp:404]     Test net output #1: loss = 0.0269631 (* 1 = 0.0269631 loss)
I1018 19:39:46.273110  5095 solver.cpp:228] Iteration 12150, loss = 0.134624
I1018 19:39:46.273120  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:39:46.273125  5095 solver.cpp:244]     Train net output #1: loss = 0.134624 (* 1 = 0.134624 loss)
I1018 19:39:46.273130  5095 sgd_solver.cpp:106] Iteration 12150, lr = 1e-06
I1018 19:39:47.474442  5095 solver.cpp:228] Iteration 12200, loss = 0.0249032
I1018 19:39:47.474462  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:47.474467  5095 solver.cpp:244]     Train net output #1: loss = 0.024903 (* 1 = 0.024903 loss)
I1018 19:39:47.474470  5095 sgd_solver.cpp:106] Iteration 12200, lr = 1e-06
I1018 19:39:48.674548  5095 solver.cpp:228] Iteration 12250, loss = 0.119151
I1018 19:39:48.674571  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:39:48.674577  5095 solver.cpp:244]     Train net output #1: loss = 0.119151 (* 1 = 0.119151 loss)
I1018 19:39:48.674579  5095 sgd_solver.cpp:106] Iteration 12250, lr = 1e-06
I1018 19:39:49.851332  5095 solver.cpp:337] Iteration 12300, Testing net (#0)
I1018 19:39:50.941048  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:39:50.941068  5095 solver.cpp:404]     Test net output #1: loss = 0.027013 (* 1 = 0.027013 loss)
I1018 19:39:50.949038  5095 solver.cpp:228] Iteration 12300, loss = 0.127553
I1018 19:39:50.949048  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:39:50.949054  5095 solver.cpp:244]     Train net output #1: loss = 0.127553 (* 1 = 0.127553 loss)
I1018 19:39:50.949059  5095 sgd_solver.cpp:106] Iteration 12300, lr = 1e-06
I1018 19:39:52.151669  5095 solver.cpp:228] Iteration 12350, loss = 0.00733848
I1018 19:39:52.151691  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:52.151697  5095 solver.cpp:244]     Train net output #1: loss = 0.00733827 (* 1 = 0.00733827 loss)
I1018 19:39:52.151700  5095 sgd_solver.cpp:106] Iteration 12350, lr = 1e-06
I1018 19:39:53.353796  5095 solver.cpp:228] Iteration 12400, loss = 0.00208988
I1018 19:39:53.353818  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:53.353826  5095 solver.cpp:244]     Train net output #1: loss = 0.00208966 (* 1 = 0.00208966 loss)
I1018 19:39:53.353828  5095 sgd_solver.cpp:106] Iteration 12400, lr = 1e-06
I1018 19:39:54.531009  5095 solver.cpp:337] Iteration 12450, Testing net (#0)
I1018 19:39:55.620363  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:39:55.620388  5095 solver.cpp:404]     Test net output #1: loss = 0.0267924 (* 1 = 0.0267924 loss)
I1018 19:39:55.628360  5095 solver.cpp:228] Iteration 12450, loss = 0.0124066
I1018 19:39:55.628371  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:55.628376  5095 solver.cpp:244]     Train net output #1: loss = 0.0124064 (* 1 = 0.0124064 loss)
I1018 19:39:55.628381  5095 sgd_solver.cpp:106] Iteration 12450, lr = 1e-06
I1018 19:39:56.829293  5095 solver.cpp:228] Iteration 12500, loss = 0.241729
I1018 19:39:56.829316  5095 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I1018 19:39:56.829322  5095 solver.cpp:244]     Train net output #1: loss = 0.241729 (* 1 = 0.241729 loss)
I1018 19:39:56.829326  5095 sgd_solver.cpp:106] Iteration 12500, lr = 1e-06
I1018 19:39:58.029772  5095 solver.cpp:228] Iteration 12550, loss = 0.0142413
I1018 19:39:58.029793  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:39:58.029799  5095 solver.cpp:244]     Train net output #1: loss = 0.014241 (* 1 = 0.014241 loss)
I1018 19:39:58.029803  5095 sgd_solver.cpp:106] Iteration 12550, lr = 1e-06
I1018 19:39:59.207126  5095 solver.cpp:337] Iteration 12600, Testing net (#0)
I1018 19:40:00.296872  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9904
I1018 19:40:00.296895  5095 solver.cpp:404]     Test net output #1: loss = 0.0268997 (* 1 = 0.0268997 loss)
I1018 19:40:00.305009  5095 solver.cpp:228] Iteration 12600, loss = 0.043881
I1018 19:40:00.305021  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:00.305042  5095 solver.cpp:244]     Train net output #1: loss = 0.0438807 (* 1 = 0.0438807 loss)
I1018 19:40:00.305047  5095 sgd_solver.cpp:106] Iteration 12600, lr = 1e-06
I1018 19:40:01.507558  5095 solver.cpp:228] Iteration 12650, loss = 0.021824
I1018 19:40:01.507627  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:01.507635  5095 solver.cpp:244]     Train net output #1: loss = 0.0218238 (* 1 = 0.0218238 loss)
I1018 19:40:01.507638  5095 sgd_solver.cpp:106] Iteration 12650, lr = 1e-06
I1018 19:40:02.711237  5095 solver.cpp:228] Iteration 12700, loss = 0.0690557
I1018 19:40:02.711259  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:02.711266  5095 solver.cpp:244]     Train net output #1: loss = 0.0690554 (* 1 = 0.0690554 loss)
I1018 19:40:02.711268  5095 sgd_solver.cpp:106] Iteration 12700, lr = 1e-06
I1018 19:40:03.889858  5095 solver.cpp:337] Iteration 12750, Testing net (#0)
I1018 19:40:04.980098  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:40:04.980120  5095 solver.cpp:404]     Test net output #1: loss = 0.0269938 (* 1 = 0.0269938 loss)
I1018 19:40:04.988108  5095 solver.cpp:228] Iteration 12750, loss = 0.0351926
I1018 19:40:04.988119  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:04.988126  5095 solver.cpp:244]     Train net output #1: loss = 0.0351924 (* 1 = 0.0351924 loss)
I1018 19:40:04.988129  5095 sgd_solver.cpp:106] Iteration 12750, lr = 1e-06
I1018 19:40:06.188408  5095 solver.cpp:228] Iteration 12800, loss = 0.0101855
I1018 19:40:06.188431  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:06.188438  5095 solver.cpp:244]     Train net output #1: loss = 0.0101852 (* 1 = 0.0101852 loss)
I1018 19:40:06.188441  5095 sgd_solver.cpp:106] Iteration 12800, lr = 1e-06
I1018 19:40:07.388895  5095 solver.cpp:228] Iteration 12850, loss = 0.109567
I1018 19:40:07.388916  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:40:07.388922  5095 solver.cpp:244]     Train net output #1: loss = 0.109567 (* 1 = 0.109567 loss)
I1018 19:40:07.388926  5095 sgd_solver.cpp:106] Iteration 12850, lr = 1e-06
I1018 19:40:08.566313  5095 solver.cpp:337] Iteration 12900, Testing net (#0)
I1018 19:40:09.655441  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:40:09.655465  5095 solver.cpp:404]     Test net output #1: loss = 0.0268115 (* 1 = 0.0268115 loss)
I1018 19:40:09.663462  5095 solver.cpp:228] Iteration 12900, loss = 0.0736222
I1018 19:40:09.663475  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:40:09.663483  5095 solver.cpp:244]     Train net output #1: loss = 0.073622 (* 1 = 0.073622 loss)
I1018 19:40:09.663489  5095 sgd_solver.cpp:106] Iteration 12900, lr = 1e-06
I1018 19:40:10.865337  5095 solver.cpp:228] Iteration 12950, loss = 0.01443
I1018 19:40:10.865358  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:10.865365  5095 solver.cpp:244]     Train net output #1: loss = 0.0144298 (* 1 = 0.0144298 loss)
I1018 19:40:10.865368  5095 sgd_solver.cpp:106] Iteration 12950, lr = 1e-06
I1018 19:40:12.066045  5095 solver.cpp:228] Iteration 13000, loss = 0.0309246
I1018 19:40:12.066067  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:12.066073  5095 solver.cpp:244]     Train net output #1: loss = 0.0309243 (* 1 = 0.0309243 loss)
I1018 19:40:12.066076  5095 sgd_solver.cpp:106] Iteration 13000, lr = 1e-06
I1018 19:40:13.244770  5095 solver.cpp:337] Iteration 13050, Testing net (#0)
I1018 19:40:14.334199  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9906
I1018 19:40:14.334221  5095 solver.cpp:404]     Test net output #1: loss = 0.0267748 (* 1 = 0.0267748 loss)
I1018 19:40:14.342211  5095 solver.cpp:228] Iteration 13050, loss = 0.0127977
I1018 19:40:14.342231  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:14.342237  5095 solver.cpp:244]     Train net output #1: loss = 0.0127974 (* 1 = 0.0127974 loss)
I1018 19:40:14.342243  5095 sgd_solver.cpp:106] Iteration 13050, lr = 1e-06
I1018 19:40:15.542799  5095 solver.cpp:228] Iteration 13100, loss = 0.0377147
I1018 19:40:15.542821  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:15.542827  5095 solver.cpp:244]     Train net output #1: loss = 0.0377144 (* 1 = 0.0377144 loss)
I1018 19:40:15.542850  5095 sgd_solver.cpp:106] Iteration 13100, lr = 1e-06
I1018 19:40:16.743829  5095 solver.cpp:228] Iteration 13150, loss = 0.175299
I1018 19:40:16.743851  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:16.743857  5095 solver.cpp:244]     Train net output #1: loss = 0.175298 (* 1 = 0.175298 loss)
I1018 19:40:16.743860  5095 sgd_solver.cpp:106] Iteration 13150, lr = 1e-06
I1018 19:40:17.921084  5095 solver.cpp:337] Iteration 13200, Testing net (#0)
I1018 19:40:19.019942  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9904
I1018 19:40:19.019964  5095 solver.cpp:404]     Test net output #1: loss = 0.0269195 (* 1 = 0.0269195 loss)
I1018 19:40:19.028102  5095 solver.cpp:228] Iteration 13200, loss = 0.00507962
I1018 19:40:19.028115  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:19.028120  5095 solver.cpp:244]     Train net output #1: loss = 0.00507932 (* 1 = 0.00507932 loss)
I1018 19:40:19.028126  5095 sgd_solver.cpp:106] Iteration 13200, lr = 1e-06
I1018 19:40:20.274099  5095 solver.cpp:228] Iteration 13250, loss = 0.0238367
I1018 19:40:20.274122  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:20.274130  5095 solver.cpp:244]     Train net output #1: loss = 0.0238364 (* 1 = 0.0238364 loss)
I1018 19:40:20.274133  5095 sgd_solver.cpp:106] Iteration 13250, lr = 1e-06
I1018 19:40:21.491497  5095 solver.cpp:228] Iteration 13300, loss = 0.028233
I1018 19:40:21.491520  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:21.491528  5095 solver.cpp:244]     Train net output #1: loss = 0.0282327 (* 1 = 0.0282327 loss)
I1018 19:40:21.491531  5095 sgd_solver.cpp:106] Iteration 13300, lr = 1e-06
I1018 19:40:22.679956  5095 solver.cpp:337] Iteration 13350, Testing net (#0)
I1018 19:40:23.817364  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:40:23.817389  5095 solver.cpp:404]     Test net output #1: loss = 0.0267411 (* 1 = 0.0267411 loss)
I1018 19:40:23.825301  5095 solver.cpp:228] Iteration 13350, loss = 0.00356416
I1018 19:40:23.825312  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:23.825317  5095 solver.cpp:244]     Train net output #1: loss = 0.00356383 (* 1 = 0.00356383 loss)
I1018 19:40:23.825322  5095 sgd_solver.cpp:106] Iteration 13350, lr = 1e-06
I1018 19:40:25.063334  5095 solver.cpp:228] Iteration 13400, loss = 0.0178666
I1018 19:40:25.063357  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:25.063364  5095 solver.cpp:244]     Train net output #1: loss = 0.0178662 (* 1 = 0.0178662 loss)
I1018 19:40:25.063367  5095 sgd_solver.cpp:106] Iteration 13400, lr = 1e-06
I1018 19:40:26.271162  5095 solver.cpp:228] Iteration 13450, loss = 0.00387764
I1018 19:40:26.271184  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:26.271190  5095 solver.cpp:244]     Train net output #1: loss = 0.00387728 (* 1 = 0.00387728 loss)
I1018 19:40:26.271194  5095 sgd_solver.cpp:106] Iteration 13450, lr = 1e-06
I1018 19:40:27.449960  5095 solver.cpp:337] Iteration 13500, Testing net (#0)
I1018 19:40:28.539568  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9907
I1018 19:40:28.539592  5095 solver.cpp:404]     Test net output #1: loss = 0.0269179 (* 1 = 0.0269179 loss)
I1018 19:40:28.547664  5095 solver.cpp:228] Iteration 13500, loss = 0.0760784
I1018 19:40:28.547674  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:40:28.547680  5095 solver.cpp:244]     Train net output #1: loss = 0.0760781 (* 1 = 0.0760781 loss)
I1018 19:40:28.547684  5095 sgd_solver.cpp:106] Iteration 13500, lr = 1e-06
I1018 19:40:29.749296  5095 solver.cpp:228] Iteration 13550, loss = 0.112575
I1018 19:40:29.749317  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:40:29.749323  5095 solver.cpp:244]     Train net output #1: loss = 0.112575 (* 1 = 0.112575 loss)
I1018 19:40:29.749326  5095 sgd_solver.cpp:106] Iteration 13550, lr = 1e-06
I1018 19:40:30.952133  5095 solver.cpp:228] Iteration 13600, loss = 0.11673
I1018 19:40:30.952180  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:30.952188  5095 solver.cpp:244]     Train net output #1: loss = 0.11673 (* 1 = 0.11673 loss)
I1018 19:40:30.952190  5095 sgd_solver.cpp:106] Iteration 13600, lr = 1e-06
I1018 19:40:32.141783  5095 solver.cpp:337] Iteration 13650, Testing net (#0)
I1018 19:40:33.248634  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9907
I1018 19:40:33.248662  5095 solver.cpp:404]     Test net output #1: loss = 0.0268263 (* 1 = 0.0268263 loss)
I1018 19:40:33.256804  5095 solver.cpp:228] Iteration 13650, loss = 0.039493
I1018 19:40:33.256814  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:40:33.256819  5095 solver.cpp:244]     Train net output #1: loss = 0.0394926 (* 1 = 0.0394926 loss)
I1018 19:40:33.256824  5095 sgd_solver.cpp:106] Iteration 13650, lr = 1e-06
I1018 19:40:34.529026  5095 solver.cpp:228] Iteration 13700, loss = 0.00804983
I1018 19:40:34.529065  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:34.529072  5095 solver.cpp:244]     Train net output #1: loss = 0.00804949 (* 1 = 0.00804949 loss)
I1018 19:40:34.529078  5095 sgd_solver.cpp:106] Iteration 13700, lr = 1e-06
I1018 19:40:35.768273  5095 solver.cpp:228] Iteration 13750, loss = 0.0103908
I1018 19:40:35.768297  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:35.768304  5095 solver.cpp:244]     Train net output #1: loss = 0.0103904 (* 1 = 0.0103904 loss)
I1018 19:40:35.768307  5095 sgd_solver.cpp:106] Iteration 13750, lr = 1e-06
I1018 19:40:36.957907  5095 solver.cpp:337] Iteration 13800, Testing net (#0)
I1018 19:40:38.061543  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9905
I1018 19:40:38.061568  5095 solver.cpp:404]     Test net output #1: loss = 0.0265348 (* 1 = 0.0265348 loss)
I1018 19:40:38.069758  5095 solver.cpp:228] Iteration 13800, loss = 0.0635506
I1018 19:40:38.069772  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:38.069777  5095 solver.cpp:244]     Train net output #1: loss = 0.0635503 (* 1 = 0.0635503 loss)
I1018 19:40:38.069783  5095 sgd_solver.cpp:106] Iteration 13800, lr = 1e-06
I1018 19:40:39.277451  5095 solver.cpp:228] Iteration 13850, loss = 0.197153
I1018 19:40:39.277477  5095 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I1018 19:40:39.277482  5095 solver.cpp:244]     Train net output #1: loss = 0.197153 (* 1 = 0.197153 loss)
I1018 19:40:39.277487  5095 sgd_solver.cpp:106] Iteration 13850, lr = 1e-06
I1018 19:40:40.503044  5095 solver.cpp:228] Iteration 13900, loss = 0.0411957
I1018 19:40:40.503068  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:40.503075  5095 solver.cpp:244]     Train net output #1: loss = 0.0411953 (* 1 = 0.0411953 loss)
I1018 19:40:40.503079  5095 sgd_solver.cpp:106] Iteration 13900, lr = 1e-06
I1018 19:40:41.796743  5095 solver.cpp:337] Iteration 13950, Testing net (#0)
I1018 19:40:42.981451  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1018 19:40:42.981482  5095 solver.cpp:404]     Test net output #1: loss = 0.0265636 (* 1 = 0.0265636 loss)
I1018 19:40:42.989822  5095 solver.cpp:228] Iteration 13950, loss = 0.119971
I1018 19:40:42.989866  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:40:42.989874  5095 solver.cpp:244]     Train net output #1: loss = 0.119971 (* 1 = 0.119971 loss)
I1018 19:40:42.989881  5095 sgd_solver.cpp:106] Iteration 13950, lr = 1e-06
I1018 19:40:44.262598  5095 solver.cpp:228] Iteration 14000, loss = 0.0660717
I1018 19:40:44.262621  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:44.262627  5095 solver.cpp:244]     Train net output #1: loss = 0.0660713 (* 1 = 0.0660713 loss)
I1018 19:40:44.262630  5095 sgd_solver.cpp:106] Iteration 14000, lr = 1e-06
I1018 19:40:45.550267  5095 solver.cpp:228] Iteration 14050, loss = 0.00292329
I1018 19:40:45.550290  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:45.550297  5095 solver.cpp:244]     Train net output #1: loss = 0.00292293 (* 1 = 0.00292293 loss)
I1018 19:40:45.550299  5095 sgd_solver.cpp:106] Iteration 14050, lr = 1e-06
I1018 19:40:46.735759  5095 solver.cpp:337] Iteration 14100, Testing net (#0)
I1018 19:40:47.825973  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9905
I1018 19:40:47.825996  5095 solver.cpp:404]     Test net output #1: loss = 0.0270993 (* 1 = 0.0270993 loss)
I1018 19:40:47.833961  5095 solver.cpp:228] Iteration 14100, loss = 0.168608
I1018 19:40:47.833972  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:47.833977  5095 solver.cpp:244]     Train net output #1: loss = 0.168608 (* 1 = 0.168608 loss)
I1018 19:40:47.833983  5095 sgd_solver.cpp:106] Iteration 14100, lr = 1e-06
I1018 19:40:49.036909  5095 solver.cpp:228] Iteration 14150, loss = 0.111919
I1018 19:40:49.036931  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:49.036936  5095 solver.cpp:244]     Train net output #1: loss = 0.111919 (* 1 = 0.111919 loss)
I1018 19:40:49.036939  5095 sgd_solver.cpp:106] Iteration 14150, lr = 1e-06
I1018 19:40:50.240101  5095 solver.cpp:228] Iteration 14200, loss = 0.024638
I1018 19:40:50.240124  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:50.240130  5095 solver.cpp:244]     Train net output #1: loss = 0.0246376 (* 1 = 0.0246376 loss)
I1018 19:40:50.240134  5095 sgd_solver.cpp:106] Iteration 14200, lr = 1e-06
I1018 19:40:51.429536  5095 solver.cpp:337] Iteration 14250, Testing net (#0)
I1018 19:40:52.542060  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:40:52.542084  5095 solver.cpp:404]     Test net output #1: loss = 0.0267878 (* 1 = 0.0267878 loss)
I1018 19:40:52.549988  5095 solver.cpp:228] Iteration 14250, loss = 0.0091611
I1018 19:40:52.549998  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:52.550003  5095 solver.cpp:244]     Train net output #1: loss = 0.00916076 (* 1 = 0.00916076 loss)
I1018 19:40:52.550009  5095 sgd_solver.cpp:106] Iteration 14250, lr = 1e-06
I1018 19:40:53.821166  5095 solver.cpp:228] Iteration 14300, loss = 0.00154186
I1018 19:40:53.821189  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:53.821195  5095 solver.cpp:244]     Train net output #1: loss = 0.00154151 (* 1 = 0.00154151 loss)
I1018 19:40:53.821198  5095 sgd_solver.cpp:106] Iteration 14300, lr = 1e-06
I1018 19:40:55.106911  5095 solver.cpp:228] Iteration 14350, loss = 0.0506239
I1018 19:40:55.106930  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:40:55.106936  5095 solver.cpp:244]     Train net output #1: loss = 0.0506235 (* 1 = 0.0506235 loss)
I1018 19:40:55.106940  5095 sgd_solver.cpp:106] Iteration 14350, lr = 1e-06
I1018 19:40:56.403576  5095 solver.cpp:337] Iteration 14400, Testing net (#0)
I1018 19:40:57.562125  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9907
I1018 19:40:57.562149  5095 solver.cpp:404]     Test net output #1: loss = 0.0269003 (* 1 = 0.0269003 loss)
I1018 19:40:57.570243  5095 solver.cpp:228] Iteration 14400, loss = 0.00840873
I1018 19:40:57.570253  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:57.570258  5095 solver.cpp:244]     Train net output #1: loss = 0.00840837 (* 1 = 0.00840837 loss)
I1018 19:40:57.570263  5095 sgd_solver.cpp:106] Iteration 14400, lr = 1e-06
I1018 19:40:58.778178  5095 solver.cpp:228] Iteration 14450, loss = 0.00863834
I1018 19:40:58.778203  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:40:58.778208  5095 solver.cpp:244]     Train net output #1: loss = 0.00863797 (* 1 = 0.00863797 loss)
I1018 19:40:58.778211  5095 sgd_solver.cpp:106] Iteration 14450, lr = 1e-06
I1018 19:41:00.006536  5095 solver.cpp:228] Iteration 14500, loss = 0.0474078
I1018 19:41:00.006559  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:41:00.006567  5095 solver.cpp:244]     Train net output #1: loss = 0.0474074 (* 1 = 0.0474074 loss)
I1018 19:41:00.006569  5095 sgd_solver.cpp:106] Iteration 14500, lr = 1e-06
I1018 19:41:01.303189  5095 solver.cpp:337] Iteration 14550, Testing net (#0)
I1018 19:41:02.400599  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9907
I1018 19:41:02.400671  5095 solver.cpp:404]     Test net output #1: loss = 0.0269072 (* 1 = 0.0269072 loss)
I1018 19:41:02.408599  5095 solver.cpp:228] Iteration 14550, loss = 0.0606494
I1018 19:41:02.408609  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:41:02.408614  5095 solver.cpp:244]     Train net output #1: loss = 0.060649 (* 1 = 0.060649 loss)
I1018 19:41:02.408618  5095 sgd_solver.cpp:106] Iteration 14550, lr = 1e-06
I1018 19:41:03.668850  5095 solver.cpp:228] Iteration 14600, loss = 0.204318
I1018 19:41:03.668874  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:41:03.668880  5095 solver.cpp:244]     Train net output #1: loss = 0.204317 (* 1 = 0.204317 loss)
I1018 19:41:03.668882  5095 sgd_solver.cpp:106] Iteration 14600, lr = 1e-06
I1018 19:41:04.934351  5095 solver.cpp:228] Iteration 14650, loss = 0.00705755
I1018 19:41:04.934373  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:41:04.934381  5095 solver.cpp:244]     Train net output #1: loss = 0.00705716 (* 1 = 0.00705716 loss)
I1018 19:41:04.934383  5095 sgd_solver.cpp:106] Iteration 14650, lr = 1e-06
I1018 19:41:06.110312  5095 solver.cpp:337] Iteration 14700, Testing net (#0)
I1018 19:41:07.206254  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9905
I1018 19:41:07.206276  5095 solver.cpp:404]     Test net output #1: loss = 0.0269144 (* 1 = 0.0269144 loss)
I1018 19:41:07.214390  5095 solver.cpp:228] Iteration 14700, loss = 0.056879
I1018 19:41:07.214401  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:41:07.214406  5095 solver.cpp:244]     Train net output #1: loss = 0.0568786 (* 1 = 0.0568786 loss)
I1018 19:41:07.214411  5095 sgd_solver.cpp:106] Iteration 14700, lr = 1e-06
I1018 19:41:08.415783  5095 solver.cpp:228] Iteration 14750, loss = 0.0187153
I1018 19:41:08.415807  5095 solver.cpp:244]     Train net output #0: accuracy = 1
I1018 19:41:08.415813  5095 solver.cpp:244]     Train net output #1: loss = 0.0187149 (* 1 = 0.0187149 loss)
I1018 19:41:08.415817  5095 sgd_solver.cpp:106] Iteration 14750, lr = 1e-06
I1018 19:41:09.619326  5095 solver.cpp:228] Iteration 14800, loss = 0.223533
I1018 19:41:09.619354  5095 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I1018 19:41:09.619360  5095 solver.cpp:244]     Train net output #1: loss = 0.223533 (* 1 = 0.223533 loss)
I1018 19:41:09.619365  5095 sgd_solver.cpp:106] Iteration 14800, lr = 1e-06
I1018 19:41:10.880810  5095 solver.cpp:337] Iteration 14850, Testing net (#0)
I1018 19:41:12.062405  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9904
I1018 19:41:12.062430  5095 solver.cpp:404]     Test net output #1: loss = 0.0267599 (* 1 = 0.0267599 loss)
I1018 19:41:12.070577  5095 solver.cpp:228] Iteration 14850, loss = 0.0783853
I1018 19:41:12.070593  5095 solver.cpp:244]     Train net output #0: accuracy = 0.953125
I1018 19:41:12.070598  5095 solver.cpp:244]     Train net output #1: loss = 0.078385 (* 1 = 0.078385 loss)
I1018 19:41:12.070603  5095 sgd_solver.cpp:106] Iteration 14850, lr = 1e-06
I1018 19:41:13.329741  5095 solver.cpp:228] Iteration 14900, loss = 0.146974
I1018 19:41:13.329779  5095 solver.cpp:244]     Train net output #0: accuracy = 0.984375
I1018 19:41:13.329790  5095 solver.cpp:244]     Train net output #1: loss = 0.146974 (* 1 = 0.146974 loss)
I1018 19:41:13.329797  5095 sgd_solver.cpp:106] Iteration 14900, lr = 1e-06
I1018 19:41:14.535354  5095 solver.cpp:228] Iteration 14950, loss = 0.100551
I1018 19:41:14.535378  5095 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I1018 19:41:14.535387  5095 solver.cpp:244]     Train net output #1: loss = 0.100551 (* 1 = 0.100551 loss)
I1018 19:41:14.535390  5095 sgd_solver.cpp:106] Iteration 14950, lr = 1e-06
I1018 19:41:15.712100  5095 solver.cpp:454] Snapshotting to binary proto file cifar-10_leakyrelu_RMSProp_iter_15000.caffemodel
I1018 19:41:15.737373  5095 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cifar-10_leakyrelu_RMSProp_iter_15000.solverstate
I1018 19:41:15.749996  5095 solver.cpp:317] Iteration 15000, loss = 0.00857416
I1018 19:41:15.750028  5095 solver.cpp:337] Iteration 15000, Testing net (#0)
I1018 19:41:16.823607  5095 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1018 19:41:16.823632  5095 solver.cpp:404]     Test net output #1: loss = 0.0270497 (* 1 = 0.0270497 loss)
I1018 19:41:16.823637  5095 solver.cpp:322] Optimization Done.
I1018 19:41:16.823638  5095 caffe.cpp:254] Optimization Done.
